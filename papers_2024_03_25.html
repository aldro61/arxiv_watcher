
            <html>
            <head>
                <title>Report Generated on March 25, 2024</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .paper-box {
                        background-color: #f0f0f0;
                        margin-bottom: 20px;
                        padding: 15px;
                        border-radius: 5px;
                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    }
                    h1 { text-align: center; }
                    h2 {
                        cursor: pointer;
                        color: #333;
                        border-bottom: 2px solid #666;
                    }
                    a { color: #337ab7; text-decoration: none; }
                    a:hover { text-decoration: underline; }
                    h3 { color: #337ab7; }
                    .timestamp { text-align: center; font-size: small; margin-top: 40px; }
                    .paper-figure {
                        max-width: 200px;
                        border: 1px solid #ddd;
                        border-radius: 4px;
                        padding: 5px;
                        margin-top: 10px;
                    }
                    .papers-container { display: block; padding: 0 18px; }
                </style>
            </head>
            <body>
            <h1>Report for March 25, 2024</h1>
            <script>
                function toggleSection(id) {
                    var x = document.getElementById(id);
                    if (x.style.display === "none") {
                        x.style.display = "block";
                    } else {
                        x.style.display = "none";
                    }
                }
            </script>
            <h2 onclick="toggleSection('section_time-series')">Time-series</h2><div id='section_time-series' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14735" target="_blank">Foundation Models for Time Series Analysis: A Tutorial and Survey</a></h3>
            <a href="https://arxiv.org/html/2403.14735v1/extracted/5486186/img/roadmap.png" target="_blank"><img src="https://arxiv.org/html/2403.14735v1/extracted/5486186/img/roadmap.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, Qingsong Wen</p>
            <p><strong>Summary:</strong> arXiv:2403.14735v1 Announce Type: new 
Abstract: Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric classification, delineating various pivotal elements of time-series FMs, including model architectures, pre-training techniques, adaptation methods, and data modalities. Overall, this survey serves to consolidate the latest advancements in FMs pertinent to time series analysis, accentuating their theoretical underpinnings, recent strides in development, and avenues for future research exploration.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14735">https://arxiv.org/abs/2403.14735</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is very relevant to your interests as it not only presents a tutorial and survey on Foundation Models for Time Series analysis, focusing on new methods, but it also provides information on datasets and multimodal data which you've mentioned you want to know more about.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.04147" target="_blank">Multi-resolution Time-Series Transformer for Long-term Forecasting</a></h3>
            <a href="https://arxiv.org/html/2311.04147v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2311.04147v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yitian Zhang, Liheng Ma, Soumyasundar Pal, Yingxue Zhang, Mark Coates</p>
            <p><strong>Summary:</strong> arXiv:2311.04147v2 Announce Type: replace 
Abstract: The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.04147">https://arxiv.org/abs/2311.04147</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interests as it proposes a new transformer-like model, the Multi-resolution Time-Series Transformer, for time-series forecasting. It also has a novel multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.16424" target="_blank">Soft Contrastive Learning for Time Series</a></h3>
            
            <p><strong>Authors:</strong> Seunghan Lee, Taeyoung Park, Kibok Lee</p>
            <p><strong>Summary:</strong> arXiv:2312.16424v3 Announce Type: replace 
Abstract: Contrastive learning has shown to be effective to learn representations from time series in a self-supervised way. However, contrasting similar time series instances or values from adjacent timestamps within a time series leads to ignore their inherent correlations, which results in deteriorating the quality of learned representations. To address this issue, we propose SoftCLT, a simple yet effective soft contrastive learning strategy for time series. This is achieved by introducing instance-wise and temporal contrastive loss with soft assignments ranging from zero to one. Specifically, we define soft assignments for 1) instance-wise contrastive loss by the distance between time series on the data space, and 2) temporal contrastive loss by the difference of timestamps. SoftCLT is a plug-and-play method for time series contrastive learning that improves the quality of learned representations without bells and whistles. In experiments, we demonstrate that SoftCLT consistently improves the performance in various downstream tasks including classification, semi-supervised learning, transfer learning, and anomaly detection, showing state-of-the-art performance. Code is available at this repository: https://github.com/seunghan96/softclt.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.16424">https://arxiv.org/abs/2312.16424</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interest as it introduces SoftCLT, a new method for time series contrastive learning. This approach could potentially offer new insights into deep learning methods for time series, which is a subtopic you're interested in. Moreover, the method has been demonstrated to perform well in various downstream tasks such as classification, semi-supervised learning, transfer learning, and anomaly detection.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.16427" target="_blank">Learning to Embed Time Series Patches Independently</a></h3>
            
            <p><strong>Authors:</strong> Seunghan Lee, Taeyoung Park, Kibok Lee</p>
            <p><strong>Summary:</strong> arXiv:2312.16427v3 Announce Type: replace 
Abstract: Masked time series modeling has recently gained much attention as a self-supervised representation learning strategy for time series. Inspired by masked image modeling in computer vision, recent works first patchify and partially mask out time series, and then train Transformers to capture the dependencies between patches by predicting masked patches from unmasked patches. However, we argue that capturing such patch dependencies might not be an optimal strategy for time series representation learning; rather, learning to embed patches independently results in better time series representations. Specifically, we propose to use 1) the simple patch reconstruction task, which autoencode each patch without looking at other patches, and 2) the simple patch-wise MLP that embeds each patch independently. In addition, we introduce complementary contrastive learning to hierarchically capture adjacent time series information efficiently. Our proposed method improves time series forecasting and classification performance compared to state-of-the-art Transformer-based models, while it is more efficient in terms of the number of parameters and training/inference time. Code is available at this repository: https://github.com/seunghan96/pits.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.16427">https://arxiv.org/abs/2312.16427</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is very relevant to your interest in time series and deep learning as it proposes new methods for time series representation learning, specifically for forecasting, and discusses a new approach to training Transformers for time series data. </p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14949" target="_blank">Addressing Concept Shift in Online Time Series Forecasting: Detect-then-Adapt</a></h3>
            <a href="https://arxiv.org/html/2403.14949v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.14949v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> YiFan Zhang, Weiqi Chen, Zhaoyang Zhu, Dalin Qin, Liang Sun, Xue Wang, Qingsong Wen, Zhang Zhang, Liang Wang, Rong Jin</p>
            <p><strong>Summary:</strong> arXiv:2403.14949v1 Announce Type: new 
Abstract: Online updating of time series forecasting models aims to tackle the challenge of concept drifting by adjusting forecasting models based on streaming data. While numerous algorithms have been developed, most of them focus on model design and updating. In practice, many of these methods struggle with continuous performance regression in the face of accumulated concept drifts over time. To address this limitation, we present a novel approach, Concept \textbf{D}rift \textbf{D}etection an\textbf{D} \textbf{A}daptation (D3A), that first detects drifting conception and then aggressively adapts the current model to the drifted concepts after the detection for rapid adaption. To best harness the utility of historical data for model adaptation, we propose a data augmentation strategy introducing Gaussian noise into existing training instances. It helps mitigate the data distribution gap, a critical factor contributing to train-test performance inconsistency. The significance of our data augmentation process is verified by our theoretical analysis. Our empirical studies across six datasets demonstrate the effectiveness of D3A in improving model adaptation capability. Notably, compared to a simple Temporal Convolutional Network (TCN) baseline, D3A reduces the average Mean Squared Error (MSE) by $43.9\%$. For the state-of-the-art (SOTA) model, the MSE is reduced by $33.3\%$.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14949">https://arxiv.org/abs/2403.14949</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper proposes a new approach to online time series forecasting, which is relevant to your interest in new methods for time series. It does not focus on deep learning, foundation models, multimodal approaches, or transformer-like models for time series, which lessens its relevancy a bit.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15027" target="_blank">Grey-informed neural network for time-series forecasting</a></h3>
            <a href="https://arxiv.org/html/2403.15027v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15027v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Wanli Xie, Ruibin Zhao, Zhenguo Xu, Tingting Liang</p>
            <p><strong>Summary:</strong> arXiv:2403.15027v1 Announce Type: new 
Abstract: Neural network models have shown outstanding performance and successful resolutions to complex problems in various fields. However, the majority of these models are viewed as black-box, requiring a significant amount of data for development. Consequently, in situations with limited data, constructing appropriate models becomes challenging due to the lack of transparency and scarcity of data. To tackle these challenges, this study suggests the implementation of a grey-informed neural network (GINN). The GINN ensures that the output of the neural network follows the differential equation model of the grey system, improving interpretability. Moreover, incorporating prior knowledge from grey system theory enables traditional neural networks to effectively handle small data samples. Our proposed model has been observed to uncover underlying patterns in the real world and produce reliable forecasts based on empirical data.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15027">https://arxiv.org/abs/2403.15027</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is proposing a new neural network method for time-series forecasting, which aligns with your interest in new deep learning methods for time series. However, it focuses on small data samples rather than foundation or multimodal models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14695" target="_blank">Chain-structured neural architecture search for financial time series forecasting</a></h3>
            <a href="https://arxiv.org/html/2403.14695v1/extracted/5473623/results.png" target="_blank"><img src="https://arxiv.org/html/2403.14695v1/extracted/5473623/results.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Denis Levchenko, Efstratios Rappos, Shabnam Ataee, Biagio Nigro, Stephan Robert</p>
            <p><strong>Summary:</strong> arXiv:2403.14695v1 Announce Type: cross 
Abstract: We compare three popular neural architecture search strategies on chain-structured search spaces: Bayesian optimization, the hyperband method, and reinforcement learning in the context of financial time series forecasting.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14695">https://arxiv.org/abs/2403.14695</a></p>
            <p><strong>Category:</strong> q-fin.ST</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> The paper explores three neural architecture search strategies for forecasting financial time series, which aligns with your interest in new methods for time series forecasting. However, it does not clearly mention whether it leverages deep learning methods, multimodal models, or transformer-like models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15360" target="_blank">SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series</a></h3>
            <a href="https://arxiv.org/html/2403.15360v1/extracted/5484948/simba.png" target="_blank"><img src="https://arxiv.org/html/2403.15360v1/extracted/5484948/simba.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Badri N. Patro, Vijay S. Agneeswaran</p>
            <p><strong>Summary:</strong> arXiv:2403.15360v1 Announce Type: cross 
Abstract: Transformers have widely adopted attention networks for sequence mixing and MLPs for channel mixing, playing a pivotal role in achieving breakthroughs across domains. However, recent literature highlights issues with attention networks, including low inductive bias and quadratic complexity concerning input sequence length. State Space Models (SSMs) like S4 and others (Hippo, Global Convolutions, liquid S4, LRU, Mega, and Mamba), have emerged to address the above issues to help handle longer sequence lengths. Mamba, while being the state-of-the-art SSM, has a stability issue when scaled to large networks for computer vision datasets. We propose SiMBA, a new architecture that introduces Einstein FFT (EinFFT) for channel modeling by specific eigenvalue computations and uses the Mamba block for sequence modeling. Extensive performance studies across image and time-series benchmarks demonstrate that SiMBA outperforms existing SSMs, bridging the performance gap with state-of-the-art transformers. Notably, SiMBA establishes itself as the new state-of-the-art SSM on ImageNet and transfer learning benchmarks such as Stanford Car and Flower as well as task learning benchmarks as well as seven time series benchmark datasets. The project page is available on this website ~\url{https://github.com/badripatro/Simba}.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15360">https://arxiv.org/abs/2403.15360</a></p>
            <p><strong>Category:</strong> cs.CV</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper fits your interest because it presents a new architecture, SiMBA, for long sequence and time series analysis - a subtopic under your specified interests in time series and deep learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.05469" target="_blank">Learning to Predict Structural Vibrations</a></h3>
            <a href="https://arxiv.org/html/2310.05469v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.05469v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jan van Delden, Julius Schultz, Christopher Blech, Sabine C. Langer, Timo L\"uddecke</p>
            <p><strong>Summary:</strong> arXiv:2310.05469v3 Announce Type: replace 
Abstract: In mechanical structures like airplanes, cars and houses, noise is generated and transmitted through vibrations. To take measures to reduce this noise, vibrations need to be simulated with expensive numerical computations. Surrogate deep learning models present a promising alternative to classical numerical simulations as they can be evaluated magnitudes faster, while trading-off accuracy. To quantify such trade-offs systematically and foster the development of methods, we present a benchmark on the task of predicting the vibration of harmonically excited plates. The benchmark features a total of 12000 plate geometries with varying forms of beadings, material and sizes with associated numerical solutions. To address the benchmark task, we propose a new network architecture, named Frequency-Query Operator, which is trained to map plate geometries to their vibration pattern given a specific excitation frequency. Applying principles from operator learning and implicit models for shape encoding, our approach effectively addresses the prediction of highly variable frequency response functions occurring in dynamic systems. To quantify the prediction quality, we introduce a set of evaluation metrics and evaluate the method on our vibrating-plates benchmark. Our method outperforms DeepONets, Fourier Neural Operators and more traditional neural network architectures. Code, dataset and visualizations: https://eckerlab.org/code/delden2023_plate</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.05469">https://arxiv.org/abs/2310.05469</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper presents a new network architecture, the Frequency-Query Operator, which is trained to forecast the vibration patterns of various plate geometries given a specific excitation frequency. Even if it's not directly about a time series application, methods and architectures proposed in the paper might be applicable or useful for time series forecasting.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.11558" target="_blank">A Temporally Disentangled Contrastive Diffusion Model for Spatiotemporal Imputation</a></h3>
            <a href="https://arxiv.org/html/2402.11558v2/extracted/5488386/disentangle.png" target="_blank"><img src="https://arxiv.org/html/2402.11558v2/extracted/5488386/disentangle.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yakun Chen, Kaize Shi, Zhangkai Wu, Juan Chen, Xianzhi Wang, Julian McAuley, Guandong Xu, Shui Yu</p>
            <p><strong>Summary:</strong> arXiv:2402.11558v2 Announce Type: replace 
Abstract: Spatiotemporal data analysis is pivotal across various domains, such as transportation, meteorology, and healthcare. The data collected in real-world scenarios are often incomplete due to device malfunctions and network errors. Spatiotemporal imputation aims to predict missing values by exploiting the spatial and temporal dependencies in the observed data. Traditional imputation approaches based on statistical and machine learning techniques require the data to conform to their distributional assumptions, while graph and recurrent neural networks are prone to error accumulation problems due to their recurrent structures. Generative models, especially diffusion models, can potentially circumvent the reliance on inaccurate, previously imputed values for future predictions; However, diffusion models still face challenges in generating stable results. We propose to address these challenges by designing conditional information to guide the generative process and expedite the training process. We introduce a conditional diffusion framework called C$^2$TSD, which incorporates disentangled temporal (trend and seasonality) representations as conditional information and employs contrastive learning to improve generalizability. Our extensive experiments on three real-world datasets demonstrate the superior performance of our approach compared to a number of state-of-the-art baselines.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.11558">https://arxiv.org/abs/2402.11558</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is about developing a deep learning algorithm for spatiotemporal imputation, which could be seen as a temporal series forecasting problem. Although it does not focus specifically on the subtopics you listed, it seems to explore a new deep learning method, which makes it relevant to your interests.</p>
        </div>
        </div><h2 onclick="toggleSection('section_causality')">Causality</h2><div id='section_causality' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14843" target="_blank">Local Causal Discovery with Linear non-Gaussian Cyclic Models</a></h3>
            
            <p><strong>Authors:</strong> Haoyue Dai, Ignavier Ng, Yujia Zheng, Zhengqing Gao, Kun Zhang</p>
            <p><strong>Summary:</strong> arXiv:2403.14843v1 Announce Type: new 
Abstract: Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acyclic scenarios. Our identifiability results are empirically validated using both synthetic and real-world datasets.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14843">https://arxiv.org/abs/2403.14843</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> The paper focuses on local causal discovery which falls under your causality and machine learning interest. It also explores new methodologies in this field.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15025" target="_blank">Robust Conformal Prediction under Distribution Shift via Physics-Informed Structural Causal Model</a></h3>
            <a href="https://arxiv.org/html/2403.15025v1/extracted/5488049/Coverage_Divergence_v2.png" target="_blank"><img src="https://arxiv.org/html/2403.15025v1/extracted/5488049/Coverage_Divergence_v2.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Rui Xu, Yue Sun, Chao Chen, Parv Venkitasubramaniam, Sihong Xie</p>
            <p><strong>Summary:</strong> arXiv:2403.15025v1 Announce Type: new 
Abstract: Uncertainty is critical to reliable decision-making with machine learning. Conformal prediction (CP) handles uncertainty by predicting a set on a test input, hoping the set to cover the true label with at least $(1-\alpha)$ confidence. This coverage can be guaranteed on test data even if the marginal distributions $P_X$ differ between calibration and test datasets. However, as it is common in practice, when the conditional distribution $P_{Y|X}$ is different on calibration and test data, the coverage is not guaranteed and it is essential to measure and minimize the coverage loss under distributional shift at \textit{all} possible confidence levels. To address these issues, we upper bound the coverage difference at all levels using the cumulative density functions of calibration and test conformal scores and Wasserstein distance. Inspired by the invariance of physics across data distributions, we propose a physics-informed structural causal model (PI-SCM) to reduce the upper bound. We validated that PI-SCM can improve coverage robustness along confidence level and test domain on a traffic speed prediction task and an epidemic spread task with multiple real-world datasets.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15025">https://arxiv.org/abs/2403.15025</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in causality and machine learning. It addresses the issue of uncertainty in decision-making through Conformal prediction (CP) and proposes a new method, physics-informed structural causal model (PI-SCM), for ensuring robust coverage across confidence levels and test domains. While it does not directly talk about causal discovery or use of large language models, it contributes to the general topic of incorporating causality in machine learning.</p>
        </div>
        </div><h2 onclick="toggleSection('section_llm-agents')">Llm-agents</h2><div id='section_llm-agents' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15371" target="_blank">Can large language models explore in-context?</a></h3>
            <a href="https://arxiv.org/html/2403.15371v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15371v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Akshay Krishnamurthy, Keegan Harris, Dylan J. Foster, Cyril Zhang, Aleksandrs Slivkins</p>
            <p><strong>Summary:</strong> arXiv:2403.15371v1 Announce Type: new 
Abstract: We investigate the extent to which contemporary Large Language Models (LLMs) can engage in exploration, a core capability in reinforcement learning and decision making. We focus on native performance of existing LLMs, without training interventions. We deploy LLMs as agents in simple multi-armed bandit environments, specifying the environment description and interaction history entirely in-context, i.e., within the LLM prompt. We experiment with GPT-3.5, GPT-4, and Llama2, using a variety of prompt designs, and find that the models do not robustly engage in exploration without substantial interventions: i) Across all of our experiments, only one configuration resulted in satisfactory exploratory behavior: GPT-4 with chain-of-thought reasoning and an externally summarized interaction history, presented as sufficient statistics; ii) All other configurations did not result in robust exploratory behavior, including those with chain-of-thought reasoning but unsummarized history. Although these findings can be interpreted positively, they suggest that external summarization -- which may not be possible in more complex settings -- is important for obtaining desirable behavior from LLM agents. We conclude that non-trivial algorithmic interventions, such as fine-tuning or dataset curation, may be required to empower LLM-based decision making agents in complex settings.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15371">https://arxiv.org/abs/2403.15371</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper falls under your interest in large language models agents. It investigates how Large Language Models (LLMs) perform in reinforcement learning and decision making scenarios, which is connected to using LLMs to control software and computer automation. However, it does not specifically cover controlling web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14683" target="_blank">A Moral Imperative: The Need for Continual Superalignment of Large Language Models</a></h3>
            
            <p><strong>Authors:</strong> Gokul Puthumanaillam, Manav Vora, Pranay Thangeda, Melkior Ornik</p>
            <p><strong>Summary:</strong> arXiv:2403.14683v1 Announce Type: cross 
Abstract: This paper examines the challenges associated with achieving life-long superalignment in AI systems, particularly large language models (LLMs). Superalignment is a theoretical framework that aspires to ensure that superintelligent AI systems act in accordance with human values and goals. Despite its promising vision, we argue that achieving superalignment requires substantial changes in the current LLM architectures due to their inherent limitations in comprehending and adapting to the dynamic nature of these human ethics and evolving global scenarios. We dissect the challenges of encoding an ever-changing spectrum of human values into LLMs, highlighting the discrepancies between static AI models and the dynamic nature of human societies. To illustrate these challenges, we analyze two distinct examples: one demonstrates a qualitative shift in human values, while the other presents a quantifiable change. Through these examples, we illustrate how LLMs, constrained by their training data, fail to align with contemporary human values and scenarios. The paper concludes by exploring potential strategies to address and possibly mitigate these alignment discrepancies, suggesting a path forward in the pursuit of more adaptable and responsive AI systems.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14683">https://arxiv.org/abs/2403.14683</a></p>
            <p><strong>Category:</strong> cs.CY</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interests as it discusses the challenges and potential strategies in developing large language models, specifically tackling the alignment of these models with dynamic human values - an important aspect in controlling software or web browsers using large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14720" target="_blank">Defending Against Indirect Prompt Injection Attacks With Spotlighting</a></h3>
            <a href="https://arxiv.org/html/2403.14720v1/extracted/5484347/imgs/asr_baselines.png" target="_blank"><img src="https://arxiv.org/html/2403.14720v1/extracted/5484347/imgs/asr_baselines.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Keegan Hines, Gary Lopez, Matthew Hall, Federico Zarfati, Yonatan Zunger, Emre Kiciman</p>
            <p><strong>Summary:</strong> arXiv:2403.14720v1 Announce Type: cross 
Abstract: Large Language Models (LLMs), while powerful, are built and trained to process a single text input. In common applications, multiple inputs can be processed by concatenating them together into a single stream of text. However, the LLM is unable to distinguish which sections of prompt belong to various input sources. Indirect prompt injection attacks take advantage of this vulnerability by embedding adversarial instructions into untrusted data being processed alongside user commands. Often, the LLM will mistake the adversarial instructions as user commands to be followed, creating a security vulnerability in the larger system. We introduce spotlighting, a family of prompt engineering techniques that can be used to improve LLMs' ability to distinguish among multiple sources of input. The key insight is to utilize transformations of an input to provide a reliable and continuous signal of its provenance. We evaluate spotlighting as a defense against indirect prompt injection attacks, and find that it is a robust defense that has minimal detrimental impact to underlying NLP tasks. Using GPT-family models, we find that spotlighting reduces the attack success rate from greater than {50}\% to below {2}\% in our experiments with minimal impact on task efficacy.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14720">https://arxiv.org/abs/2403.14720</a></p>
            <p><strong>Category:</strong> cs.CR</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> While it doesn't directly propose a new method for controlling software or web browsers with large language models, it discusses the robustness and security of these models. This could be indirectly relevant for building secure and reliable LLM-based agents.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14950" target="_blank">KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation</a></h3>
            <a href="https://arxiv.org/html/2403.14950v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.14950v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xindi Luo, Zequn Sun, Jing Zhao, Zhe Zhao, Wei Hu</p>
            <p><strong>Summary:</strong> arXiv:2403.14950v1 Announce Type: cross 
Abstract: Parameter-efficient finetuning (PEFT) is a key technique for adapting large language models (LLMs) to downstream tasks. In this paper, we study leveraging knowledge graph embeddings to improve the effectiveness of PEFT. We propose a knowledgeable adaptation method called KnowLA. It inserts an adaptation layer into an LLM to integrate the embeddings of entities appearing in the input text. The adaptation layer is trained in combination with LoRA on instruction data. Experiments on six benchmarks with two popular LLMs and three knowledge graphs demonstrate the effectiveness and robustness of KnowLA. We show that \modelname can help activate the relevant parameterized knowledge in an LLM to answer a question without changing its parameters or input prompts.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14950">https://arxiv.org/abs/2403.14950</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in large language models controlling software. It discusses improving the effectiveness of parameter-efficient finetuning for large language models, a method could potentially be used to better control software through these models. However, it doesn't specifically mention controlling web browsers or other computer automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15246" target="_blank">FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions</a></h3>
            <a href="https://arxiv.org/html/2403.15246v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15246v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Orion Weller, Benjamin Chang, Sean MacAvaney, Kyle Lo, Arman Cohan, Benjamin Van Durme, Dawn Lawrie, Luca Soldaini</p>
            <p><strong>Summary:</strong> arXiv:2403.15246v1 Announce Type: cross 
Abstract: Modern Large Language Models (LLMs) are capable of following long and complex instructions that enable a diverse amount of user tasks. However, despite Information Retrieval (IR) models using LLMs as the backbone of their architectures, nearly all of them still only take queries as input, with no instructions. For the handful of recent models that do take instructions, it's unclear how they use them. We introduce our dataset FollowIR, which contains a rigorous instruction evaluation benchmark as well as a training set for helping IR models learn to better follow real-world instructions. FollowIR builds off the long history of the TREC conferences: as TREC provides human annotators with instructions (also known as narratives) to determine document relevance, so should IR models be able to understand and decide relevance based on these detailed instructions. Our evaluation benchmark starts with three deeply judged TREC collections and alters the annotator instructions, re-annotating relevant documents. Through this process, we can measure how well IR models follow instructions, through a new pairwise evaluation framework. Our results indicate that existing retrieval models fail to correctly use instructions, using them for basic keywords and struggling to understand long-form information. However, we show that it is possible for IR models to learn to follow complex instructions: our new FollowIR-7B model has significant improvements (over 13%) after fine-tuning on our training set.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15246">https://arxiv.org/abs/2403.15246</a></p>
            <p><strong>Category:</strong> cs.IR</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in large language models and their applications in information retrieval and task execution. It doesn't propose a new method but introduces a new dataset that could be beneficial in designing more efficient large language model agents.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15250" target="_blank">Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach</a></h3>
            <a href="https://arxiv.org/html/2403.15250v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15250v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kun Sun, Rong Wang, Haitao Liu, Anders S{\o}gaard</p>
            <p><strong>Summary:</strong> arXiv:2403.15250v1 Announce Type: cross 
Abstract: Amidst the rapid evolution of LLMs, the significance of evaluation in comprehending and propelling these models forward is increasingly paramount. Evaluations have revealed that factors such as scaling, training types, architectures and other factors profoundly impact the performance of LLMs. However, the extent and nature of these impacts continue to be subjects of debate because most assessments have been restricted to a limited number of models and data points. Clarifying the effects of these factors on performance scores can be more effectively achieved through a statistical lens. Our study embarks on a thorough re-examination of these LLMs, targeting the inadequacies in current evaluation methods. With the advent of a uniform evaluation framework, our research leverages an expansive dataset of evaluation results, introducing a comprehensive statistical methodology. This includes the application of ANOVA, Tukey HSD tests, GAMM, and clustering technique, offering a robust and transparent approach to deciphering LLM performance data. Contrary to prevailing findings, our results challenge assumptions about emergent abilities and the influence of given training types and architectures in LLMs. These findings furnish new perspectives on the characteristics, intrinsic nature, and developmental trajectories of LLMs. By providing straightforward and reliable methods to scrutinize and reassess LLM performance data, this study contributes a nuanced perspective on LLM efficiency and potentials.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15250">https://arxiv.org/abs/2403.15250</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper provides a comprehensive statistical approach for evaluating LLMs. Though not directly tied to controlling software or web browsers, the insights regarding the efficiency and development trajectories of LLMs might be applicable to your agent-based interests.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2303.02204" target="_blank">KGLiDS: A Platform for Semantic Abstraction, Linking, and Automation of Data Science</a></h3>
            <a href="https://arxiv.org/html/2303.02204v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2303.02204v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Mossad Helali, Niki Monjazeb, Shubham Vashisth, Philippe Carrier, Ahmed Helal, Antonio Cavalcante, Khaled Ammar, Katja Hose, Essam Mansour</p>
            <p><strong>Summary:</strong> arXiv:2303.02204v3 Announce Type: replace 
Abstract: In recent years, we have witnessed the growing interest from academia and industry in applying data science technologies to analyze large amounts of data. In this process, a myriad of artifacts (datasets, pipeline scripts, etc.) are created. However, there has been no systematic attempt to holistically collect and exploit all the knowledge and experiences that are implicitly contained in those artifacts. Instead, data scientists recover information and expertise from colleagues or learn via trial and error. Hence, this paper presents a scalable platform, KGLiDS, that employs machine learning and knowledge graph technologies to abstract and capture the semantics of data science artifacts and their connections. Based on this information, KGLiDS enables various downstream applications, such as data discovery and pipeline automation. Our comprehensive evaluation covers use cases in data discovery, data cleaning, transformation, and AutoML. It shows that KGLiDS is significantly faster with a lower memory footprint than the state-of-the-art systems while achieving comparable or better accuracy.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2303.02204">https://arxiv.org/abs/2303.02204</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is about automation of data science pipelines using machine learning and knowledge graph technologies, a subject matter similar to computer automation using large language models. However, it doesn't specifically mention the use of large language models for control.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.15929" target="_blank">E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity</a></h3>
            <a href="https://arxiv.org/html/2310.15929v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.15929v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yun Li, Lin Niu, Xipeng Zhang, Kai Liu, Jianchen Zhu, Zhanhui Kang</p>
            <p><strong>Summary:</strong> arXiv:2310.15929v2 Announce Type: replace 
Abstract: Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands. For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights. (2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is implemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere GPUs. Extensive experiments on the LLaMA family and OPT models show that E-Sparse can significantly speed up the model inference over the dense model (up to 1.53X) and obtain significant memory saving (up to 43.52%), with acceptable accuracy loss.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.15929">https://arxiv.org/abs/2310.15929</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper proposes a new metric, namely E-Sparse, to improve N:M sparsity in Large Language Models, a topic relevant to the 'agents based on large-language models' category. Though not directly related to browser control or software control using LLMs, the discussed techniques can potentially enhance the efficiency of LLMs for such tasks.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.18598" target="_blank">Generalisable Agents for Neural Network Optimisation</a></h3>
            <a href="https://arxiv.org/html/2311.18598v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2311.18598v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kale-ab Tessera, Callum Rhys Tilbury, Sasha Abramowitz, Ruan de Kock, Omayma Mahjoub, Benjamin Rosman, Sara Hooker, Arnu Pretorius</p>
            <p><strong>Summary:</strong> arXiv:2311.18598v2 Announce Type: replace 
Abstract: Optimising deep neural networks is a challenging task due to complex training dynamics, high computational requirements, and long training times. To address this difficulty, we propose the framework of Generalisable Agents for Neural Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL) approach that learns to improve neural network optimisation by dynamically and responsively scheduling hyperparameters during training. GANNO utilises an agent per layer that observes localised network dynamics and accordingly takes actions to adjust these dynamics at a layerwise level to collectively improve global performance. In this paper, we use GANNO to control the layerwise learning rate and show that the framework can yield useful and responsive schedules that are competitive with handcrafted heuristics. Furthermore, GANNO is shown to perform robustly across a wide variety of unseen initial conditions, and can successfully generalise to harder problems than it was trained on. Our work presents an overview of the opportunities that this paradigm offers for training neural networks, along with key challenges that remain to be overcome.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.18598">https://arxiv.org/abs/2311.18598</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in 'Agents based on large-language models' as it presents a new approach to using agents (specifically a multi-agent reinforcement learning approach) to optimize deep neural networks. While it doesn't directly relate to controlling software/browsers with large language models, it does touch on automation and optimization in the realm of machine learning, which could potentially be adapted or expanded to include large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.15220" target="_blank">ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition</a></h3>
            
            <p><strong>Authors:</strong> Lu Ye, Ze Tao, Yong Huang, Yang Li</p>
            <p><strong>Summary:</strong> arXiv:2402.15220v2 Announce Type: replace 
Abstract: Self-attention is an essential component of large language models(LLMs) but a significant source of inference latency for long sequences. In multi-tenant LLMs serving scenarios, the compute and memory operation cost of self-attention can be optimized by using the probability that multiple LLM requests have shared system prompts in prefixes. In this paper, we introduce ChunkAttention, a prefix-aware self-attention module that can detect matching prompt prefixes across multiple requests and share their key/value tensors in memory at runtime to improve the memory utilization of KV cache. This is achieved by breaking monolithic key/value tensors into smaller chunks and structuring them into the auxiliary prefix tree. Consequently, on top of the prefix-tree based KV cache, we design an efficient self-attention kernel, where a two-phase partition algorithm is implemented to improve the data locality during self-attention computation in the presence of shared system prompts. Experiments show that ChunkAttention can speed up the self-attention kernel by 3.2-4.8$\times$ compared to the start-of-the-art implementation, with the length of the system prompt ranging from 1024 to 4096.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.15220">https://arxiv.org/abs/2402.15220</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> Whilst its focus isn't directly on controlling software/web browsers or automation, the paper discusses improvements in efficiency of large language models, which will impact on those subfields. It proposes a new method (ChunkAttention) for improving self-attention mechanisms in these models, which would be pertinent to your interests in agents based on LLMs.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.08763" target="_blank">Simple and Scalable Strategies to Continually Pre-train Large Language Models</a></h3>
            
            <p><strong>Authors:</strong> Adam Ibrahim, Benjamin Th\'erien, Kshitij Gupta, Mats L. Richter, Quentin Anthony, Timoth\'ee Lesort, Eugene Belilovsky, Irina Rish</p>
            <p><strong>Summary:</strong> arXiv:2403.08763v2 Announce Type: replace 
Abstract: Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.08763">https://arxiv.org/abs/2403.08763</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper discusses strategies to continually pre-train Large Language Models (LLMs), which is relevant to your interest in using LLMs for tasks such as controlling software and web browsers. The paper doesn't specifically address these applications, but the methods it presents could potentially be very useful for them.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2304.14178" target="_blank">mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality</a></h3>
            <a href="https://arxiv.org/html/2304.14178v2/extracted/5488275/logo_new.png" target="_blank"><img src="https://arxiv.org/html/2304.14178v2/extracted/5488275/logo_new.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou</p>
            <p><strong>Summary:</strong> arXiv:2304.14178v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tune a low-rank adaption (LoRA) module on LLM and the abstractor module by freezing the visual knowledge module. We carefully build a visually-related instruction evaluation set OwlEval. Experimental results show that our model outperforms existing multi-modal models, demonstrating mPLUG-Owl's impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. Besides, we observe some unexpected and exciting abilities such as multi-image correlation and scene text understanding, which makes it possible to leverage it for harder real scenarios, such as vision-only document comprehension. Our code, pre-trained model, instruction-tuned models, and evaluation set are available at https://github.com/X-PLUG/mPLUG-Owl. The online demo is available at https://www.modelscope.cn/studios/damo/mPLUG-Owl.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2304.14178">https://arxiv.org/abs/2304.14178</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant because it discusses the development and application of large language models in multimodal scenarios, which pertains to your interest in agents based on large language models, particularly those involving multimodal deep learning. Although it does not specifically address time series or browser control, the new method discussed might be extrapolated to these topics.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.00812" target="_blank">Empowering Autonomous Driving with Large Language Models: A Safety Perspective</a></h3>
            <a href="https://arxiv.org/html/2312.00812v4/x1.png" target="_blank"><img src="https://arxiv.org/html/2312.00812v4/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yixuan Wang, Ruochen Jiao, Sinong Simon Zhan, Chengtian Lang, Chao Huang, Zhaoran Wang, Zhuoran Yang, Qi Zhu</p>
            <p><strong>Summary:</strong> arXiv:2312.00812v4 Announce Type: replace-cross 
Abstract: Autonomous Driving (AD) encounters significant safety hurdles in long-tail unforeseen driving scenarios, largely stemming from the non-interpretability and poor generalization of the deep neural networks within the AD system, particularly in out-of-distribution and uncertain data. To this end, this paper explores the integration of Large Language Models (LLMs) into AD systems, leveraging their robust common-sense knowledge and reasoning abilities. The proposed methodologies employ LLMs as intelligent decision-makers in behavioral planning, augmented with a safety verifier shield for contextual safety learning, for enhancing driving performance and safety. We present two key studies in a simulated environment: an adaptive LLM-conditioned Model Predictive Control (MPC) and an LLM-enabled interactive behavior planning scheme with a state machine. Demonstrating superior performance and safety metrics compared to state-of-the-art approaches, our approach shows the promising potential for using LLMs for autonomous vehicles.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.00812">https://arxiv.org/abs/2312.00812</a></p>
            <p><strong>Category:</strong> cs.AI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is about using Large Language Models in Autonomous Driving systems, which is close to your interest in using such models for software control and automation. Although the specific applications you mentioned aren't addressed, the techniques and insights might be relevant to them.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.09919" target="_blank">Recurrent Drafter for Fast Speculative Decoding in Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2403.09919v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.09919v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Aonan Zhang, Chong Wang, Yi Wang, Xuanyu Zhang, Yunfei Cheng</p>
            <p><strong>Summary:</strong> arXiv:2403.09919v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce an improved approach of speculative decoding aimed at enhancing the efficiency of serving large language models. Our method capitalizes on the strengths of two established techniques: the classic two-model speculative decoding approach, and the more recent single-model approach, Medusa. Drawing inspiration from Medusa, our approach adopts a single-model strategy for speculative decoding. However, our method distinguishes itself by employing a single, lightweight draft head with a recurrent dependency design, akin in essence to the small, draft model uses in classic speculative decoding, but without the complexities of the full transformer architecture. And because of the recurrent dependency, we can use beam search to swiftly filter out undesired candidates with the draft head. The outcome is a method that combines the simplicity of single-model design and avoids the need to create a data-dependent tree attention structure only for inference in Medusa. We empirically demonstrate the effectiveness of the proposed method on several popular open source language models, along with a comprehensive analysis of the trade-offs involved in adopting this approach.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.09919">https://arxiv.org/abs/2403.09919</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper focuses on enhancing the efficiency of large language models, one of your key interests. However, it doesn't directly discuss controlling software or browsers, or computer automation, which is why it's not scored a 5.</p>
        </div>
        </div><div class='timestamp'>Report generated on March 25, 2024 at 09:21:16</div></body></html>