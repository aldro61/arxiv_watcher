
            <html>
            <head>
                <title>Report Generated on March 26, 2024</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .paper-box {
                        background-color: #f0f0f0;
                        margin-bottom: 20px;
                        padding: 15px;
                        border-radius: 5px;
                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    }
                    h1 { text-align: center; }
                    h2 {
                        cursor: pointer;
                        color: #333;
                        border-bottom: 2px solid #666;
                    }
                    a { color: #337ab7; text-decoration: none; }
                    a:hover { text-decoration: underline; }
                    h3 { color: #337ab7; }
                    .timestamp { text-align: center; font-size: small; margin-top: 40px; }
                    .paper-figure {
                        max-width: 200px;
                        border: 1px solid #ddd;
                        border-radius: 4px;
                        padding: 5px;
                        margin-top: 10px;
                    }
                    .papers-container { display: block; padding: 0 18px; }
                </style>
            </head>
            <body>
            <h1>Report for March 26, 2024</h1>
            <script>
                function toggleSection(id) {
                    var x = document.getElementById(id);
                    if (x.style.display === "none") {
                        x.style.display = "block";
                    } else {
                        x.style.display = "none";
                    }
                }
            </script>
            <h2 onclick="toggleSection('section_causality')">Causality</h2><div id='section_causality' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15711" target="_blank">Identifiable Latent Neural Causal Models</a></h3>
            <a href="https://arxiv.org/html/2403.15711v1/extracted/5490232/Figs/MLPGaussian.png" target="_blank"><img src="https://arxiv.org/html/2403.15711v1/extracted/5490232/Figs/MLPGaussian.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yuhang Liu, Zhen Zhang, Dong Gong, Mingming Gong, Biwei Huang, Anton van den Hengel, Kun Zhang, Javen Qinfeng Shi</p>
            <p><strong>Summary:</strong> arXiv:2403.15711v1 Announce Type: new 
Abstract: Causal representation learning seeks to uncover latent, high-level causal representations from low-level observed data. It is particularly good at predictions under unseen distribution shifts, because these shifts can generally be interpreted as consequences of interventions. Hence leveraging {seen} distribution shifts becomes a natural strategy to help identifying causal representations, which in turn benefits predictions where distributions are previously {unseen}. Determining the types (or conditions) of such distribution shifts that do contribute to the identifiability of causal representations is critical. This work establishes a {sufficient} and {necessary} condition characterizing the types of distribution shifts for identifiability in the context of latent additive noise models. Furthermore, we present partial identifiability results when only a portion of distribution shifts meets the condition. In addition, we extend our findings to latent post-nonlinear causal models. We translate our findings into a practical algorithm, allowing for the acquisition of reliable latent causal representations. Our algorithm, guided by our underlying theory, has demonstrated outstanding performance across a diverse range of synthetic and real-world datasets. The empirical observations align closely with the theoretical findings, affirming the robustness and effectiveness of our approach.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15711">https://arxiv.org/abs/2403.15711</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interest as it presents a new method for causal representation learning, using both synthetic and real-world datasets. It specifically focuses on uncovering latent, high-level causal representations from data and provides a practical algorithm guided by its original theoretical findings.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.02695" target="_blank">Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions</a></h3>
            
            <p><strong>Authors:</strong> Simon Bing, Urmi Ninad, Jonas Wahl, Jakob Runge</p>
            <p><strong>Summary:</strong> arXiv:2311.02695v2 Announce Type: replace-cross 
Abstract: The task of inferring high-level causal variables from low-level observations, commonly referred to as causal representation learning, is fundamentally underconstrained. As such, recent works to address this problem focus on various assumptions that lead to identifiability of the underlying latent causal variables. A large corpus of these preceding approaches consider multi-environment data collected under different interventions on the causal model. What is common to virtually all of these works is the restrictive assumption that in each environment, only a single variable is intervened on. In this work, we relax this assumption and provide the first identifiability result for causal representation learning that allows for multiple variables to be targeted by an intervention within one environment. Our approach hinges on a general assumption on the coverage and diversity of interventions across environments, which also includes the shared assumption of single-node interventions of previous works. The main idea behind our approach is to exploit the trace that interventions leave on the variance of the ground truth causal variables and regularizing for a specific notion of sparsity with respect to this trace. In addition to and inspired by our theoretical contributions, we present a practical algorithm to learn causal representations from multi-node interventional data and provide empirical evidence that validates our identifiability results.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.02695">https://arxiv.org/abs/2311.02695</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This research paper explores various facets of your interest in causality and machine learning. Specifically, it delves into causal representation learning, a subtopic you mentioned. It proposes a new approach to causal representation learning that allows multiple variables to be targeted by an intervention within one environment, hence expanding upon known methods.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15499" target="_blank">A Causal Analysis of CO2 Reduction Strategies in Electricity Markets Through Machine Learning-Driven Metalearners</a></h3>
            <a href="https://arxiv.org/html/2403.15499v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15499v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Iman Emtiazi Naeini, Zahra Saberi, Khadijeh Hassanzadeh</p>
            <p><strong>Summary:</strong> arXiv:2403.15499v1 Announce Type: new 
Abstract: This study employs the Causal Machine Learning (CausalML) statistical method to analyze the influence of electricity pricing policies on carbon dioxide (CO2) levels in the household sector. Investigating the causality between potential outcomes and treatment effects, where changes in pricing policies are the treatment, our analysis challenges the conventional wisdom surrounding incentive-based electricity pricing. The study's findings suggest that adopting such policies may inadvertently increase CO2 intensity. Additionally, we integrate a machine learning-based meta-algorithm, reflecting a contemporary statistical approach, to enhance the depth of our causal analysis. The study conducts a comparative analysis of learners X, T, S, and R to ascertain the optimal methods based on the defined question's specified goals and contextual nuances. This research contributes valuable insights to the ongoing dialogue on sustainable development practices, emphasizing the importance of considering unintended consequences in policy formulation.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15499">https://arxiv.org/abs/2403.15499</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper employs a Causal Machine Learning method to analyze the effect of electricity pricing policies on CO2 levels. It is relevant as it involves causal discovery and representation learning within the field of machine learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15500" target="_blank">Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View</a></h3>
            <a href="https://arxiv.org/html/2403.15500v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15500v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Haoyue Dai, Ignavier Ng, Gongxu Luo, Peter Spirtes, Petar Stojanov, Kun Zhang</p>
            <p><strong>Summary:</strong> arXiv:2403.15500v1 Announce Type: cross 
Abstract: Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15500">https://arxiv.org/abs/2403.15500</a></p>
            <p><strong>Category:</strong> q-bio.QM</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant as it discusses the concept of causality in gene regulatory network inference, which seems to be akin to causal discovery. However, it doesn't deal with machine learning or large language models directly.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16031" target="_blank">Learning Directed Acyclic Graphs from Partial Orderings</a></h3>
            <a href="https://arxiv.org/html/2403.16031v1/" target="_blank"><img src="https://arxiv.org/html/2403.16031v1/" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Ali Shojaie, Wenyu Chen</p>
            <p><strong>Summary:</strong> arXiv:2403.16031v1 Announce Type: cross 
Abstract: Directed acyclic graphs (DAGs) are commonly used to model causal relationships among random variables. In general, learning the DAG structure is both computationally and statistically challenging. Moreover, without additional information, the direction of edges may not be estimable from observational data. In contrast, given a complete causal ordering of the variables, the problem can be solved efficiently, even in high dimensions. In this paper, we consider the intermediate problem of learning DAGs when a partial causal ordering of variables is available. We propose a general estimation framework for leveraging the partial ordering and present efficient estimation algorithms for low- and high-dimensional problems. The advantages of the proposed framework are illustrated via numerical studies.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16031">https://arxiv.org/abs/2403.16031</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> The paper titled 'Learning Directed Acyclic Graphs from Partial Orderings' is relevant to your interests as it discusses the process of learning DAG structures, which is a primary concept in causal discovery, one of your subtopics in causality.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16523" target="_blank">Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis</a></h3>
            <a href="https://arxiv.org/html/2403.16523v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.16523v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jie Qiao, Yu Xiang, Zhengming Chen, Ruichu Cai, Zhifeng Hao</p>
            <p><strong>Summary:</strong> arXiv:2403.16523v1 Announce Type: cross 
Abstract: Count data naturally arise in many fields, such as finance, neuroscience, and epidemiology, and discovering causal structure among count data is a crucial task in various scientific and industrial scenarios. One of the most common characteristics of count data is the inherent branching structure described by a binomial thinning operator and an independent Poisson distribution that captures both branching and noise. For instance, in a population count scenario, mortality and immigration contribute to the count, where survival follows a Bernoulli distribution, and immigration follows a Poisson distribution. However, causal discovery from such data is challenging due to the non-identifiability issue: a single causal pair is Markov equivalent, i.e., $X\rightarrow Y$ and $Y\rightarrow X$ are distributed equivalent. Fortunately, in this work, we found that the causal order from $X$ to its child $Y$ is identifiable if $X$ is a root vertex and has at least two directed paths to $Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed path to $Y$ without passing $X$. Specifically, we propose a Poisson Branching Structure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using high-order cumulants. Theoretical results establish the connection between the path and cumulant and demonstrate that the path information can be obtained from the cumulant. With the path information, causal order is identifiable under some graphical conditions. A practical algorithm for learning causal structure under PB-SCM is proposed and the experiments demonstrate and verify the effectiveness of the proposed method.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16523">https://arxiv.org/abs/2403.16523</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper could be quite relevant to your interests as it is centered on the topic of causal discovery, specifically within the context of count data. Methodologically, it proposes a novel model called the Poisson Branching Structure Causal Model (PB-SCM), and an associated practical algorithm for learning causal structure. However, it doesn't cover the aspect of large language models in causal discovery.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2304.01391" target="_blank">Counterfactual Learning on Graphs: A Survey</a></h3>
            
            <p><strong>Authors:</strong> Zhimeng Guo, Teng Xiao, Zongyu Wu, Charu Aggarwal, Hui Liu, Suhang Wang</p>
            <p><strong>Summary:</strong> arXiv:2304.01391v2 Announce Type: replace 
Abstract: Graph-structured data are pervasive in the real-world such as social networks, molecular graphs and transaction networks. Graph neural networks (GNNs) have achieved great success in representation learning on graphs, facilitating various downstream tasks. However, GNNs have several drawbacks such as lacking interpretability, can easily inherit the bias of data and cannot model casual relations. Recently, counterfactual learning on graphs has shown promising results in alleviating these drawbacks. Various approaches have been proposed for counterfactual fairness, explainability, link prediction and other applications on graphs. To facilitate the development of this promising direction, in this survey, we categorize and comprehensively review papers on graph counterfactual learning. We divide existing methods into four categories based on problems studied. For each category, we provide background and motivating examples, a general framework summarizing existing works and a detailed review of these works. We point out promising future research directions at the intersection of graph-structured data, counterfactual learning, and real-world applications. To offer a comprehensive view of resources for future studies, we compile a collection of open-source implementations, public datasets, and commonly-used evaluation metrics. This survey aims to serve as a ``one-stop-shop'' for building a unified understanding of graph counterfactual learning categories and current resources. We also maintain a repository for papers and resources and will keep updating the repository https://github.com/TimeLovercc/Awesome-Graph-Causal-Learning.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2304.01391">https://arxiv.org/abs/2304.01391</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper would be relevant to your interests in causality and machine learning. It reviews various approaches for counterfactual learning on graphs and suggests promising future research directions in this area. Although the paper does not focus on new methods, it gives a comprehensive survey that should be valuable for your research.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.05884" target="_blank">A Meta-Learning Perspective on Transformers for Causal Language Modeling</a></h3>
            <a href="https://arxiv.org/html/2310.05884v2/extracted/5493393/latex/images/clustering_sgd_val_f1.png" target="_blank"><img src="https://arxiv.org/html/2310.05884v2/extracted/5493393/latex/images/clustering_sgd_val_f1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xinbo Wu, Lav R. Varshney</p>
            <p><strong>Summary:</strong> arXiv:2310.05884v2 Announce Type: replace 
Abstract: The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process within the Transformer. Further, within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models. Our analysis is supported by experiments in various settings.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.05884">https://arxiv.org/abs/2310.05884</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant for your interest in causal discovery and the use of large language models in causal discovery. Despite it doesn't propose a new method, it provides a detailed analysis on how transformers, which are a type of large language models, work for the causal language modeling task. This may give you insights into their role in causal discovery.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2306.06721" target="_blank">Differentially Private Conditional Independence Testing</a></h3>
            <a href="https://arxiv.org/html/2306.06721v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2306.06721v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Iden Kalemaj, Shiva Prasad Kasiviswanathan, Aaditya Ramdas</p>
            <p><strong>Summary:</strong> arXiv:2306.06721v3 Announce Type: replace-cross 
Abstract: Conditional independence (CI) tests are widely used in statistical data analysis, e.g., they are the building block of many algorithms for causal graph discovery. The goal of a CI test is to accept or reject the null hypothesis that $X \perp \!\!\! \perp Y \mid Z$, where $X \in \mathbb{R}, Y \in \mathbb{R}, Z \in \mathbb{R}^d$. In this work, we investigate conditional independence testing under the constraint of differential privacy. We design two private CI testing procedures: one based on the generalized covariance measure of Shah and Peters (2020) and another based on the conditional randomization test of Cand\`es et al. (2016) (under the model-X assumption). We provide theoretical guarantees on the performance of our tests and validate them empirically. These are the first private CI tests with rigorous theoretical guarantees that work for the general case when $Z$ is continuous.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2306.06721">https://arxiv.org/abs/2306.06721</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> The paper is about the use of Conditional Independence (CI) tests in statistical data analysis which are often used in algorithms for causal graph discovery. This is relevant to your interest in causal discovery. The paper also proposes new privacy-conscious methods for CI testing which can be considered a new method in the scope of causality and machine learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2309.13339" target="_blank">Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic</a></h3>
            <a href="https://arxiv.org/html/2309.13339v3/" target="_blank"><img src="https://arxiv.org/html/2309.13339v3/" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xufeng Zhao, Mengdi Li, Wenhao Lu, Cornelius Weber, Jae Hee Lee, Kun Chu, Stefan Wermter</p>
            <p><strong>Summary:</strong> arXiv:2309.13339v3 Announce Type: replace-cross 
Abstract: Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts), a self-improvement prompting framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of enhanced reasoning by logic. The implementation code for LoT can be accessed at: \url{https://github.com/xf-zhao/LoT}.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2309.13339">https://arxiv.org/abs/2309.13339</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in causality and large language models. The reason is, it discusses enhancing reasoning abilities of large language models using principles rooted in symbolic logic, which can be connected to causal inference.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.02760" target="_blank">Causal Question Answering with Reinforcement Learning</a></h3>
            
            <p><strong>Authors:</strong> Lukas Bl\"ubaum, Stefan Heindorf</p>
            <p><strong>Summary:</strong> arXiv:2311.02760v2 Announce Type: replace-cross 
Abstract: Causal questions inquire about causal relationships between different events or phenomena. They are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with a causality graph, a large-scale dataset of causal relations between noun phrases along with the relations' provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on a causality graph for causal question answering. We introduce an Actor-Critic-based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sparse rewards. Our evaluation shows that the agent successfully prunes the search space to answer binary causal questions by visiting less than 30 nodes per question compared to over 3,000 nodes by a naive breadth-first search. Our ablation study indicates that our supervised learning strategy provides a strong foundation upon which our reinforcement learning agent improves. The paths returned by our agent explain the mechanisms by which a cause produces an effect. Moreover, for each edge on a path, our causality graph provides its original source allowing for easy verification of paths.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.02760">https://arxiv.org/abs/2311.02760</a></p>
            <p><strong>Category:</strong> cs.AI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interests because it proposes a new reinforcement learning method for answering causal questions using a causality graph, which falls within your subtopic of interest in causal discovery.</p>
        </div>
        </div><h2 onclick="toggleSection('section_time-series')">Time-series</h2><div id='section_time-series' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.01327" target="_blank">TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series</a></h3>
            <a href="https://arxiv.org/html/2310.01327v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.01327v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Arjun Ashok, \'Etienne Marcotte, Valentina Zantedeschi, Nicolas Chapados, Alexandre Drouin</p>
            <p><strong>Summary:</strong> arXiv:2310.01327v2 Announce Type: replace 
Abstract: We introduce a new model for multivariate probabilistic time series prediction, designed to flexibly address a range of tasks including forecasting, interpolation, and their combinations. Building on copula theory, we propose a simplified objective for the recently-introduced transformer-based attentional copulas (TACTiS), wherein the number of distributional parameters now scales linearly with the number of variables instead of factorially. The new objective requires the introduction of a training curriculum, which goes hand-in-hand with necessary changes to the original architecture. We show that the resulting model has significantly better training dynamics and achieves state-of-the-art performance across diverse real-world forecasting tasks, while maintaining the flexibility of prior work, such as seamless handling of unaligned and unevenly-sampled time series. Code is made available at https://github.com/ServiceNow/TACTiS.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.01327">https://arxiv.org/abs/2310.01327</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is very relevant to your interests as it introduces a new transformer-based model for prediction in multivariate time series, directly satisfying your interest in new transformer-like models and methods for time series forecasting.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.11959" target="_blank">A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis</a></h3>
            <a href="https://arxiv.org/html/2310.11959v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.11959v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Shuhan Zhong, Sizhe Song, Weipeng Zhuo, Guanyao Li, Yang Liu, S. -H. Gary Chan</p>
            <p><strong>Summary:</strong> arXiv:2310.11959v2 Announce Type: replace 
Abstract: Time series data, including univariate and multivariate ones, are characterized by unique composition and complex multi-scale temporal variations. They often require special consideration of decomposition and multi-scale modeling to analyze. Existing deep learning methods on this best fit to univariate time series only, and have not sufficiently considered sub-series modeling and decomposition completeness. To address these challenges, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer, which learns to explicitly decompose and represent the input time series in its different layers. To handle the multi-scale temporal patterns and multivariate dependencies, we propose a novel temporal patching approach to model the time series as multi-scale patches, and employ MLPs to capture intra- and inter-patch variations and channel-wise correlations. In addition, we propose a novel loss function to constrain both the mean and the autocorrelation of the decomposition residual for better decomposition completeness. Through extensive experiments on various real-world datasets for five common time series analysis tasks, we demonstrate that MSD-Mixer consistently and significantly outperforms other state-of-the-art algorithms with better efficiency.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.11959">https://arxiv.org/abs/2310.11959</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interests as it proposes a new deep learning method (MSD-Mixer) for time series analysis, including temporal patterns and multivariate dependencies. Additionally, it offers a novel loss function to better handle decomposition completeness, aligns with your interest in new foundation models and methods for time series.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16108" target="_blank">A Transformer approach for Electricity Price Forecasting</a></h3>
            <a href="https://arxiv.org/html/2403.16108v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.16108v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Oscar Llorente Gonzalez, Jose Portela</p>
            <p><strong>Summary:</strong> arXiv:2403.16108v1 Announce Type: new 
Abstract: This paper presents a novel approach to electricity price forecasting (EPF) using a pure Transformer model. As opposed to other alternatives, no other recurrent network is used in combination to the attention mechanism. Hence, showing that the attention layer is enough for capturing the temporal patterns. The paper also provides fair comparison of the models using the open-source EPF toolbox and provide the code to enhance reproducibility and transparency in EPF research. The results show that the Transformer model outperforms traditional methods, offering a promising solution for reliable and sustainable power system operation.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16108">https://arxiv.org/abs/2403.16108</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper aligns well with your interest in 'Transformer-like models for time series.' It proposes a new transformer model for electricity price forecasting which could be thought of as a kind of 'time series data'. Please note that while it does involve a novel usage of transformer models on time series data, it's aimed more towards practical applications and not proposing a completely new model or method.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16377" target="_blank">Real-time Adaptation for Condition Monitoring Signal Prediction using Label-aware Neural Processes</a></h3>
            <a href="https://arxiv.org/html/2403.16377v1/extracted/5491107/figs/NP.png" target="_blank"><img src="https://arxiv.org/html/2403.16377v1/extracted/5491107/figs/NP.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Seokhyun Chung, Raed Al Kontar</p>
            <p><strong>Summary:</strong> arXiv:2403.16377v1 Announce Type: new 
Abstract: Building a predictive model that rapidly adapts to real-time condition monitoring (CM) signals is critical for engineering systems/units. Unfortunately, many current methods suffer from a trade-off between representation power and agility in online settings. For instance, parametric methods that assume an underlying functional form for CM signals facilitate efficient online prediction updates. However, this simplification leads to vulnerability to model specifications and an inability to capture complex signals. On the other hand, approaches based on over-parameterized or non-parametric models can excel at explaining complex nonlinear signals, but real-time updates for such models pose a challenging task. In this paper, we propose a neural process-based approach that addresses this trade-off. It encodes available observations within a CM signal into a representation space and then reconstructs the signal's history and evolution for prediction. Once trained, the model can encode an arbitrary number of observations without requiring retraining, enabling on-the-spot real-time predictions along with quantified uncertainty and can be readily updated as more online data is gathered. Furthermore, our model is designed to incorporate qualitative information (i.e., labels) from individual units. This integration not only enhances individualized predictions for each unit but also enables joint inference for both signals and their associated labels. Numerical studies on both synthetic and real-world data in reliability engineering highlight the advantageous features of our model in real-time adaptation, enhanced signal prediction with uncertainty quantification, and joint prediction for labels and signals.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16377">https://arxiv.org/abs/2403.16377</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper proposes a new method for time series prediction focusing on real-time adaptation, especially in the context of condition monitoring signals. Although it does not directly mention the use of deep learning, it introduces a neural process-based approach which falls under the larger umbrella of machine learning. It does not however explicitly mention being a foundation model or being multimodal or transformer-like. </p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16495" target="_blank">LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural Network for Traffic Flow Forecasting</a></h3>
            <a href="https://arxiv.org/html/2403.16495v1/extracted/5493108/intro.png" target="_blank"><img src="https://arxiv.org/html/2403.16495v1/extracted/5493108/intro.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Qinyao Luo, Silu He, Xing Han, Yuhan Wang, Haifeng Li</p>
            <p><strong>Summary:</strong> arXiv:2403.16495v1 Announce Type: new 
Abstract: Accurate traffic forecasting is a fundamental problem in intelligent transportation systems and learning long-range traffic representations with key information through spatiotemporal graph neural networks (STGNNs) is a basic assumption of current traffic flow prediction models. However, due to structural limitations, existing STGNNs can only utilize short-range traffic flow data; therefore, the models cannot adequately learn the complex trends and periodic features in traffic flow. Besides, it is challenging to extract the key temporal information from the long historical traffic series and obtain a compact representation. To solve the above problems, we propose a novel LSTTN (Long-Short Term Transformer-based Network) framework comprehensively considering the long- and short-term features in historical traffic flow. First, we employ a masked subseries Transformer to infer the content of masked subseries from a small portion of unmasked subseries and their temporal context in a pretraining manner, forcing the model to efficiently learn compressed and contextual subseries temporal representations from long historical series. Then, based on the learned representations, long-term trend is extracted by using stacked 1D dilated convolution layers, and periodic features are extracted by dynamic graph convolution layers. For the difficulties in making time-step level prediction, LSTTN adopts a short-term trend extractor to learn fine-grained short-term temporal features. Finally, LSTTN fuses the long-term trend, periodic features and short-term features to obtain the prediction results. Experiments on four real-world datasets show that in 60-minute-ahead long-term forecasting, the LSTTN model achieves a minimum improvement of 5.63\% and a maximum improvement of 16.78\% over baseline models. The source code is available at https://github.com/GeoX-Lab/LSTTN.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16495">https://arxiv.org/abs/2403.16495</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is relevant because it introduces a new deep learning model (called LSTTN) for long-range traffic forecasting, a type of time series forecasting. It also discusses a new technique of learning temporal features from long historical series, which could be interesting for your request regarding new deep learning methods for time series. However, it focuses on a specific application (traffic flow forecasting), which is why it doesn't get a perfect score.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16899" target="_blank">State Space Models as Foundation Models: A Control Theoretic Overview</a></h3>
            <a href="https://arxiv.org/html/2403.16899v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.16899v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Carmen Amo Alonso, Jerome Sieber, Melanie N. Zeilinger</p>
            <p><strong>Summary:</strong> arXiv:2403.16899v1 Announce Type: cross 
Abstract: In recent years, there has been a growing interest in integrating linear state-space models (SSM) in deep neural network architectures of foundation models. This is exemplified by the recent success of Mamba, showing better performance than the state-of-the-art Transformer architectures in language tasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a latent space in order to learn a compressed representation of the data. The same goal has been pursued by control theorists using SSMs to efficiently model dynamical systems. Therefore, SSMs can be naturally connected to deep sequence modeling, offering the opportunity to create synergies between the corresponding research areas. This paper is intended as a gentle introduction to SSM-based architectures for control theorists and summarizes the latest research developments. It provides a systematic review of the most successful SSM proposals and highlights their main features from a control theoretic perspective. Additionally, we present a comparative analysis of these models, evaluating their performance on a standardized benchmark designed for assessing a model's efficiency at learning long sequences.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16899">https://arxiv.org/abs/2403.16899</a></p>
            <p><strong>Category:</strong> eess.SY</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper focuses on the integration of linear state-space models in deep neural network architectures of foundation models, which relates to your interest in new foundation models for time series. However, it does not provide detailed information specifically about time series forecasting, hence the score of 4 instead of 5.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2301.12528" target="_blank">Sequential Estimation of Gaussian Process-based Deep State-Space Models</a></h3>
            <a href="https://arxiv.org/html/2301.12528v2/extracted/5491216/AQ/ci.png" target="_blank"><img src="https://arxiv.org/html/2301.12528v2/extracted/5491216/AQ/ci.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yuhao Liu, Marzieh Ajirak, Petar Djuric</p>
            <p><strong>Summary:</strong> arXiv:2301.12528v2 Announce Type: replace 
Abstract: We consider the problem of sequential estimation of the unknowns of state-space and deep state-space models that include estimation of functions and latent processes of the models. The proposed approach relies on Gaussian and deep Gaussian processes that are implemented via random feature-based Gaussian processes. In these models, we have two sets of unknowns, highly nonlinear unknowns (the values of the latent processes) and conditionally linear unknowns (the constant parameters of the random feature-based Gaussian processes). We present a method based on particle filtering where the parameters of the random feature-based Gaussian processes are integrated out in obtaining the predictive density of the states and do not need particles. We also propose an ensemble version of the method, with each member of the ensemble having its own set of features. With several experiments, we show that the method can track the latent processes up to a scale and rotation.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2301.12528">https://arxiv.org/abs/2301.12528</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper seems to be relevant to your interest in 'new deep learning methods for time series'. It discusses the integration of Gaussian Processes into state-space models to forecast time series data.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2401.17548" target="_blank">Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators</a></h3>
            <a href="https://arxiv.org/html/2401.17548v3/training_sample.pdf" target="_blank"><img src="https://arxiv.org/html/2401.17548v3/training_sample.pdf" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Lifan Zhao, Yanyan Shen</p>
            <p><strong>Summary:</strong> arXiv:2401.17548v3 Announce Type: replace 
Abstract: Recently, channel-independent methods have achieved state-of-the-art performance in multivariate time series (MTS) forecasting. Despite reducing overfitting risks, these methods miss potential opportunities in utilizing channel dependence for accurate predictions. We argue that there exist locally stationary lead-lag relationships between variates, i.e., some lagged variates may follow the leading indicators within a short time period. Exploiting such channel dependence is beneficial since leading indicators offer advance information that can be used to reduce the forecasting difficulty of the lagged variates. In this paper, we propose a new method named LIFT that first efficiently estimates leading indicators and their leading steps at each time step and then judiciously allows the lagged variates to utilize the advance information from leading indicators. LIFT plays as a plugin that can be seamlessly collaborated with arbitrary time series forecasting methods. Extensive experiments on six real-world datasets demonstrate that LIFT improves the state-of-the-art methods by 5.5% in average forecasting performance. Our code is available at https://github.com/SJTU-Quant/LIFT.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2401.17548">https://arxiv.org/abs/2401.17548</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interest in time series and deep learning, as it presents a new method (LIFT) for time series forecasting, which makes use of channel dependence. However, it does not seem to specifically involve deep learning or transformer-like models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.02023" target="_blank">Self-Supervised Contrastive Learning for Long-term Forecasting</a></h3>
            <a href="https://arxiv.org/html/2402.02023v2/" target="_blank"><img src="https://arxiv.org/html/2402.02023v2/" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Junwoo Park, Daehoon Gwak, Jaegul Choo, Edward Choi</p>
            <p><strong>Summary:</strong> arXiv:2402.02023v2 Announce Type: replace 
Abstract: Long-term forecasting presents unique challenges due to the time and memory complexity of handling long sequences. Existing methods, which rely on sliding windows to process long sequences, struggle to effectively capture long-term variations that are partially caught within the short window (i.e., outer-window variations). In this paper, we introduce a novel approach that overcomes this limitation by employing contrastive learning and enhanced decomposition architecture, specifically designed to focus on long-term variations. To this end, our contrastive loss incorporates global autocorrelation held in the whole time series, which facilitates the construction of positive and negative pairs in a self-supervised manner. When combined with our decomposition networks, our contrastive learning significantly improves long-term forecasting performance. Extensive experiments demonstrate that our approach outperforms 14 baseline models in multiple experiments over nine long-term benchmarks, especially in challenging scenarios that require a significantly long output for forecasting. Source code is available at https://github.com/junwoopark92/Self-Supervised-Contrastive-Forecsating.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.02023">https://arxiv.org/abs/2402.02023</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is relevant because it proposes a new approach that blends self-supervised contrastive learning with a decomposition architecture specifically for long-term time series forecasting, thereby aligning with your interest in new deep learning methods for time series.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.11922" target="_blank">Spatio-Temporal Few-Shot Learning via Diffusive Neural Network Generation</a></h3>
            <a href="https://arxiv.org/html/2402.11922v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2402.11922v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yuan Yuan, Chenyang Shao, Jingtao Ding, Depeng Jin, Yong Li</p>
            <p><strong>Summary:</strong> arXiv:2402.11922v3 Announce Type: replace 
Abstract: Spatio-temporal modeling is foundational for smart city applications, yet it is often hindered by data scarcity in many cities and regions. To bridge this gap, we propose a novel generative pre-training framework, GPD, for spatio-temporal few-shot learning with urban knowledge transfer. Unlike conventional approaches that heavily rely on common feature extraction or intricate few-shot learning designs, our solution takes a novel approach by performing generative pre-training on a collection of neural network parameters optimized with data from source cities. We recast spatio-temporal few-shot learning as pre-training a generative diffusion model, which generates tailored neural networks guided by prompts, allowing for adaptability to diverse data distributions and city-specific characteristics. GPD employs a Transformer-based denoising diffusion model, which is model-agnostic to integrate with powerful spatio-temporal neural networks. By addressing challenges arising from data gaps and the complexity of generalizing knowledge across cities, our framework consistently outperforms state-of-the-art baselines on multiple real-world datasets for tasks such as traffic speed prediction and crowd flow prediction. The implementation of our approach is available: https://github.com/tsinghua-fib-lab/GPD.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.11922">https://arxiv.org/abs/2402.11922</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper introduces a new approach, a generative pre-training framework (GPD), for spatio-temporal few-shot learning. It specifically relates to your interest in new deep learning methods and foundation models for time series, although the focus is not specifically on forecasting.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.11722" target="_blank">Time Series Compression using Quaternion Valued Neural Networks and Quaternion Backpropagation</a></h3>
            
            <p><strong>Authors:</strong> Johannes P\"oppelbaum, Andreas Schwung</p>
            <p><strong>Summary:</strong> arXiv:2403.11722v2 Announce Type: replace 
Abstract: We propose a novel quaternionic time-series compression methodology where we divide a long time-series into segments of data, extract the min, max, mean and standard deviation of these chunks as representative features and encapsulate them in a quaternion, yielding a quaternion valued time-series. This time-series is processed using quaternion valued neural network layers, where we aim to preserve the relation between these features through the usage of the Hamilton product. To train this quaternion neural network, we derive quaternion backpropagation employing the GHR calculus, which is required for a valid product and chain rule in quaternion space. Furthermore, we investigate the connection between the derived update rules and automatic differentiation. We apply our proposed compression method on the Tennessee Eastman Dataset, where we perform fault classification using the compressed data in two settings: a fully supervised one and in a semi supervised, contrastive learning setting. Both times, we were able to outperform real valued counterparts as well as two baseline models: one with the uncompressed time-series as the input and the other with a regular downsampling using the mean. Further, we could improve the classification benchmark set by SimCLR-TS from 81.43% to 83.90%.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.11722">https://arxiv.org/abs/2403.11722</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper could be relevant to your interests as it proposes a novel quaternionic time-series methodology and thus, corresponds with your interest in new deep learning methods for time series.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.13841" target="_blank">Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting</a></h3>
            <a href="https://arxiv.org/html/2403.13841v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.13841v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Zhongqi Yang, Yuning Wang, Ken S. Yamashita, Maryam Sabah, Elahe Khatibi, Iman Azimi, Nikil Dutt, Jessica L. Borelli, Amir M. Rahmani</p>
            <p><strong>Summary:</strong> arXiv:2403.13841v2 Announce Type: replace 
Abstract: Emotional states, as indicators of affect, are pivotal to overall health, making their accurate prediction before onset crucial. Current studies are primarily centered on immediate short-term affect detection using data from wearable and mobile devices. These studies typically focus on objective sensory measures, often neglecting other forms of self-reported information like diaries and notes. In this paper, we propose a multimodal deep learning model for affect status forecasting. This model combines a transformer encoder with a pre-trained language model, facilitating the integrated analysis of objective metrics and self-reported diaries. To validate our model, we conduct a longitudinal study, enrolling college students and monitoring them over a year, to collect an extensive dataset including physiological, environmental, sleep, metabolic, and physical activity parameters, alongside open-ended textual diaries provided by the participants. Our results demonstrate that the proposed model achieves predictive accuracy of 82.50% for positive affect and 82.76% for negative affect, a full week in advance. The effectiveness of our model is further elevated by its explainability.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.13841">https://arxiv.org/abs/2403.13841</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> Although the paper focuses on affect status forecasting, it introduces a new multimodal deep learning model for time series that combines a transformer encoder with a pre-trained language model. This meets your interest in new multimodal deep learning models for time series forecasting.</p>
        </div>
        </div><h2 onclick="toggleSection('section_llm-agents')">Llm-agents</h2><div id='section_llm-agents' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16354" target="_blank">ChatDBG: An AI-Powered Debugging Assistant</a></h3>
            <a href="https://arxiv.org/html/2403.16354v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.16354v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kyla Levin, Nicolas van Kempen, Emery D. Berger, Stephen N. Freund</p>
            <p><strong>Summary:</strong> arXiv:2403.16354v1 Announce Type: cross 
Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded nearly 30,000 times.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16354">https://arxiv.org/abs/2403.16354</a></p>
            <p><strong>Category:</strong> cs.SE</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This research paper is highly relevant to your interests as it details the use of large language models in controlling software and enhancing debugging capabilities. It introduces ChatDBG, which uses LLMs to analyze and explain bugs, showcasing the practical use of LLMs in automating programming processes.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16843" target="_blank">Do LLM Agents Have Regret? A Case Study in Online Learning and Games</a></h3>
            
            <p><strong>Authors:</strong> Chanwoo Park, Xiangyu Liu, Asuman Ozdaglar, Kaiqing Zhang</p>
            <p><strong>Summary:</strong> arXiv:2403.16843v1 Announce Type: new 
Abstract: Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of \emph{regret}. We first empirically study the {no-regret} behaviors of LLMs in canonical (non-stationary) online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behaviors of LLM agents, under certain assumptions on the supervised pre-training and the rationality model of human decision-makers who generate the data. Notably, we also identify (simple) cases where advanced LLMs such as GPT-4 fail to be no-regret. To promote the no-regret behaviors, we propose a novel \emph{unsupervised} training loss of \emph{regret-loss}, which, in contrast to the supervised pre-training loss, does not require the labels of (optimal) actions. We then establish the statistical guarantee of generalization bound for regret-loss minimization, followed by the optimization guarantee that minimizing such a loss may automatically lead to known no-regret learning algorithms. Our further experiments demonstrate the effectiveness of our regret-loss, especially in addressing the above ``regrettable'' cases.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16843">https://arxiv.org/abs/2403.16843</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper investigates Large Language Model (LLM) based autonomous agents, specifically their performance in decision-making settings which aligns with your interests in using large language models to control software/web browsers and for automation. However, it doesn't specifically study controlling software or web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15464" target="_blank">LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction</a></h3>
            <a href="https://arxiv.org/html/2403.15464v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15464v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Hejie Cui, Zhuocheng Shen, Jieyu Zhang, Hui Shao, Lianhui Qin, Joyce C. Ho, Carl Yang</p>
            <p><strong>Summary:</strong> arXiv:2403.15464v1 Announce Type: cross 
Abstract: Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs can achieve decent few-shot performance compared to traditional supervised learning methods in EHR-based disease predictions, suggesting its potential for health-oriented applications.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15464">https://arxiv.org/abs/2403.15464</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper explores using large language models and proposing a method to convert detailed patient data into natural language, which is highly relevant to your interest in utilizing LLMs for software control - in this case, for electronic health records. While it's slightly tangential as it involves applications in health, the method proposed can be of use to explore foundational applications.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15484" target="_blank">RakutenAI-7B: Extending Large Language Models for Japanese</a></h3>
            
            <p><strong>Authors:</strong>  Rakuten Group, Aaron Levine, Connie Huang, Chenguang Wang, Eduardo Batista, Ewa Szymanska, Hongyi Ding, Hou Wei Chou, Jean-Fran\c{c}ois Pessiot, Johanes Effendi, Justin Chiu, Kai Torben Ohlhus, Karan Chopra, Keiji Shinzato, Koji Murakami, Lee Xiong, Lei Chen, Maki Kubota, Maksim Tkachenko, Miroku Lee, Naoki Takahashi, Prathyusha Jwalapuram, Ryutaro Tatsushima, Saurabh Jain, Sunil Kumar Yadav, Ting Cai, Wei-Te Chen, Yandi Xia, Yuki Nakayama, Yutaka Higashiyama</p>
            <p><strong>Summary:</strong> arXiv:2403.15484v1 Announce Type: cross 
Abstract: We introduce RakutenAI-7B, a suite of Japanese-oriented large language models that achieve the best performance on the Japanese LM Harness benchmarks among the open 7B models. Along with the foundation model, we release instruction- and chat-tuned models, RakutenAI-7B-instruct and RakutenAI-7B-chat respectively, under the Apache 2.0 license.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15484">https://arxiv.org/abs/2403.15484</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper presents RakutenAI-7B, a suite of Japanese-based large language models which include instruction- and chat-tuned models. This paper might be useful in understanding how large language models work and can be tuned for specific tasks, which aligns well with your interest in using large language models for controlling software.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15796" target="_blank">Understanding Emergent Abilities of Language Models from the Loss Perspective</a></h3>
            
            <p><strong>Authors:</strong> Zhengxiao Du, Aohan Zeng, Yuxiao Dong, Jie Tang</p>
            <p><strong>Summary:</strong> arXiv:2403.15796v1 Announce Type: cross 
Abstract: Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) there is doubt on the discontinuous metrics used to measure these abilities. In this paper, we propose to study emergent abilities in the lens of pre-training loss, instead of model size or training compute. We demonstrate that the models with the same pre-training loss, but different model and data sizes, generate the same performance on various downstream tasks. We also discover that a model exhibits emergent abilities on certain tasks -- regardless of the continuity of metrics -- when its pre-training loss falls below a specific threshold. Before reaching this threshold, its performance remains at the level of random guessing. This inspires us to redefine emergent abilities as those that manifest in models with lower pre-training losses, highlighting that these abilities cannot be predicted by merely extrapolating the performance trends of models with higher pre-training losses.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15796">https://arxiv.org/abs/2403.15796</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper might be of interest to you, because it discusses the emergent abilities of language models which can be beneficial in controlling software or automating tasks using large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15886" target="_blank">Leveraging Zero-Shot Prompting for Efficient Language Model Distillation</a></h3>
            <a href="https://arxiv.org/html/2403.15886v1/extracted/5490966/step_by_step.png" target="_blank"><img src="https://arxiv.org/html/2403.15886v1/extracted/5490966/step_by_step.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Lukas V\"oge, Vincent Gurgul, Stefan Lessmann</p>
            <p><strong>Summary:</strong> arXiv:2403.15886v1 Announce Type: cross 
Abstract: This paper introduces a novel approach for efficiently distilling LLMs into smaller, application-specific models, significantly reducing operational costs and manual labor. Addressing the challenge of deploying computationally intensive LLMs in specific applications or edge devices, this technique utilizes LLMs' reasoning capabilities to generate labels and natural language rationales for unlabeled data. Our approach enhances both finetuning and distillation by employing a multi-task training framework where student models mimic these rationales alongside teacher predictions. Key contributions include the employment of zero-shot prompting to elicit teacher model rationales, reducing the necessity for handcrafted few-shot examples and lowering the overall token count required, which directly translates to cost savings given the pay-per-token billing model of major tech companies' LLM APIs. Additionally, the paper investigates the impact of explanation properties on distillation efficiency, demonstrating that minimal performance loss occurs even when rationale augmentation is not applied across the entire dataset, facilitating further reductions of tokens. This research marks a step toward the efficient training of task-specific models with minimal human intervention, offering substantial cost-savings while maintaining, or even enhancing, performance.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15886">https://arxiv.org/abs/2403.15886</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper is relevant to your interest in agents based on large language models. It explores how to make LLMs more accessible and efficient, particularly in specific applications or edge devices. However, it doesn't directly discuss LLM control of software or web browsers, hence the score of 4.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.15938" target="_blank">LlamBERT: Large-scale low-cost data annotation in NLP</a></h3>
            <a href="https://arxiv.org/html/2403.15938v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.15938v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> B\'alint Csan\'ady, Lajos Muzsai, P\'eter Vedres, Zolt\'an N\'adasdy, Andr\'as Luk\'acs</p>
            <p><strong>Summary:</strong> arXiv:2403.15938v1 Announce Type: cross 
Abstract: Large Language Models (LLMs), such as GPT-4 and Llama 2, show remarkable proficiency in a wide range of natural language processing (NLP) tasks. Despite their effectiveness, the high costs associated with their use pose a challenge. We present LlamBERT, a hybrid approach that leverages LLMs to annotate a small subset of large, unlabeled databases and uses the results for fine-tuning transformer encoders like BERT and RoBERTa. This strategy is evaluated on two diverse datasets: the IMDb review dataset and the UMLS Meta-Thesaurus. Our results indicate that the LlamBERT approach slightly compromises on accuracy while offering much greater cost-effectiveness.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.15938">https://arxiv.org/abs/2403.15938</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The research paper is about the utilization of large language models for data annotation tasks in natural language processing, which is indirectly related to your interest in large language models for controlling software or web browsers or for computer automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16087" target="_blank">LLMs as Compiler for Arabic Programming Language</a></h3>
            <a href="https://arxiv.org/html/2403.16087v1/extracted/5491777/figures/modelarc.jpeg" target="_blank"><img src="https://arxiv.org/html/2403.16087v1/extracted/5491777/figures/modelarc.jpeg" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Serry Sibaee, Omar Najar, Lahouri Ghouti, Anis Koubaa</p>
            <p><strong>Summary:</strong> arXiv:2403.16087v1 Announce Type: cross 
Abstract: In this paper we introduce APL (Arabic Programming Language) that uses Large language models (LLM) as semi-compiler to covert Arabic text code to python code then run the code. Designing a full pipeline from the structure of the APL text then a prompt (using prompt engineering) then running the prodcued python code using PyRunner. This project has a three parts first python library, a playground with simple interface and this research paper.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16087">https://arxiv.org/abs/2403.16087</a></p>
            <p><strong>Category:</strong> cs.SE</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in large language models and their applications in controlling software, as it discusses the usage of a LLM as a semi-compiler to convert Arabic text code to Python code.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16218" target="_blank">CoverUp: Coverage-Guided LLM-Based Test Generation</a></h3>
            <a href="https://arxiv.org/html/2403.16218v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.16218v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Juan Altmayer Pizzorno, Emery D. Berger</p>
            <p><strong>Summary:</strong> arXiv:2403.16218v1 Announce Type: cross 
Abstract: This paper presents CoverUp, a novel system that drives the generation of high-coverage Python regression tests via a combination of coverage analysis and large-language models (LLMs). CoverUp iteratively improves coverage, interleaving coverage analysis with dialogs with the LLM to focus its attention on as yet uncovered lines and branches. The resulting test suites significantly improve coverage over the current state of the art: compared to CodaMosa, a hybrid LLM / search-based software testing system, CoverUp substantially improves coverage across the board. On a per-module basis, CoverUp achieves median line coverage of 81% (vs. 62%), branch coverage of 53% (vs. 35%) and line+branch coverage of 78% (vs. 55%). We show that CoverUp's iterative, coverage-guided approach is crucial to its effectiveness, contributing to nearly half of its successes.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16218">https://arxiv.org/abs/2403.16218</a></p>
            <p><strong>Category:</strong> cs.SE</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper discusses the use of large language models (LLMs) for software test generation, which falls under the umbrella of computer automation using LLMs. Although it does not focus on controlling software or web browsers specifically, it presents a novel approach to using LLMs for software-related tasks, hence its relevance.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.16809" target="_blank">An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems</a></h3>
            <a href="https://arxiv.org/html/2403.16809v1/extracted/5493971/SysDiagram.png" target="_blank"><img src="https://arxiv.org/html/2403.16809v1/extracted/5493971/SysDiagram.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Hanqing Yang, Marie Siew, Carlee Joe-Wong</p>
            <p><strong>Summary:</strong> arXiv:2403.16809v1 Announce Type: cross 
Abstract: The increasing prevalence of Cyber-Physical Systems and the Internet of Things (CPS-IoT) applications and Foundation Models are enabling new applications that leverage real-time control of the environment. For example, real-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems can reduce its usage when not needed for the comfort of human occupants, hence reducing energy consumption. Collecting real-time feedback on human preferences in such human-in-the-loop (HITL) systems, however, is difficult in practice. We propose the use of large language models (LLMs) to deal with the challenges of dynamic environments and difficult-to-obtain data in CPS optimization. In this paper, we present a case study that employs LLM agents to mimic the behaviors and thermal preferences of various population groups (e.g. young families, the elderly) in a shopping mall. The aggregated thermal preferences are integrated into an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which employs the LLM as a dynamic simulation of the physical environment to learn how to balance between energy savings and occupant comfort. Our results show that LLMs are capable of simulating complex population movements within large open spaces. Besides, AitL-RL demonstrates superior performance compared to the popular existing policy of set point control, suggesting that adaptive and personalized decision-making is critical for efficient optimization in CPS-IoT applications. Through this case study, we demonstrate the potential of integrating advanced Foundation Models like LLMs into CPS-IoT to enhance system adaptability and efficiency. The project's code can be found on our GitHub repository.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16809">https://arxiv.org/abs/2403.16809</a></p>
            <p><strong>Category:</strong> eess.SY</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper aligns with your interests in agents based on large-language models. It discusses the usage of large language models in optimizing human-in-the-loop systems and simulation of complex population movements in large spaces, which could be considered as a method of controlling software environments.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2309.15531" target="_blank">Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2309.15531v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2309.15531v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jung Hwan Heo, Jeonghoon Kim, Beomseok Kwon, Byeongwook Kim, Se Jung Kwon, Dongsoo Lee</p>
            <p><strong>Summary:</strong> arXiv:2309.15531v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have recently demonstrated remarkable success across various tasks. However, efficiently serving LLMs has been a challenge due to the large memory bottleneck, specifically in small batch inference settings (e.g. mobile devices). Weight-only quantization can be a promising approach, but sub-4 bit quantization remains a challenge due to large-magnitude activation outliers. To mitigate the undesirable outlier effect, we first propose per-IC quantization, a simple yet effective method that creates quantization groups within each input channel (IC) rather than the conventional per-output-channel (per-OC). Our method is motivated by the observation that activation outliers affect the input dimension of the weight matrix, so similarly grouping the weights in the IC direction can isolate outliers within a group. We also find that activation outliers do not dictate quantization difficulty, and inherent weight sensitivities also exist. With per-IC quantization as a new outlier-friendly scheme, we propose Adaptive Dimensions (AdaDim), a versatile quantization framework that can adapt to various weight sensitivity patterns. We demonstrate the effectiveness of AdaDim by augmenting prior methods such as Round-To-Nearest and GPTQ, showing significant improvements across various language modeling benchmarks for both base (up to +4.7% on MMLU) and instruction-tuned (up to +10% on HumanEval) LLMs. Code is available at https://github.com/johnheo/adadim-llm</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2309.15531">https://arxiv.org/abs/2309.15531</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper discusses a technique to efficiently manage Large Language Models (LLMs) by addressing memory bottlenecks, which is very useful for deploying LLM-based agents in diverse environments like mobile devices. While it does not explicitly discuss controlling software or web browsers, the efficiency gains can indirectly support such tasks.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.08446" target="_blank">Towards Robust Multi-Modal Reasoning via Model Selection</a></h3>
            <a href="https://arxiv.org/html/2310.08446v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.08446v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xiangyan Liu, Rongxue Li, Wei Ji, Tao Lin</p>
            <p><strong>Summary:</strong> arXiv:2310.08446v2 Announce Type: replace 
Abstract: The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents. LLM serves as the "brain" of the agent, orchestrating multiple tools for collaborative multi-step task solving. Unlike methods invoking tools like calculators or weather APIs for straightforward tasks, multi-modal agents excel by integrating diverse AI models for complex challenges. However, current multi-modal agents neglect the significance of model selection: they primarily focus on the planning and execution phases, and will only invoke predefined task-specific models for each subtask, making the execution fragile. Meanwhile, other traditional model selection methods are either incompatible with or suboptimal for the multi-modal agent scenarios, due to ignorance of dependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges therein and propose the $\textit{M}^3$ framework as a plug-in with negligible runtime overhead at test-time. This framework improves model selection and bolsters the robustness of multi-modal agents in multi-step reasoning. In the absence of suitable benchmarks, we create MS-GQA, a new dataset specifically designed to investigate the model selection challenge in multi-modal agents. Our experiments reveal that our framework enables dynamic model selection, considering both user inputs and subtask dependencies, thereby robustifying the overall reasoning process. Our code and benchmark: https://github.com/LINs-lab/M3.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.08446">https://arxiv.org/abs/2310.08446</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper explores the use of LLMs (Large Language Models) in the context of autonomous agents, focusing on improving the robustness of multi-modal agents in multi-step reasoning. Even though it doesn't specifically focus on 'controlling software' or 'web browsing', it explores the broader context in which such functionalities could be deployed.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.16430" target="_blank">Preference as Reward, Maximum Preference Optimization with Importance Sampling</a></h3>
            <a href="https://arxiv.org/html/2312.16430v5/extracted/5492959/pic/process.jpg" target="_blank"><img src="https://arxiv.org/html/2312.16430v5/extracted/5492959/pic/process.jpg" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Zaifan Jiang, Xing Huang, Chao Wei</p>
            <p><strong>Summary:</strong> arXiv:2312.16430v5 Announce Type: replace 
Abstract: Preference learning is a key technology for aligning language models with human values. Reinforcement Learning from Human Feedback (RLHF) is a model-based algorithm to optimize preference learning, which first fits a reward model for preference scores and then optimizes the generating policy with an on-policy PPO algorithm to maximize the reward. The processing of RLHF is complex, time-consuming, and unstable. The Direct Preference Optimization (DPO) algorithm uses an off-policy algorithm to directly optimize the generating policy and eliminates the need for a reward model. DPO is more data-efficient and stable. However, DPO has a drawback of overfitting to the preference data and ignoring the KL-regularization term when the preference is deterministic. Identity mapping Preference Optimization(IPO) uses a root-finding MSE loss to incorporate KL-regularization. However, both DPO and IPO fail to properly address the KL-regularization term because the support of the preference distribution is not equal to the reference distribution. In this paper, we propose a simple and intuitive off-policy preference optimization algorithm from an importance sampling view, which we call Maximum Preference Optimization (MPO). MPO incorporates the off-policy KL-regularization term, making regularization truly effective. MPO achieves the best of both worlds by combining the objectives of RLHF and IPO while being an off-policy algorithm. Furthermore, MPO eliminates the need for a reward model and reference policy, simplifying the learning process and reducing memory usage.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.16430">https://arxiv.org/abs/2312.16430</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper discusses the use of preference learning to align language models with human values. Although it does not directly talk about controlling software or web browsers, it has implications for the development of agents based on large-language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.04870" target="_blank">Lemur: Integrating Large Language Models in Automated Program Verification</a></h3>
            <a href="https://arxiv.org/html/2310.04870v3/extracted/5492254/figs/histogram_esbmc.png" target="_blank"><img src="https://arxiv.org/html/2310.04870v3/extracted/5492254/figs/histogram_esbmc.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Haoze Wu, Clark Barrett, Nina Narodytska</p>
            <p><strong>Summary:</strong> arXiv:2310.04870v3 Announce Type: replace-cross 
Abstract: The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that demands high-level abstract reasoning about program properties that is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of derivation rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure, which led to practical improvements on a set of synthetic and competition benchmarks.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.04870">https://arxiv.org/abs/2310.04870</a></p>
            <p><strong>Category:</strong> cs.FL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant because it discusses the integration of large language models in automated program verification, which seeks to hone the abilities of these models to control software programs. This falls within your interest of using large language models for computer automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.07240" target="_blank">CacheGen: KV Cache Compression and Streaming for Fast Language Model Serving</a></h3>
            <a href="https://arxiv.org/html/2310.07240v4/" target="_blank"><img src="https://arxiv.org/html/2310.07240v4/" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi Yao, Shan Lu, Ganesh Ananthanarayanan, Michael Maire, Henry Hoffmann, Ari Holtzman, Junchen Jiang</p>
            <p><strong>Summary:</strong> arXiv:2310.07240v4 Announce Type: replace-cross 
Abstract: As large language models (LLMs) take on complex tasks, their inputs are supplemented with longer contexts that incorporate domain knowledge or user-specific information. Yet using long contexts poses a challenge for responsive LLM systems, as nothing can be generated until the whole context is processed by the LLM. While the context-processing delay can be reduced by reusing the KV cache of a context across different inputs, fetching the KV cache, which contains large tensors, over the network can cause extra network delays.
  CacheGen is a fast context-loading module for LLM systems. First, CacheGen uses a custom tensor encoder, which embraces KV cache's distributional properties, to encode a KV cache into more compact bitstream representations with negligible encoding/decoding overhead. This reduces the bandwidth demand to fetch the KV cache. Second, to maintain low context-loading delay and high generation quality, CacheGen adapts the streaming strategies to cope with changes in available bandwidth. When available bandwidth drops, CacheGen may raise the compression level for a part of the context or choose to recompute its KV cache on the fly. We test CacheGen on four popular LLMs of various sizes and four datasets (662 contexts in total). Compared to the recent systems that reuse the KV cache, CacheGen reduces the KV cache size by 3.7-4.3x and the total delay in fetching and processing contexts by 2.7-3.2x while having negligible impact on the LLM response quality in accuracy or perplexity.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.07240">https://arxiv.org/abs/2310.07240</a></p>
            <p><strong>Category:</strong> cs.NI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper discusses CacheGen, a fast context-loading module for Large Language Models (LLMs), which could be relevant in the context of developing LLM agents for software control and automation. While it doesn't specifically address controlling software or web browsers, understanding the mechanism of efficient context loading can promote efficient functioning of LLM agents.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.11667" target="_blank">SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents</a></h3>
            
            <p><strong>Authors:</strong> Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, Maarten Sap</p>
            <p><strong>Summary:</strong> arXiv:2310.11667v2 Announce Type: replace-cross 
Abstract: Humans are social beings; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and interact under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completion rate than humans and struggles to exhibit social commonsense reasoning and strategic communication skills. These findings demonstrate SOTOPIA's promise as a general platform for research on evaluating and improving social intelligence in artificial agents.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.11667">https://arxiv.org/abs/2310.11667</a></p>
            <p><strong>Category:</strong> cs.AI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper details the evaluation of social intelligence in LLM-based agents which could be comparable to a form of automation. However, it doesn't specifically focus on controlling software or web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.07311" target="_blank">Knowledge Graph Large Language Model (KG-LLM) for Link Prediction</a></h3>
            <a href="https://arxiv.org/html/2403.07311v5/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.07311v5/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Dong Shu, Tianle Chen, Mingyu Jin, Yiting Zhang, Chong Zhang, Mengnan Du, Yongfeng Zhang</p>
            <p><strong>Summary:</strong> arXiv:2403.07311v5 Announce Type: replace-cross 
Abstract: The task of predicting multiple links within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (NLP) and KG embedding techniques. This paper introduces a novel methodology, the Knowledge Graph Large Language Model Framework (KG-LLM), which leverages pivotal NLP paradigms, including chain-of-thought (CoT) prompting and in-context learning (ICL), to enhance multi-hop link prediction in KGs. By converting the KG to a CoT prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations. To show the efficacy of the KG-LLM Framework, we fine-tune three leading Large Language Models (LLMs) within this framework, employing both non-ICL and ICL tasks for a comprehensive evaluation. Further, we explore the framework's potential to provide LLMs with zero-shot capabilities for handling previously unseen prompts. Our experimental findings discover that integrating ICL and CoT not only augments the performance of our approach but also significantly boosts the models' generalization capacity, thereby ensuring more precise predictions in unfamiliar scenarios.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.07311">https://arxiv.org/abs/2403.07311</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> While the paper does not directly mention controlling software or web browsers, it does discuss the usage of large language models in a unique way. It employs large language models to predict links within knowledge graphs, which possibly could be used for tasks related to software control and automation. There is strong potential that the concepts explored are relevant to your interests in large language model applications, particularly if 'Knowledge Graph Large Language Model Framework' has implications not directly discussed in the abstract.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.14589" target="_blank">ReAct Meets ActRe: Autonomous Annotation of Agent Trajectories for Contrastive Self-Training</a></h3>
            <a href="https://arxiv.org/html/2403.14589v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.14589v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Zonghan Yang, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu</p>
            <p><strong>Summary:</strong> arXiv:2403.14589v2 Announce Type: replace-cross 
Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotation or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent executes multiple trajectories for the failed tasks, and selects the successful ones to supplement its failed trajectory for contrastive self-training. Realized by policy gradient methods with binarized rewards, the contrastive self-training with accumulated trajectories facilitates a closed loop for multiple rounds of language agent self-improvement. We conduct experiments using QLoRA fine-tuning with the open-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with A$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative rounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human average, and 4 rounds of iterative refinement lead to the performance approaching human experts. A$^3$T agents significantly outperform existing techniques, including prompting with GPT-4, advanced agent frameworks, and fully fine-tuned LLMs.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.14589">https://arxiv.org/abs/2403.14589</a></p>
            <p><strong>Category:</strong> cs.AI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The research paper details autonomous decision-making abilities by reasoning with foundation models, significantly aligning with your interest in agents based on large language models, specifically computer automation using large language models. However, it does not particularly focus on controlling software or web browsers, hence the 4 score.</p>
        </div>
        </div><div class='timestamp'>Report generated on March 26, 2024 at 21:43:00</div></body></html>