
            <html>
            <head>
                <title>Report Generated on March 28, 2024</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .paper-box {
                        background-color: #f0f0f0;
                        margin-bottom: 20px;
                        padding: 15px;
                        border-radius: 5px;
                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    }
                    h1 { text-align: center; }
                    h2 {
                        cursor: pointer;
                        color: #333;
                        border-bottom: 2px solid #666;
                    }
                    a { color: #337ab7; text-decoration: none; }
                    a:hover { text-decoration: underline; }
                    h3 { color: #337ab7; }
                    .timestamp { text-align: center; font-size: small; margin-top: 40px; }
                    .paper-figure {
                        max-width: 200px;
                        border: 1px solid #ddd;
                        border-radius: 4px;
                        padding: 5px;
                        margin-top: 10px;
                    }
                    .papers-container { display: block; padding: 0 18px; }
                </style>
            </head>
            <body>
            <h1>Report for March 28, 2024</h1>
            <script>
                function toggleSection(id) {
                    var x = document.getElementById(id);
                    if (x.style.display === "none") {
                        x.style.display = "block";
                    } else {
                        x.style.display = "none";
                    }
                }
            </script>
            <h2 onclick="toggleSection('section_time-series')">Time-series</h2><div id='section_time-series' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18316" target="_blank">Multi-Modal Contrastive Learning for Online Clinical Time-Series Applications</a></h3>
            <a href="https://arxiv.org/html/2403.18316v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.18316v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Fabian Baldenweg, Manuel Burger, Gunnar R\"atsch, Rita Kuznetsova</p>
            <p><strong>Summary:</strong> arXiv:2403.18316v1 Announce Type: new 
Abstract: Electronic Health Record (EHR) datasets from Intensive Care Units (ICU) contain a diverse set of data modalities. While prior works have successfully leveraged multiple modalities in supervised settings, we apply advanced self-supervised multi-modal contrastive learning techniques to ICU data, specifically focusing on clinical notes and time-series for clinically relevant online prediction tasks. We introduce a loss function Multi-Modal Neighborhood Contrastive Loss (MM-NCL), a soft neighborhood function, and showcase the excellent linear probe and zero-shot performance of our approach.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18316">https://arxiv.org/abs/2403.18316</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interests in new multimodal deep learning models for time series. It discusses a novel self-supervised multi-modal contrastive learning method specifically for time-series data in clinical settings. However, the paper does not focus on forecasting.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18379" target="_blank">IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining Useful Life Prediction</a></h3>
            <a href="https://arxiv.org/html/2403.18379v1/extracted/5498898/images/IIPMixing.jpg" target="_blank"><img src="https://arxiv.org/html/2403.18379v1/extracted/5498898/images/IIPMixing.jpg" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Guangzai Ye, Li Feng, Jianlan Guo, Yuqiang Chen</p>
            <p><strong>Summary:</strong> arXiv:2403.18379v1 Announce Type: new 
Abstract: Accurately estimating the Remaining Useful Life (RUL) of lithium-ion batteries is crucial for maintaining the safe and stable operation of rechargeable battery management systems. However, this task is often challenging due to the complex temporal dynamics involved. Recently, attention-based networks, such as Transformers and Informer, have been the popular architecture in time series forecasting. Despite their effectiveness, these models with abundant parameters necessitate substantial training time to unravel temporal patterns. To tackle these challenges, we propose a simple MLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which is an architecture based exclusively on multi-layer perceptrons (MLPs), extracting information by mixing operations along both intra-patch and inter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer comprises parallel dual-head mixer layers: the intra-patch mixing MLP, capturing local temporal patterns in the short-term period, and the inter-patch mixing MLP, capturing global temporal patterns in the long-term period. Notably, to address the varying importance of features in RUL prediction, we introduce a weighted loss function in the MLP-Mixer-based architecture, marking the first time such an approach has been employed. Our experiments demonstrate that IIP-Mixer achieves competitive performance in battery RUL prediction, outperforming other popular time-series frameworks</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18379">https://arxiv.org/abs/2403.18379</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> The paper introduces an architecture called 'Intra-Inter Patch Mixer' (IIP-Mixer), which is a deep learning method designed specifically for time series prediction (Remaining Useful Life (RUL) of lithium-ion batteries). It's a form of MLP-Mixer-based architecture, which is a transformer-like model, integrating both short-term and long-term period patterns. However, it's not explicitly multimodal or a fundamental foundation model, which is why the score isn't the maximum.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18451" target="_blank">CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in Resource-Constrained CPS and IoT</a></h3>
            <a href="https://arxiv.org/html/2403.18451v1/extracted/5499097/figs/demo.png" target="_blank"><img src="https://arxiv.org/html/2403.18451v1/extracted/5499097/figs/demo.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yi Hu, Jinhang Zuo, Alanis Zhao, Bob Iannucci, Carlee Joe-Wong</p>
            <p><strong>Summary:</strong> arXiv:2403.18451v1 Announce Type: new 
Abstract: Foundation models (FMs) emerge as a promising solution to harness distributed and diverse environmental data by leveraging prior knowledge to understand the complicated temporal and spatial correlations within heterogeneous datasets. Unlike distributed learning frameworks such as federated learning, which often struggle with multimodal data, FMs can transform diverse inputs into embeddings. This process facilitates the integration of information from various modalities and the application of prior learning to new domains. However, deploying FMs in resource-constrained edge systems poses significant challenges. To this end, we introduce CoRAST, a novel learning framework that utilizes FMs for enhanced analysis of distributed, correlated heterogeneous data. Utilizing a server-based FM, CoRAST can exploit existing environment information to extract temporal, spatial, and cross-modal correlations among sensor data. This enables CoRAST to offer context-aware insights for localized client tasks through FM-powered global representation learning. Our evaluation on real-world weather dataset demonstrates CoRAST's ability to exploit correlated heterogeneous data through environmental representation learning to reduce the forecast errors by up to 50.3% compared to the baselines.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18451">https://arxiv.org/abs/2403.18451</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is relevant as it proposes a novel learning framework, CoRAST, for time series analysis. It highlights the use of Foundation Models for the analysis of distributed, correlated heterogeneous data. Although it doesn't speak specifically on forecasting, the given method is proposed for reducing forecast errors, thus making it applicable and relevant.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18447" target="_blank">Can Language Beat Numerical Regression? Language-Based Multimodal Trajectory Prediction</a></h3>
            <a href="https://arxiv.org/html/2403.18447v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.18447v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Inhwan Bae, Junoh Lee, Hae-Gon Jeon</p>
            <p><strong>Summary:</strong> arXiv:2403.18447v1 Announce Type: cross 
Abstract: Language models have demonstrated impressive ability in context understanding and generative performance. Inspired by the recent success of language foundation models, in this paper, we propose LMTraj (Language-based Multimodal Trajectory predictor), which recasts the trajectory prediction task into a sort of question-answering problem. Departing from traditional numerical regression models, which treat the trajectory coordinate sequence as continuous signals, we consider them as discrete signals like text prompts. Specially, we first transform an input space for the trajectory coordinate into the natural language space. Here, the entire time-series trajectories of pedestrians are converted into a text prompt, and scene images are described as text information through image captioning. The transformed numerical and image data are then wrapped into the question-answering template for use in a language model. Next, to guide the language model in understanding and reasoning high-level knowledge, such as scene context and social relationships between pedestrians, we introduce an auxiliary multi-task question and answering. We then train a numerical tokenizer with the prompt data. We encourage the tokenizer to separate the integer and decimal parts well, and leverage it to capture correlations between the consecutive numbers in the language model. Lastly, we train the language model using the numerical tokenizer and all of the question-answer prompts. Here, we propose a beam-search-based most-likely prediction and a temperature-based multimodal prediction to implement both deterministic and stochastic inferences. Applying our LMTraj, we show that the language-based model can be a powerful pedestrian trajectory predictor, and outperforms existing numerical-based predictor methods. Code is publicly available at https://github.com/inhwanbae/LMTrajectory .</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18447">https://arxiv.org/abs/2403.18447</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> The paper proposes a novel language-based multimodal model, LMTraj, for trajectory prediction, which could be classified as a time series problem. It's also utilizing transformers (large language models) for this task.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18810" target="_blank">LightningNet: Distributed Graph-based Cellular Network Performance Forecasting for the Edge</a></h3>
            <a href="https://arxiv.org/html/2403.18810v1/extracted/5399021/figs/overview.png" target="_blank"><img src="https://arxiv.org/html/2403.18810v1/extracted/5399021/figs/overview.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Konstantinos Zacharopoulos, Georgios Koutroumpas, Ioannis Arapakis, Konstantinos Georgopoulos, Javad Khangosstar, Sotiris Ioannidis</p>
            <p><strong>Summary:</strong> arXiv:2403.18810v1 Announce Type: cross 
Abstract: The cellular network plays a pivotal role in providing Internet access, since it is the only global-scale infrastructure with ubiquitous mobility support. To manage and maintain large-scale networks, mobile network operators require timely information, or even accurate performance forecasts. In this paper, we propose LightningNet, a lightweight and distributed graph-based framework for forecasting cellular network performance, which can capture spatio-temporal dependencies that arise in the network traffic. LightningNet achieves a steady performance increase over state-of-the-art forecasting techniques, while maintaining a similar resource usage profile. Our architecture ideology also excels in the respect that it is specifically designed to support IoT and edge devices, giving us an even greater step ahead of the current state-of-the-art, as indicated by our performance experiments with NVIDIA Jetson.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18810">https://arxiv.org/abs/2403.18810</a></p>
            <p><strong>Category:</strong> cs.NI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is related to your interests as it presents LightningNet, a new approach for forecasting cellular network performance, which is a type of time series data. However, it does not seem to touch upon multimodal deep learning or transformer-like models specifically.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2309.11427" target="_blank">Generative Pre-Training of Time-Series Data for Unsupervised Fault Detection in Semiconductor Manufacturing</a></h3>
            <a href="https://arxiv.org/html/2309.11427v2/extracted/5499593/lee7.png" target="_blank"><img src="https://arxiv.org/html/2309.11427v2/extracted/5499593/lee7.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Sewoong Lee, JinKyou Choi, Min Su Kim</p>
            <p><strong>Summary:</strong> arXiv:2309.11427v2 Announce Type: replace 
Abstract: This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing. In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect. However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult. In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss. We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2309.11427">https://arxiv.org/abs/2309.11427</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper introduces TRACE-GPT, a novel framework that leverages deep learning - GPT Generative Pre trained Transformers and convolutional embedding for unsupervised fault detection in time-series data produced by the semiconductor manufacturing industry. The relevance of this paper to your interest is that it involves a new approach to time series data, even though its primary application is in the fault detection and not forecasting.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.09267" target="_blank">Deep Limit Order Book Forecasting</a></h3>
            <a href="https://arxiv.org/html/2403.09267v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.09267v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Antonio Briola, Silvia Bartolucci, Tomaso Aste</p>
            <p><strong>Summary:</strong> arXiv:2403.09267v3 Announce Type: replace-cross 
Abstract: We exploit cutting-edge deep learning methodologies to explore the predictability of high-frequency Limit Order Book mid-price changes for a heterogeneous set of stocks traded on the NASDAQ exchange. In so doing, we release `LOBFrame', an open-source code base to efficiently process large-scale Limit Order Book data and quantitatively assess state-of-the-art deep learning models' forecasting capabilities. Our results are twofold. We demonstrate that the stocks' microstructural characteristics influence the efficacy of deep learning methods and that their high forecasting power does not necessarily correspond to actionable trading signals. We argue that traditional machine learning metrics fail to adequately assess the quality of forecasts in the Limit Order Book context. As an alternative, we propose an innovative operational framework that evaluates predictions' practicality by focusing on the probability of accurately forecasting complete transactions. This work offers academics and practitioners an avenue to make informed and robust decisions on the application of deep learning techniques, their scope and limitations, effectively exploiting emergent statistical properties of the Limit Order Book.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.09267">https://arxiv.org/abs/2403.09267</a></p>
            <p><strong>Category:</strong> q-fin.TR</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper presents a way to forecast Limit Order Book mid-price changes using deep learning methods, which aligns with your interest in new deep learning methods for time series. Although it doesn't specifically mention foundation models, multimodal models, or transformer-like models, it proposes an innovative operational framework that evaluates predictions' practicality for time series.</p>
        </div>
        </div><h2 onclick="toggleSection('section_llm-agents')">Llm-agents</h2><div id='section_llm-agents' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18415" target="_blank">The Topos of Transformer Networks</a></h3>
            
            <p><strong>Authors:</strong> Mattia Jacopo Villani, Peter McBurney</p>
            <p><strong>Summary:</strong> arXiv:2403.18415v1 Announce Type: new 
Abstract: The transformer neural network has significantly out-shined all other neural network architectures as the engine behind large language models. We provide a theoretical analysis of the expressivity of the transformer architecture through the lens of topos theory. From this viewpoint, we show that many common neural network architectures, such as the convolutional, recurrent and graph convolutional networks, can be embedded in a pretopos of piecewise-linear functions, but that the transformer necessarily lives in its topos completion. In particular, this suggests that the two network families instantiate different fragments of logic: the former are first order, whereas transformers are higher-order reasoners. Furthermore, we draw parallels with architecture search and gradient descent, integrating our analysis in the framework of cybernetic agents.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18415">https://arxiv.org/abs/2403.18415</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interest in large language models. It provides a theoretical analysis of transformer networks, a pivotal architecture in large models that is used to control various applications such as software and web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18742" target="_blank">Understanding the Learning Dynamics of Alignment with Human Feedback</a></h3>
            <a href="https://arxiv.org/html/2403.18742v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.18742v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Shawn Im, Yixuan Li</p>
            <p><strong>Summary:</strong> arXiv:2403.18742v1 Announce Type: new 
Abstract: Aligning large language models (LLMs) with human intentions has become a critical task for safely deploying models in real-world systems. While existing alignment approaches have seen empirical success, theoretically understanding how these methods affect model behavior remains an open question. Our work provides an initial attempt to theoretically analyze the learning dynamics of human preference alignment. We formally show how the distribution of preference datasets influences the rate of model updates and provide rigorous guarantees on the training accuracy. Our theory also reveals an intricate phenomenon where the optimization is prone to prioritizing certain behaviors with higher preference distinguishability. We empirically validate our findings on contemporary LLMs and alignment tasks, reinforcing our theoretical insights and shedding light on considerations for future alignment approaches. Disclaimer: This paper contains potentially offensive text; reader discretion is advised.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18742">https://arxiv.org/abs/2403.18742</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in large language models and how they align with human intentions. The paper delves into aligning these models for use in real-world systems, providing theoretical analysis of the learning dynamics associated with human preference alignment - a concept critical to software and automation control.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18120" target="_blank">Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization</a></h3>
            <a href="https://arxiv.org/html/2403.18120v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.18120v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jin Peng Zhou, Charles Staats, Wenda Li, Christian Szegedy, Kilian Q. Weinberger, Yuhuai Wu</p>
            <p><strong>Summary:</strong> arXiv:2403.18120v1 Announce Type: cross 
Abstract: Large language models (LLM), such as Google's Minerva and OpenAI's GPT families, are becoming increasingly capable of solving mathematical quantitative reasoning problems. However, they still make unjustified logical and computational errors in their reasoning steps and answers. In this paper, we leverage the fact that if the training corpus of LLMs contained sufficiently many examples of formal mathematics (e.g. in Isabelle, a formal theorem proving environment), they can be prompted to translate i.e. autoformalize informal mathematical statements into formal Isabelle code -- which can be verified automatically for internal consistency. This provides a mechanism to automatically reject solutions whose formalized versions are inconsistent within themselves or with the formalized problem statement. We evaluate our method on GSM8K, MATH and MultiArith datasets and demonstrate that our approach provides a consistently better heuristic than vanilla majority voting -- the previously best method to identify correct answers, by more than 12% on GSM8K. In our experiments it improves results consistently across all datasets and LLM model sizes. The code can be found at https://github.com/jinpz/dtv.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18120">https://arxiv.org/abs/2403.18120</a></p>
            <p><strong>Category:</strong> cs.AI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper discusses the use of large language models (LLMs) for quantitative reasoning and formal theorem proving. While it doesn't specifically mention controlling software or web browsers, the methodology applied can still be quite relevant to your interests in large language models as agents.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18222" target="_blank">Uncertainty-Aware Deployment of Pre-trained Language-Conditioned Imitation Learning Policies</a></h3>
            <a href="https://arxiv.org/html/2403.18222v1/extracted/5497681/figures/title_figure.png" target="_blank"><img src="https://arxiv.org/html/2403.18222v1/extracted/5497681/figures/title_figure.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Bo Wu, Bruce D. Lee, Kostas Daniilidis, Bernadette Bucher, Nikolai Matni</p>
            <p><strong>Summary:</strong> arXiv:2403.18222v1 Announce Type: cross 
Abstract: Large-scale robotic policies trained on data from diverse tasks and robotic platforms hold great promise for enabling general-purpose robots; however, reliable generalization to new environment conditions remains a major challenge. Toward addressing this challenge, we propose a novel approach for uncertainty-aware deployment of pre-trained language-conditioned imitation learning agents. Specifically, we use temperature scaling to calibrate these models and exploit the calibrated model to make uncertainty-aware decisions by aggregating the local information of candidate actions. We implement our approach in simulation using three such pre-trained models, and showcase its potential to significantly enhance task completion rates. The accompanying code is accessible at the link: https://github.com/BobWu1998/uncertainty_quant_all.git</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18222">https://arxiv.org/abs/2403.18222</a></p>
            <p><strong>Category:</strong> cs.RO</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper may be of interest to you as it discusses large-scale robotic policies, which can be classfied as a type of agent, that are controlled via imitation learning. Additionally, it mentions the use of language conditioning which can draw a link to language based models, even though they aren't suggested as plainly as in your interests. Furthermore, the paper also addresses an issue regarding the reliable generalization of new environments which may be a subtopic of interest under the main topics you provided. However, the absence of direct application of large language model reduces the relevancy slightly.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18680" target="_blank">NL-ITI: Optimizing Probing and Intervention for Improvement of ITI Method</a></h3>
            <a href="https://arxiv.org/html/2403.18680v1/extracted/5499656/kl-mc1-revised.png" target="_blank"><img src="https://arxiv.org/html/2403.18680v1/extracted/5499656/kl-mc1-revised.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jakub Hoscilowicz, Adam Wiacek, Jan Chojnacki, Adam Cieslak, Leszek Michon, Vitalii Urbanevych, Artur Janicki</p>
            <p><strong>Summary:</strong> arXiv:2403.18680v1 Announce Type: cross 
Abstract: Large Language Models (LLM) are prone to returning false information. It constitutes one of major challenges in the AI field. In our work, we explore paradigm introduced by Inference-Time-Intervention (ITI). In first stage, it identifies attention heads, which contain the highest amount of desired type of knowledge (e.g., truthful). Afterwards, during inference, LLM activations are shifted for chosen subset of attention heads. We further improved the ITI framework by introducing a nonlinear probing and multi-token intervention - Non-Linear ITI (NL-ITI). NL-ITI is tested on diverse multiple-choice benchmarks, including TruthfulQA, on which we report around 14% MC1 metric improvement with respect to the baseline ITI results. NL-ITI achieves also encouraging results on other testsets - on Business Ethics subdomain of MMLU, around 18% MC1 improvement over baseline LLaMA2-7B. Additionally, NL-ITI performs better while being less invasive in the behavior of LLM at the same time (as measured by Kullback-Leibler divergence).</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18680">https://arxiv.org/abs/2403.18680</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper discusses Large Language Models (LLMs) and proposes optimizations to handle the challenge of these models returning false information. While it doesn't focus on control of software or web browsers, the techniques for improving LLMs with inference-time intervention could be applicable to those subtopics.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18802" target="_blank">Long-form factuality in large language models</a></h3>
            
            <p><strong>Authors:</strong> Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, Ruibo Liu, Da Huang, Cosmo Du, Quoc V. Le</p>
            <p><strong>Summary:</strong> arXiv:2403.18802v1 Announce Type: cross 
Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the percentage of provided facts relative to a hyperparameter representing a user's preferred response length (recall).
  Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times cheaper than human annotators. We also benchmark thirteen language models on LongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding that larger language models generally achieve better long-form factuality. LongFact, SAFE, and all experimental code are available at https://github.com/google-deepmind/long-form-factuality.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18802">https://arxiv.org/abs/2403.18802</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interests as it discusses using Large Language Models (LLMs) for automation tasks. It proposes a method for using LLMs to evaluate the factuality of long-form responses, which could be extrapolated to controlling software or web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.10812" target="_blank">Learning to Act without Actions</a></h3>
            <a href="https://arxiv.org/html/2312.10812v2/extracted/5498064/figures/umap_intro.png" target="_blank"><img src="https://arxiv.org/html/2312.10812v2/extracted/5498064/figures/umap_intro.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Dominik Schmidt, Minqi Jiang</p>
            <p><strong>Summary:</strong> arXiv:2312.10812v2 Announce Type: replace 
Abstract: Pre-training large models on vast amounts of web data has proven to be an effective approach for obtaining powerful, general models in domains such as language and vision. However, this paradigm has not yet taken hold in reinforcement learning. This is because videos, the most abundant form of embodied behavioral data on the web, lack the action labels required by existing methods for imitating behavior from demonstrations. We introduce Latent Action Policies (LAPO), a method for recovering latent action information, and thereby latent-action policies, world models, and inverse dynamics models, purely from videos. LAPO is the first method able to recover the structure of the true action space just from observed dynamics, even in challenging procedurally-generated environments. LAPO enables training latent-action policies that can be rapidly fine-tuned into expert-level policies, either offline using a small action-labeled dataset, or online with rewards. LAPO takes a first step towards pre-training powerful, generalist policies and world models on the vast amounts of videos readily available on the web.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.10812">https://arxiv.org/abs/2312.10812</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper falls under your interest in agents based on large-language models as it details the use of latent action policies learned purely from videos. While not explicitly mentioning large language models, the principle of learning from vast amounts of web data aligns well with your interest. It is slightly indirect with your subtopics but could be relevant in terms of applying such learned policies for control of software or automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.00117" target="_blank">ABScribe: Rapid Exploration & Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2310.00117v4/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.00117v4/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Mohi Reza, Nathan Laundry, Ilya Musabirov, Peter Dushniku, Zhi Yuan "Michael" Yu, Kashish Mittal, Tovi Grossman, Michael Liut, Anastasia Kuzminykh, Joseph Jay Williams</p>
            <p><strong>Summary:</strong> arXiv:2310.00117v4 Announce Type: replace-cross 
Abstract: Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers' flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances user perceptions of the revision process (d = 2.41, p < 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.00117">https://arxiv.org/abs/2310.00117</a></p>
            <p><strong>Category:</strong> cs.HC</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper is relevant to your interests in 'Agents based on large-language models'. It describes a method for using Large Language Models in co-writing tasks, which is a type of software control. However, it does not directly address web browsers or computer automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.01739" target="_blank">OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models</a></h3>
            <a href="https://arxiv.org/html/2402.01739v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2402.01739v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Fuzhao Xue, Zian Zheng, Yao Fu, Jinjie Ni, Zangwei Zheng, Wangchunshu Zhou, Yang You</p>
            <p><strong>Summary:</strong> arXiv:2402.01739v2 Announce Type: replace-cross 
Abstract: To help the open-source community have a better understanding of Mixture-of-Experts (MoE) based large language models (LLMs), we train and release OpenMoE, a series of fully open-sourced and reproducible decoder-only MoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T tokens. Our investigation confirms that MoE-based LLMs can offer a more favorable cost-effectiveness trade-off than dense LLMs, highlighting the potential effectiveness for future LLM development.
  One more important contribution of this study is an in-depth analysis of the routing mechanisms within our OpenMoE models, leading to three significant findings: Context-Independent Specialization, Early Routing Learning, and Drop-towards-the-End. We discovered that routing decisions in MoE models are predominantly based on token IDs, with minimal context relevance. The token-to-expert assignments are determined early in the pre-training phase and remain largely unchanged. This imperfect routing can result in performance degradation, particularly in sequential tasks like multi-turn conversations, where tokens appearing later in a sequence are more likely to be dropped. Finally, we rethink our design based on the above-mentioned observations and analysis. To facilitate future MoE LLM development, we propose potential strategies for mitigating the issues we found and further improving off-the-shelf MoE LLM designs.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.01739">https://arxiv.org/abs/2402.01739</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is on the topic of 'large language models' (LLMs) and the 'Mixture-of-Experts' (MoE) approach within said models. Although it does not specifically concern controlling software or web browsers, nor automation using these models, it contributes to a broader understanding of LLMs which could provide essential foundational information for these specific interests.</p>
        </div>
        </div><h2 onclick="toggleSection('section_causality')">Causality</h2><div id='section_causality' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.18717" target="_blank">Semi-Supervised Learning for Deep Causal Generative Models</a></h3>
            <a href="https://arxiv.org/html/2403.18717v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.18717v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yasin Ibrahim, Hermione Warr, Konstantinos Kamnitsas</p>
            <p><strong>Summary:</strong> arXiv:2403.18717v1 Announce Type: new 
Abstract: Developing models that can answer questions of the form "How would $x$ change if $y$ had been $z$?" is fundamental for advancing medical image analysis. Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data. However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this. We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data. We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample. We leverage techniques from causal inference to infer missing values and subsequently generate realistic counterfactuals, even for samples with incomplete labels.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.18717">https://arxiv.org/abs/2403.18717</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper connects with your interest in causality and machine learning. It discusses a novel semi-supervised deep causal generative model that leverages causal relationships, which relates to your subtopic of causal representation learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2306.15328" target="_blank">Simulating counterfactuals</a></h3>
            
            <p><strong>Authors:</strong> Juha Karvanen, Santtu Tikka, Matti Vihola</p>
            <p><strong>Summary:</strong> arXiv:2306.15328v3 Announce Type: replace-cross 
Abstract: Counterfactual inference considers a hypothetical intervention in a parallel world that shares some evidence with the factual world. If the evidence specifies a conditional distribution on a manifold, counterfactuals may be analytically intractable. We present an algorithm for simulating values from a counterfactual distribution where conditions can be set on both discrete and continuous variables. We show that the proposed algorithm can be presented as a particle filter leading to asymptotically valid inference. The algorithm is applied to fairness analysis in credit-scoring.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2306.15328">https://arxiv.org/abs/2306.15328</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper discusses an algorithm for simulating values from a counterfactual distribution with conditions on both discrete and continuous variables, which is closely related to your interest in causal discovery and causal representation learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.03325" target="_blank">Learning Concept-Based Causal Transition and Symbolic Reasoning for Visual Planning</a></h3>
            <a href="https://arxiv.org/html/2310.03325v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.03325v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yilue Qian, Peiyu Yu, Ying Nian Wu, Yao Su, Wei Wang, Lifeng Fan</p>
            <p><strong>Summary:</strong> arXiv:2310.03325v2 Announce Type: replace-cross 
Abstract: Visual planning simulates how humans make decisions to achieve desired goals in the form of searching for visual causal transitions between an initial visual state and a final visual goal state. It has become increasingly important in egocentric vision with its advantages in guiding agents to perform daily tasks in complex environments. In this paper, we propose an interpretable and generalizable visual planning framework consisting of i) a novel Substitution-based Concept Learner (SCL) that abstracts visual inputs into disentangled concept representations, ii) symbol abstraction and reasoning that performs task planning via the self-learned symbols, and iii) a Visual Causal Transition model (ViCT) that grounds visual causal transitions to semantically similar real-world actions. Given an initial state, we perform goal-conditioned visual planning with a symbolic reasoning method fueled by the learned representations and causal transitions to reach the goal state. To verify the effectiveness of the proposed model, we collect a large-scale visual planning dataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this challenging dataset demonstrate the superior performance of our method in visual task planning. Empirically, we show that our framework can generalize to unseen task trajectories, unseen object categories, and real-world data. Further details of this work are provided at https://fqyqc.github.io/ConTranPlan/.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.03325">https://arxiv.org/abs/2310.03325</a></p>
            <p><strong>Category:</strong> cs.AI</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> The paper investigates aspects of causal representation learning and causal discovery in the context of visual planning, which aligns with your interest in causality and machine learning. Although it does not directly involve large language models, it may still provide valuable insights for your research.</p>
        </div>
        </div><div class='timestamp'>Report generated on March 28, 2024 at 21:34:54</div></body></html>