
            <html>
            <head>
                <title>Report Generated on April 01, 2024</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .paper-box {
                        background-color: #f0f0f0;
                        margin-bottom: 20px;
                        padding: 15px;
                        border-radius: 5px;
                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    }
                    h1 { text-align: center; }
                    h2 {
                        cursor: pointer;
                        color: #333;
                        border-bottom: 2px solid #666;
                    }
                    a { color: #337ab7; text-decoration: none; }
                    a:hover { text-decoration: underline; }
                    h3 { color: #337ab7; }
                    .timestamp { text-align: center; font-size: small; margin-top: 40px; }
                    .paper-figure {
                        max-width: 200px;
                        border: 1px solid #ddd;
                        border-radius: 4px;
                        padding: 5px;
                        margin-top: 10px;
                    }
                    .papers-container { display: block; padding: 0 18px; }
                </style>
            </head>
            <body>
            <h1>Report for April 01, 2024</h1>
            <script>
                function toggleSection(id) {
                    var x = document.getElementById(id);
                    if (x.style.display === "none") {
                        x.style.display = "block";
                    } else {
                        x.style.display = "none";
                    }
                }
            </script>
            <h2 onclick="toggleSection('section_time-series')">Time-series</h2><div id='section_time-series' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19888" target="_blank">MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection</a></h3>
            <a href="https://arxiv.org/html/2403.19888v1/extracted/5503205/MambaMixer-2-2.png" target="_blank"><img src="https://arxiv.org/html/2403.19888v1/extracted/5503205/MambaMixer-2-2.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Ali Behrouz, Michele Santacatterina, Ramin Zabih</p>
            <p><strong>Summary:</strong> arXiv:2403.19888v1 Announce Type: new 
Abstract: Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibits quadratic time and space in input size, limiting their scalability for long-sequence modeling. Despite recent attempts to design efficient and effective architecture backbone for multi-dimensional data, such as images and multivariate time series, existing models are either data independent, or fail to allow inter- and intra-dimension communication. Recently, State Space Models (SSMs), and more specifically Selective State Space Models, with efficient hardware-aware implementation, have shown promising potential for long sequence modeling. Motivated by the success of SSMs, we present MambaMixer, a new architecture with data-dependent weights that uses a dual selection mechanism across tokens and channels, called Selective Token and Channel Mixer. MambaMixer connects selective mixers using a weighted averaging mechanism, allowing layers to have direct access to early features. As a proof of concept, we design Vision MambaMixer (ViM2) and Time Series MambaMixer (TSM2) architectures based on the MambaMixer block and explore their performance in various vision and time series forecasting tasks. Our results underline the importance of selective mixing across both tokens and channels. In ImageNet classification, object detection, and semantic segmentation tasks, ViM2 achieves competitive performance with well-established vision models and outperforms SSM-based vision models. In time series forecasting, TSM2 achieves outstanding performance compared to state-of-the-art methods while demonstrating significantly improved computational cost. These results show that while Transformers, cross-channel attention, and MLPs are sufficient for good performance in time series forecasting, neither is necessary.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19888">https://arxiv.org/abs/2403.19888</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper introduces MambaMixer, a new architecture proposed for more efficient and effective long sequence modeling in time series forecasting, which aligns with your interest in new deep learning methods and transformer-like models for time series.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19721" target="_blank">Computationally and Memory-Efficient Robust Predictive Analytics Using Big Data</a></h3>
            <a href="https://arxiv.org/html/2403.19721v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.19721v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Daniel Menges, Adil Rasheed</p>
            <p><strong>Summary:</strong> arXiv:2403.19721v1 Announce Type: new 
Abstract: In the current data-intensive era, big data has become a significant asset for Artificial Intelligence (AI), serving as a foundation for developing data-driven models and providing insight into various unknown fields. This study navigates through the challenges of data uncertainties, storage limitations, and predictive data-driven modeling using big data. We utilize Robust Principal Component Analysis (RPCA) for effective noise reduction and outlier elimination, and Optimal Sensor Placement (OSP) for efficient data compression and storage. The proposed OSP technique enables data compression without substantial information loss while simultaneously reducing storage needs. While RPCA offers an enhanced alternative to traditional Principal Component Analysis (PCA) for high-dimensional data management, the scope of this work extends its utilization, focusing on robust, data-driven modeling applicable to huge data sets in real-time. For that purpose, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network, are applied to model and predict data based on a low-dimensional subset obtained from OSP, leading to a crucial acceleration of the training phase. LSTMs are feasible for capturing long-term dependencies in time series data, making them particularly suited for predicting the future states of physical systems on historical data. All the presented algorithms are not only theorized but also simulated and validated using real thermal imaging data mapping a ship's engine.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19721">https://arxiv.org/abs/2403.19721</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper deploys robust predictive analytics using big data, with Long Short-Term Memory (LSTM) networks applied to model and predict data based on a low-dimensional subset. Though it does not offer a new method, it steps up the use of LSTM for managing high-dimensional data and accelerates the training phase, relevance to your interest in deep learning methods for time series forecasting.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19800" target="_blank">Gegenbauer Graph Neural Networks for Time-varying Signal Reconstruction</a></h3>
            <a href="https://arxiv.org/html/2403.19800v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.19800v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jhon A. Castro-Correa, Jhony H. Giraldo, Mohsen Badiey, Fragkiskos D. Malliaros</p>
            <p><strong>Summary:</strong> arXiv:2403.19800v1 Announce Type: new 
Abstract: Reconstructing time-varying graph signals (or graph time-series imputation) is a critical problem in machine learning and signal processing with broad applications, ranging from missing data imputation in sensor networks to time-series forecasting. Accurately capturing the spatio-temporal information inherent in these signals is crucial for effectively addressing these tasks. However, existing approaches relying on smoothness assumptions of temporal differences and simple convex optimization techniques have inherent limitations. To address these challenges, we propose a novel approach that incorporates a learning module to enhance the accuracy of the downstream task. To this end, we introduce the Gegenbauer-based graph convolutional (GegenConv) operator, which is a generalization of the conventional Chebyshev graph convolution by leveraging the theory of Gegenbauer polynomials. By deviating from traditional convex problems, we expand the complexity of the model and offer a more accurate solution for recovering time-varying graph signals. Building upon GegenConv, we design the Gegenbauer-based time Graph Neural Network (GegenGNN) architecture, which adopts an encoder-decoder structure. Likewise, our approach also utilizes a dedicated loss function that incorporates a mean squared error component alongside Sobolev smoothness regularization. This combination enables GegenGNN to capture both the fidelity to ground truth and the underlying smoothness properties of the signals, enhancing the reconstruction performance. We conduct extensive experiments on real datasets to evaluate the effectiveness of our proposed approach. The experimental results demonstrate that GegenGNN outperforms state-of-the-art methods, showcasing its superior capability in recovering time-varying graph signals.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19800">https://arxiv.org/abs/2403.19800</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> The paper proposes a new model (Gegenbauer-based time Graph Neural Network) for reconstruction of time-varying graph signals, which does connect to the time series forecasting aspect. However, it does not directly touch on foundation models or multimodal aspects.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19996" target="_blank">DeepHeteroIoT: Deep Local and Global Learning over Heterogeneous IoT Sensor Data</a></h3>
            <a href="https://arxiv.org/html/2403.19996v1/extracted/5495897/figs/Mobiquitous_Revised_Diagram_New.png" target="_blank"><img src="https://arxiv.org/html/2403.19996v1/extracted/5495897/figs/Mobiquitous_Revised_Diagram_New.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Muhammad Sakib Khan Inan, Kewen Liao, Haifeng Shen, Prem Prakash Jayaraman, Dimitrios Georgakopoulos, Ming Jian Tang</p>
            <p><strong>Summary:</strong> arXiv:2403.19996v1 Announce Type: new 
Abstract: Internet of Things (IoT) sensor data or readings evince variations in timestamp range, sampling frequency, geographical location, unit of measurement, etc. Such presented sequence data heterogeneity makes it difficult for traditional time series classification algorithms to perform well. Therefore, addressing the heterogeneity challenge demands learning not only the sub-patterns (local features) but also the overall pattern (global feature). To address the challenge of classifying heterogeneous IoT sensor data (e.g., categorizing sensor data types like temperature and humidity), we propose a novel deep learning model that incorporates both Convolutional Neural Network and Bi-directional Gated Recurrent Unit to learn local and global features respectively, in an end-to-end manner. Through rigorous experimentation on heterogeneous IoT sensor datasets, we validate the effectiveness of our proposed model, which outperforms recent state-of-the-art classification methods as well as several machine learning and deep learning baselines. In particular, the model achieves an average absolute improvement of 3.37% in Accuracy and 2.85% in F1-Score across datasets</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19996">https://arxiv.org/abs/2403.19996</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper could be of interest as it proposes a new deep learning model for handling heterogeneous IoT sensor data, which is a form of time series data. However, it does not propose new transformer-like models or foundation models for time series, or directly address multimodal deep learning, which are specific subtopics of your interest.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20150" target="_blank">TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods</a></h3>
            <a href="https://arxiv.org/html/2403.20150v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.20150v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xiangfei Qiu, Jilin Hu, Lekui Zhou, Xingjian Wu, Junyang Du, Buang Zhang, Chenjuan Guo, Aoying Zhou, Christian S. Jensen, Zhenli Sheng, Bin Yang</p>
            <p><strong>Summary:</strong> arXiv:2403.20150v1 Announce Type: new 
Abstract: Time series are generated in diverse domains such as economic, traffic, health, and energy, where forecasting of future values has numerous important applications. Not surprisingly, many forecasting methods are being proposed. To ensure progress, it is essential to be able to study and compare such methods empirically in a comprehensive and reliable manner. To achieve this, we propose TFB, an automated benchmark for Time Series Forecasting (TSF) methods. TFB advances the state-of-the-art by addressing shortcomings related to datasets, comparison methods, and evaluation pipelines: 1) insufficient coverage of data domains, 2) stereotype bias against traditional methods, and 3) inconsistent and inflexible pipelines. To achieve better domain coverage, we include datasets from 10 different domains: traffic, electricity, energy, the environment, nature, economic, stock markets, banking, health, and the web. We also provide a time series characterization to ensure that the selected datasets are comprehensive. To remove biases against some methods, we include a diverse range of methods, including statistical learning, machine learning, and deep learning methods, and we also support a variety of evaluation strategies and metrics to ensure a more comprehensive evaluations of different methods. To support the integration of different methods into the benchmark and enable fair comparisons, TFB features a flexible and scalable pipeline that eliminates biases. Next, we employ TFB to perform a thorough evaluation of 21 Univariate Time Series Forecasting (UTSF) methods on 8,068 univariate time series and 14 Multivariate Time Series Forecasting (MTSF) methods on 25 datasets. The benchmark code and data are available at https://github.com/decisionintelligence/TFB.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20150">https://arxiv.org/abs/2403.20150</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> The paper titled 'TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods' presents an approach to benchmarking various Time Series Forecasting (TSF) methods, with a focus on deep learning among others. It features the creation of a new and comprehensive dataset from diverse domains, which can be also used to test new methods in future. While it does not specifically propose a novel deep learning approach, it might be insightful in understanding current benchmark methodologies and strategies in TSF.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19806" target="_blank">Feature-Based Echo-State Networks: A Step Towards Interpretability and Minimalism in Reservoir Computer</a></h3>
            <a href="https://arxiv.org/html/2403.19806v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.19806v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Debdipta Goswami</p>
            <p><strong>Summary:</strong> arXiv:2403.19806v1 Announce Type: new 
Abstract: This paper proposes a novel and interpretable recurrent neural-network structure using the echo-state network (ESN) paradigm for time-series prediction. While the traditional ESNs perform well for dynamical systems prediction, it needs a large dynamic reservoir with increased computational complexity. It also lacks interpretability to discern contributions from different input combinations to the output. Here, a systematic reservoir architecture is developed using smaller parallel reservoirs driven by different input combinations, known as features, and then they are nonlinearly combined to produce the output. The resultant feature-based ESN (Feat-ESN) outperforms the traditional single-reservoir ESN with less reservoir nodes. The predictive capability of the proposed architecture is demonstrated on three systems: two synthetic datasets from chaotic dynamical systems and a set of real-time traffic data.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19806">https://arxiv.org/abs/2403.19806</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 3.5</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper discusses a new method for time series prediction using echo-state network paradigm, which might interest you. However, it does not specifically focus on deep learning, multimodal models, or transformer-like models.</p>
        </div>
        </div><h2 onclick="toggleSection('section_llm-agents')">Llm-agents</h2><div id='section_llm-agents' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19925" target="_blank">Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces</a></h3>
            <a href="https://arxiv.org/html/2403.19925v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.19925v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Toshihiro Ota</p>
            <p><strong>Summary:</strong> arXiv:2403.19925v1 Announce Type: new 
Abstract: Decision Transformer, a promising approach that applies Transformer architectures to reinforcement learning, relies on causal self-attention to model sequences of states, actions, and rewards. While this method has shown competitive results, this paper investigates the integration of the Mamba framework, known for its advanced capabilities in efficient and effective sequence modeling, into the Decision Transformer architecture, focusing on the potential performance enhancements in sequential decision-making tasks. Our study systematically evaluates this integration by conducting a series of experiments across various decision-making environments, comparing the modified Decision Transformer, Decision Mamba, with its traditional counterpart. This work contributes to the advancement of sequential decision-making models, suggesting that the architecture and training methodology of neural networks can significantly impact their performance in complex tasks, and highlighting the potential of Mamba as a valuable tool for improving the efficacy of Transformer-based models in reinforcement learning scenarios.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19925">https://arxiv.org/abs/2403.19925</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is about an investigation into the integration of the Mamba framework with the Decision Transformer architecture. A part of your interests is on agents based on large language models, and the transformer is a type of large language model. Even though the paper does not directly speak of controlling software or browsers, the study's scope in enhancing performance in sequential decision-making tasks can be applicable and relevant to your interests.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20208" target="_blank">Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science</a></h3>
            
            <p><strong>Authors:</strong> Yazheng Yang, Yuqi Wang, Sankalok Sen, Lei Li, Qi Liu</p>
            <p><strong>Summary:</strong> arXiv:2403.20208v1 Announce Type: new 
Abstract: In the domain of data science, the predictive tasks of classification, regression, and imputation of missing values are commonly encountered challenges associated with tabular data. This research endeavors to apply Large Language Models (LLMs) towards addressing these predictive tasks. Despite their proficiency in comprehending natural language, LLMs fall short in dealing with structured tabular data. This limitation stems from their lacking exposure to the intricacies of tabular data during their foundational training. Our research aims to mitigate this gap by compiling a comprehensive corpus of tables annotated with instructions and executing large-scale training of Llama-2 on this enriched dataset. Furthermore, we investigate the practical application of applying the trained model to zero-shot prediction, few-shot prediction, and in-context learning scenarios. Through extensive experiments, our methodology has shown significant improvements over existing benchmarks. These advancements highlight the efficacy of tailoring LLM training to solve table-related problems in data science, thereby establishing a new benchmark in the utilization of LLMs for enhancing tabular intelligence.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20208">https://arxiv.org/abs/2403.20208</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interests as it deals with the application of Large Language Models (LLMs) towards predictive tasks in the field of data science, which corresponds to your interest in agents based on large-language models. However, it got a 4 instead of 5 because it does not specifically mention controlling software or web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19708" target="_blank">AttentionStore: Cost-effective Attention Reuse across Multi-turn Conversations in Large Language Model Serving</a></h3>
            <a href="https://arxiv.org/html/2403.19708v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.19708v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Bin Gao, Zhuomin He, Puru Sharma, Qingxuan Kang, Djordje Jevdjic, Junbo Deng, Xingkun Yang, Zhou Yu, Pengfei Zuo</p>
            <p><strong>Summary:</strong> arXiv:2403.19708v1 Announce Type: cross 
Abstract: Interacting with humans through multi-turn conversations is a fundamental feature of large language models (LLMs). However, existing LLM serving engines for executing multi-turn conversations are inefficient due to the need to repeatedly compute the key-value (KV) caches of historical tokens, incurring high serving costs. To address the problem, this paper proposes AttentionStore, a new attention mechanism that enables the reuse of KV caches (i.e., attention reuse) across multi-turn conversations, significantly reducing the repetitive computation overheads. AttentionStore maintains a hierarchical KV caching system that leverages cost-effective memory/storage mediums to save KV caches for all requests. To reduce KV cache access overheads from slow mediums, AttentionStore employs layer-wise pre-loading and asynchronous saving schemes to overlap the KV cache access with the GPU computation. To ensure that the KV caches to be accessed are placed in the fastest hierarchy, AttentionStore employs scheduler-aware fetching and eviction schemes to consciously place the KV caches in different layers based on the hints from the inference job scheduler. To avoid the invalidation of the saved KV caches incurred by context window overflow, AttentionStore enables the saved KV caches to remain valid via decoupling the positional encoding and effectively truncating the KV caches. Extensive experimental results demonstrate that AttentionStore significantly decreases the time to the first token (TTFT) by up to 88%, improves the prompt prefilling throughput by 8.2$\times$ for multi-turn conversations, and reduces the end-to-end inference cost by up to 56%. For long sequence inference, AttentionStore reduces the TTFT by up to 95% and improves the prompt prefilling throughput by 22$\times$.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19708">https://arxiv.org/abs/2403.19708</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper may be of interest as it discusses improving efficiency and reducing costs in large language model serving, which can be directly applied to large language models controlling software or automated systems. Although it does not specifically address control of web browsers or specific computer automations, its findings may have broad implications for these subtopics.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19887" target="_blank">Jamba: A Hybrid Transformer-Mamba Language Model</a></h3>
            <a href="https://arxiv.org/html/2403.19887v1/extracted/5503083/figures/AI21_logo.png" target="_blank"><img src="https://arxiv.org/html/2403.19887v1/extracted/5503083/figures/AI21_logo.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Opher Lieber, Barak Lenz, Hofit Bata, Gal Cohen, Jhonathan Osin, Itay Dalmedigos, Erez Safahi, Shaked Meirom, Yonatan Belinkov, Shai Shalev-Shwartz, Omri Abend, Raz Alon, Tomer Asida, Amir Bergman, Roman Glozman, Michael Gokhman, Avashalom Manevich, Nir Ratner, Noam Rozen, Erez Shwartz, Mor Zusman, Yoav Shoham</p>
            <p><strong>Summary:</strong> arXiv:2403.19887v1 Announce Type: cross 
Abstract: We present Jamba, a new base large language model based on a novel hybrid Transformer-Mamba mixture-of-experts (MoE) architecture. Specifically, Jamba interleaves blocks of Transformer and Mamba layers, enjoying the benefits of both model families. MoE is added in some of these layers to increase model capacity while keeping active parameter usage manageable. This flexible architecture allows resource- and objective-specific configurations. In the particular configuration we have implemented, we end up with a powerful model that fits in a single 80GB GPU. Built at large scale, Jamba provides high throughput and small memory footprint compared to vanilla Transformers, and at the same time state-of-the-art performance on standard language model benchmarks and long-context evaluations. Remarkably, the model presents strong results for up to 256K tokens context length. We study various architectural decisions, such as how to combine Transformer and Mamba layers, and how to mix experts, and show that some of them are crucial in large scale modeling. We also describe several interesting properties of these architectures which the training and evaluation of Jamba have revealed, and plan to release checkpoints from various ablation runs, to encourage further exploration of this novel architecture. We make the weights of our implementation of Jamba publicly available under a permissive license.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19887">https://arxiv.org/abs/2403.19887</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper fits with your interest in 'Agents based on large-language models.' It presents a new large language model with increased capacity and improved performance. While it does not specifically mention controlling software or web browsers, its advancements might be beneficial for these applications.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19928" target="_blank">DiJiang: Efficient Large Language Models through Compact Kernelization</a></h3>
            <a href="https://arxiv.org/html/2403.19928v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.19928v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Hanting Chen, Zhicheng Liu, Xutao Wang, Yuchuan Tian, Yunhe Wang</p>
            <p><strong>Summary:</strong> arXiv:2403.19928v1 Announce Type: cross 
Abstract: In an effort to reduce the computational load of Transformers, research on linear attention has gained significant momentum. However, the improvement strategies for attention mechanisms typically necessitate extensive retraining, which is impractical for large language models with a vast array of parameters. In this paper, we present DiJiang, a novel Frequency Domain Kernelization approach that enables the transformation of a pre-trained vanilla Transformer into a linear complexity model with little training costs. By employing a weighted Quasi-Monte Carlo method for sampling, the proposed approach theoretically offers superior approximation efficiency. To further reduce the training computational complexity, our kernelization is based on Discrete Cosine Transform (DCT) operations. Extensive experiments demonstrate that the proposed method achieves comparable performance to the original Transformer, but with significantly reduced training costs and much faster inference speeds. Our DiJiang-7B achieves comparable performance with LLaMA2-7B on various benchmark while requires only about 1/50 training cost. Code is available at https://github.com/YuchuanTian/DiJiang.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19928">https://arxiv.org/abs/2403.19928</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper, while not directly discussing agents, covers the topic of optimized large language models, which could be beneficial in the context of controlling software and web browsers as an agent due to faster inference speeds and reduced training costs.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.19962" target="_blank">Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning</a></h3>
            <a href="https://arxiv.org/html/2403.19962v1/extracted/5503275/Figs/agent-intro.png" target="_blank"><img src="https://arxiv.org/html/2403.19962v1/extracted/5503275/Figs/agent-intro.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Qinhao Zhou, Zihan Zhang, Xiang Xiang, Ke Wang, Yuchuan Wu, Yongbin Li</p>
            <p><strong>Summary:</strong> arXiv:2403.19962v1 Announce Type: cross 
Abstract: Open-source pre-trained Large Language Models (LLMs) exhibit strong language understanding and generation capabilities, making them highly successful in a variety of tasks. However, when used as agents for dealing with complex problems in the real world, their performance is far inferior to large commercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need to have the capabilities of task planning, long-term memory, and the ability to leverage external tools to achieve satisfactory performance. Various methods have been proposed to enhance the agent capabilities of LLMs. On the one hand, methods involve constructing agent-specific data and fine-tuning the models. On the other hand, some methods focus on designing prompts that effectively activate the reasoning abilities of the LLMs. We explore both strategies on the 7B and 13B models. We propose a comprehensive method for constructing agent-specific data using GPT-4. Through supervised fine-tuning with constructed data, we find that for these models with a relatively small number of parameters, supervised fine-tuning can significantly reduce hallucination outputs and formatting errors in agent tasks. Furthermore, techniques such as multi-path reasoning and task decomposition can effectively decrease problem complexity and enhance the performance of LLMs as agents. We evaluate our method on five agent tasks of AgentBench and achieve satisfactory results.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19962">https://arxiv.org/abs/2403.19962</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper discusses the use of Large Language Models as agents, which aligns with your interest in exploring the usage of such agents in controlling software or browsers. It proposes methods to enhance the agent capabilities of LLMs, including strategies like constructing agent-specific data and fine-tuning the models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20252" target="_blank">Using LLMs to Model the Beliefs and Preferences of Targeted Populations</a></h3>
            <a href="https://arxiv.org/html/2403.20252v1/extracted/5504545/fig/main_fig_v2.png" target="_blank"><img src="https://arxiv.org/html/2403.20252v1/extracted/5504545/fig/main_fig_v2.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Keiichi Namikoshi, Alex Filipowicz, David A. Shamma, Rumen Iliev, Candice L. Hogan, Nikos Arechiga</p>
            <p><strong>Summary:</strong> arXiv:2403.20252v1 Announce Type: cross 
Abstract: We consider the problem of aligning a large language model (LLM) to model the preferences of a human population. Modeling the beliefs, preferences, and behaviors of a specific population can be useful for a variety of different applications, such as conducting simulated focus groups for new products, conducting virtual surveys, and testing behavioral interventions, especially for interventions that are expensive, impractical, or unethical. Existing work has had mixed success using LLMs to accurately model human behavior in different contexts. We benchmark and evaluate two well-known fine-tuning approaches and evaluate the resulting populations on their ability to match the preferences of real human respondents on a survey of preferences for battery electric vehicles (BEVs). We evaluate our models against their ability to match population-wide statistics as well as their ability to match individual responses, and we investigate the role of temperature in controlling the trade-offs between these two. Additionally, we propose and evaluate a novel loss term to improve model performance on responses that require a numeric response.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20252">https://arxiv.org/abs/2403.20252</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper aligns with your interest in using large language models in simulated situations. The paper discusses aligning a Large Language Model (LLM) to model the preferences of a human population and is thus related to controlling software/web actions based on human responses.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20262" target="_blank">ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models</a></h3>
            <a href="https://arxiv.org/html/2403.20262v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.20262v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Thibaut Thonet, Jos Rozen, Laurent Besacier</p>
            <p><strong>Summary:</strong> arXiv:2403.20262v1 Announce Type: cross 
Abstract: Research on Large Language Models (LLMs) has recently witnessed an increasing interest in extending models' context size to better capture dependencies within long documents. While benchmarks have been proposed to assess long-range abilities, existing efforts primarily considered generic tasks that are not necessarily aligned with real-world applications. In contrast, our work proposes a new benchmark for long-context LLMs focused on a practical meeting assistant scenario. In this scenario, the long contexts consist of transcripts obtained by automatic speech recognition, presenting unique challenges for LLMs due to the inherent noisiness and oral nature of such data. Our benchmark, named ELITR-Bench, augments the existing ELITR corpus' transcripts with 271 manually crafted questions and their ground-truth answers. Our experiments with recent long-context LLMs on ELITR-Bench highlight a gap between open-source and proprietary models, especially when questions are asked sequentially within a conversation. We also provide a thorough analysis of our GPT-4-based evaluation method, encompassing insights from a crowdsourcing study. Our findings suggest that while GPT-4's evaluation scores are correlated with human judges', its ability to differentiate among more than three score levels may be limited.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20262">https://arxiv.org/abs/2403.20262</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> Although this paper is primarily about the benchmarking of Large Language Models (LLMs), it is aligned with your interest in agents based on large language models. The practical meeting assistant scenario that the paper elaborates on can be seen as an application of LLM agent controlling a software (i.e., meeting assistant software). However, it doesn't primarily focus on proposing new methods pertaining to LLMs' application to software control, hence, the score of 4.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20329" target="_blank">ReALM: Reference Resolution As Language Modeling</a></h3>
            <a href="https://arxiv.org/html/2403.20329v1/extracted/5502621/figures/onscreen_annotation.png" target="_blank"><img src="https://arxiv.org/html/2403.20329v1/extracted/5502621/figures/onscreen_annotation.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Joel Ruben Antony Moniz, Soundarya Krishnan, Melis Ozyildirim, Prathamesh Saraf, Halim Cagri Ates, Yuan Zhang, Hong Yu, Nidhi Rajshree</p>
            <p><strong>Summary:</strong> arXiv:2403.20329v1 Announce Type: cross 
Abstract: Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user's screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of references, with our smallest model obtaining absolute gains of over 5% for on-screen references. We also benchmark against GPT-3.5 and GPT-4, with our smallest model achieving performance comparable to that of GPT-4, and our larger models substantially outperforming it.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20329">https://arxiv.org/abs/2403.20329</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is related to using large language models (LLMs) to understand and manipulate context, including non-conversational entities such as software applications. It showcases how LLMs can be used to resolve various types of on-screen references, which alludes to controlling software through large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2304.14178" target="_blank">mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality</a></h3>
            <a href="https://arxiv.org/html/2304.14178v3/extracted/5503797/logo_new.png" target="_blank"><img src="https://arxiv.org/html/2304.14178v3/extracted/5503797/logo_new.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou</p>
            <p><strong>Summary:</strong> arXiv:2304.14178v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tune a low-rank adaption (LoRA) module on LLM and the abstractor module by freezing the visual knowledge module. We carefully build a visually-related instruction evaluation set OwlEval. Experimental results show that our model outperforms existing multi-modal models, demonstrating mPLUG-Owl's impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. Besides, we observe some unexpected and exciting abilities such as multi-image correlation and scene text understanding, which makes it possible to leverage it for harder real scenarios, such as vision-only document comprehension. Our code, pre-trained model, instruction-tuned models, and evaluation set are available at https://github.com/X-PLUG/mPLUG-Owl. The online demo is available at https://www.modelscope.cn/studios/damo/mPLUG-Owl.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2304.14178">https://arxiv.org/abs/2304.14178</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> Although the paper is not strictly discussing controlling agents, it does provide valuable research on building large language models to understand and deal with multimodality, which could be largely beneficial for the goal of controlling software or web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.05269" target="_blank">LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos</a></h3>
            <a href="https://arxiv.org/html/2312.05269v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2312.05269v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Ying Wang, Yanlai Yang, Mengye Ren</p>
            <p><strong>Summary:</strong> arXiv:2312.05269v2 Announce Type: replace-cross 
Abstract: In this paper we introduce LifelongMemory, a new framework for accessing long-form egocentric videographic memory through natural language question answering and retrieval. LifelongMemory generates concise video activity descriptions of the camera wearer and leverages the zero-shot capabilities of pretrained large language models to perform reasoning over long-form video context. Furthermore, Lifelong Memory uses a confidence and explanation module to produce confident, high-quality, and interpretable answers. Our approach achieves state-of-the-art performance on the EgoSchema benchmark for question answering and is highly competitive on the natural language query (NLQ) challenge of Ego4D. Code is available at https://github.com/Agentic-Learning-AI-Lab/lifelong-memory.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.05269">https://arxiv.org/abs/2312.05269</a></p>
            <p><strong>Category:</strong> cs.CV</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in using large language models for control tasks. In this instance, the task is to generate descriptions and answer queries from long-form egocentric videographic content. The paper introduces a new framework called LifelongMemory that leverages pretrained large language models. However, it does not specifically talk about controlling software or web browsers, hence the score isn't a perfect 5.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.10189" target="_blank">Uncertainty Quantification for In-Context Learning of Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2402.10189v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2402.10189v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Chen Ling, Xujiang Zhao, Xuchao Zhang, Wei Cheng, Yanchi Liu, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Jie Ji, Guangji Bai, Liang Zhao, Haifeng Chen</p>
            <p><strong>Summary:</strong> arXiv:2402.10189v2 Announce Type: replace-cross 
Abstract: In-context learning has emerged as a groundbreaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM's response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM's response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model's configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-context learning in a plug-and-play fashion. Extensive experiments are conducted to demonstrate the effectiveness of the decomposition. The code and data are available at: https://github.com/lingchen0331/UQ_ICL.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.10189">https://arxiv.org/abs/2402.10189</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper may be of interest as it discusses in-depth the uncertainties faced while using Large Language Models for tasks. Though it doesn't directly mention controlling software or web browsers, it gives an understanding of the challenges faced in using these models, which could be beneficial when developing control algorithms.</p>
        </div>
        </div><h2 onclick="toggleSection('section_causality')">Causality</h2><div id='section_causality' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20250" target="_blank">Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures</a></h3>
            <a href="https://arxiv.org/html/2403.20250v1/extracted/5504639/thresholdPolicy.png" target="_blank"><img src="https://arxiv.org/html/2403.20250v1/extracted/5504639/thresholdPolicy.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Giovanni Cerulli</p>
            <p><strong>Summary:</strong> arXiv:2403.20250v1 Announce Type: cross 
Abstract: This paper deals with optimal policy learning (OPL) with observational data, i.e. data-driven optimal decision-making, in multi-action (or multi-arm) settings, where a finite set of decision options is available. It is organized in three parts, where I discuss respectively: estimation, risk preference, and potential failures. The first part provides a brief review of the key approaches to estimating the reward (or value) function and optimal policy within this context of analysis. Here, I delineate the identification assumptions and statistical properties related to offline optimal policy learning estimators. In the second part, I delve into the analysis of decision risk. This analysis reveals that the optimal choice can be influenced by the decision maker's attitude towards risks, specifically in terms of the trade-off between reward conditional mean and conditional variance. Here, I present an application of the proposed model to real data, illustrating that the average regret of a policy with multi-valued treatment is contingent on the decision-maker's attitude towards risk. The third part of the paper discusses the limitations of optimal data-driven decision-making by highlighting conditions under which decision-making can falter. This aspect is linked to the failure of the two fundamental assumptions essential for identifying the optimal choice: (i) overlapping, and (ii) unconfoundedness. Some conclusions end the paper.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20250">https://arxiv.org/abs/2403.20250</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> Although this doesn't directly mention causal discovery, the elements of optimal policy learning with observational data have overlaps with causality in machine learning. The discussion on decision risk could also connect to involving a decision maker's attitude towards risks, potentially relating to a causal-relation. However, it doesn't strictly propose new methods which is a criterion for your interest.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.20287" target="_blank">Benchmarking Counterfactual Image Generation</a></h3>
            <a href="https://arxiv.org/html/2403.20287v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2403.20287v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Thomas Melistas, Nikos Spyrou, Nefeli Gkouti, Pedro Sanchez, Athanasios Vlontzos, Giorgos Papanastasiou, Sotirios A. Tsaftaris</p>
            <p><strong>Summary:</strong> arXiv:2403.20287v1 Announce Type: cross 
Abstract: Counterfactual image generation is pivotal for understanding the causal relations of variables, with applications in interpretability and generation of unbiased synthetic data. However, evaluating image generation is a long-standing challenge in itself. The need to evaluate counterfactual generation compounds on this challenge, precisely because counterfactuals, by definition, are hypothetical scenarios without observable ground truths. In this paper, we present a novel comprehensive framework aimed at benchmarking counterfactual image generation methods. We incorporate metrics that focus on evaluating diverse aspects of counterfactuals, such as composition, effectiveness, minimality of interventions, and image realism. We assess the performance of three distinct conditional image generation model types, based on the Structural Causal Model paradigm. Our work is accompanied by a user-friendly Python package which allows to further evaluate and benchmark existing and future counterfactual image generation methods. Our framework is extendable to additional SCM and other causal methods, generative models, and datasets.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.20287">https://arxiv.org/abs/2403.20287</a></p>
            <p><strong>Category:</strong> cs.CV</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in 'Causality and machine learning'. It focuses on counterfactual image generation, a topic closely tied to causal representation learning. Additionally, the paper presents a framework to benchmark various aspects of counterfactuals, making it a valuable resource for understanding advancements in the field.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.13240" target="_blank">Transparency challenges in policy evaluation with causal machine learning -- improving usability and accountability</a></h3>
            <a href="https://arxiv.org/html/2310.13240v2/extracted/5503193/media/overall_waterfall.png" target="_blank"><img src="https://arxiv.org/html/2310.13240v2/extracted/5503193/media/overall_waterfall.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Patrick Rehill, Nicholas Biddle</p>
            <p><strong>Summary:</strong> arXiv:2310.13240v2 Announce Type: replace 
Abstract: Causal machine learning tools are beginning to see use in real-world policy evaluation tasks to flexibly estimate treatment effects. One issue with these methods is that the machine learning models used are generally black boxes, i.e., there is no globally interpretable way to understand how a model makes estimates. This is a clear problem in policy evaluation applications, particularly in government, because it is difficult to understand whether such models are functioning in ways that are fair, based on the correct interpretation of evidence and transparent enough to allow for accountability if things go wrong. However, there has been little discussion of transparency problems in the causal machine learning literature and how these might be overcome. This paper explores why transparency issues are a problem for causal machine learning in public policy evaluation applications and considers ways these problems might be addressed through explainable AI tools and by simplifying models in line with interpretable AI principles. It then applies these ideas to a case-study using a causal forest model to estimate conditional average treatment effects for a hypothetical change in the school leaving age in Australia. It shows that existing tools for understanding black-box predictive models are poorly suited to causal machine learning and that simplifying the model to make it interpretable leads to an unacceptable increase in error (in this application). It concludes that new tools are needed to properly understand causal machine learning models and the algorithms that fit them.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.13240">https://arxiv.org/abs/2310.13240</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> While it does not propose a new method, it discusses the challenges in implementing Causal Machine Learning including transparency issues. It also discusses tools that might better understand causal machine learning models which can be relevant to your interest in causal discovery and representation.</p>
        </div>
        </div><div class='timestamp'>Report generated on April 01, 2024 at 21:32:27</div></body></html>