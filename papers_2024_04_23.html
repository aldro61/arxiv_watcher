
            <html>
            <head>
                <title>Report Generated on April 23, 2024</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .paper-box {
                        background-color: #f0f0f0;
                        margin-bottom: 20px;
                        padding: 15px;
                        border-radius: 5px;
                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    }
                    h1 { text-align: center; }
                    h2 {
                        cursor: pointer;
                        color: #333;
                        border-bottom: 2px solid #666;
                    }
                    a { color: #337ab7; text-decoration: none; }
                    a:hover { text-decoration: underline; }
                    h3 { color: #337ab7; }
                    .timestamp { text-align: center; font-size: small; margin-top: 40px; }
                    .paper-figure {
                        max-width: 200px;
                        border: 1px solid #ddd;
                        border-radius: 4px;
                        padding: 5px;
                        margin-top: 10px;
                    }
                    .papers-container { display: block; padding: 0 18px; }
                </style>
            </head>
            <body>
            <h1>Report for April 23, 2024</h1>
            <script>
                function toggleSection(id) {
                    var x = document.getElementById(id);
                    if (x.style.display === "none") {
                        x.style.display = "block";
                    } else {
                        x.style.display = "none";
                    }
                }
            </script>
            <h2 onclick="toggleSection('section_llm-agents')">Llm-agents</h2><div id='section_llm-agents' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2403.07718" target="_blank">WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?</a></h3>
            <a href="https://arxiv.org/html/2403.07718v2/extracted/5549867/figures/snowoverview.jpg" target="_blank"><img src="https://arxiv.org/html/2403.07718v2/extracted/5549867/figures/snowoverview.jpg" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Alexandre Drouin, Maxime Gasse, Massimo Caccia, Issam H. Laradji, Manuel Del Verme, Tom Marty, L\'eo Boisvert, Megh Thakkar, Quentin Cappart, David Vazquez, Nicolas Chapados, Alexandre Lacoste</p>
            <p><strong>Summary:</strong> arXiv:2403.07718v2 Announce Type: replace 
Abstract: We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.07718">https://arxiv.org/abs/2403.07718</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is highly relevant to your interest in large language model-based agents for controlling software and web browsers. It introduces WorkArena, a benchmarking tool for measuring these agents' capabilities using the ServiceNow platform. Although it doesn't propose a new method, it indicates an area of growth and future research within this field which might be of interest to you.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13208" target="_blank">The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions</a></h3>
            <a href="https://arxiv.org/html/2404.13208v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13208v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng, Johannes Heidecke, Alex Beutel</p>
            <p><strong>Summary:</strong> arXiv:2404.13208v1 Announce Type: cross 
Abstract: Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts. In this work, we argue that one of the primary vulnerabilities underlying these attacks is that LLMs often consider system prompts (e.g., text from an application developer) to be the same priority as text from untrusted users and third parties. To address this, we propose an instruction hierarchy that explicitly defines how models should behave when instructions of different priorities conflict. We then propose a data generation method to demonstrate this hierarchical instruction following behavior, which teaches LLMs to selectively ignore lower-privileged instructions. We apply this method to GPT-3.5, showing that it drastically increases robustness -- even for attack types not seen during training -- while imposing minimal degradations on standard capabilities.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13208">https://arxiv.org/abs/2404.13208</a></p>
            <p><strong>Category:</strong> cs.CR</p>
            <p><strong>Interest score:</strong> 4.5</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is somewhat relevant to your interests, specifically in the areas of using large language models for control and automation. Although it doesn't explicitly discuss controlling software or web browsers, it does delve into how language models can prioritize instructions, which has direct applications in controlling various systems.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13238" target="_blank">Personalized Wireless Federated Learning for Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2404.13238v1/extracted/5543931/FedLLM0_2.png" target="_blank"><img src="https://arxiv.org/html/2404.13238v1/extracted/5543931/FedLLM0_2.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Feibo Jiang, Li Dong, Siwei Tu, Yubo Peng, Kezhi Wang, Kun Yang, Cunhua Pan, Dusit Niyato</p>
            <p><strong>Summary:</strong> arXiv:2404.13238v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have revolutionized natural language processing tasks. However, their deployment in wireless networks still face challenges, i.e., a lack of privacy and security protection mechanisms. Federated Learning (FL) has emerged as a promising approach to address these challenges. Yet, it suffers from issues including inefficient handling with big and heterogeneous data, resource-intensive training, and high communication overhead. To tackle these issues, we first compare different learning stages and their features of LLMs in wireless networks. Next, we introduce two personalized wireless federated fine-tuning methods with low communication overhead, i.e., (1) Personalized Federated Instruction Tuning (PFIT), which employs reinforcement learning to fine-tune local LLMs with diverse reward models to achieve personalization; (2) Personalized Federated Task Tuning (PFTT), which can leverage global adapters and local Low-Rank Adaptations (LoRA) to collaboratively fine-tune local LLMs, where the local LoRAs can be applied to achieve personalization without aggregation. Finally, we perform simulations to demonstrate the effectiveness of the proposed two methods and comprehensively discuss open issues.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13238">https://arxiv.org/abs/2404.13238</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> Though this paper does not directly mention controlling software or web browsers with LLMs, it discusses federated learning methods relevant to training LLMs in wireless networks. It can be of interest given its exploration on personalization of LLMs and their potential applications.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13571" target="_blank">Test-Time Training on Graphs with Large Language Models (LLMs)</a></h3>
            <a href="https://arxiv.org/html/2404.13571v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13571v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jiaxin Zhang, Yiqi Wang, Xihong Yang, Siwei Wang, Yu Feng, Yu Shi, Ruicaho Ren, En Zhu, Xinwang Liu</p>
            <p><strong>Summary:</strong> arXiv:2404.13571v1 Announce Type: new 
Abstract: Graph Neural Networks have demonstrated great success in various fields of multimedia. However, the distribution shift between the training and test data challenges the effectiveness of GNNs. To mitigate this challenge, Test-Time Training (TTT) has been proposed as a promising approach. Traditional TTT methods require a demanding unsupervised training strategy to capture the information from test to benefit the main task. Inspired by the great annotation ability of Large Language Models (LLMs) on Text-Attributed Graphs (TAGs), we propose to enhance the test-time training on graphs with LLMs as annotators. In this paper, we design a novel Test-Time Training pipeline, LLMTTT, which conducts the test-time adaptation under the annotations by LLMs on a carefully-selected node set. Specifically, LLMTTT introduces a hybrid active node selection strategy that considers not only node diversity and representativeness, but also prediction signals from the pre-trained model. Given annotations from LLMs, a two-stage training strategy is designed to tailor the test-time model with the limited and noisy labels. A theoretical analysis ensures the validity of our method and extensive experiments demonstrate that the proposed LLMTTT can achieve a significant performance improvement compared to existing Out-of-Distribution (OOD) generalization methods.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13571">https://arxiv.org/abs/2404.13571</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper seems relevant to your interests in large language models used in controlling software, including GNNs. It proposes a novel Test-Time Training pipeline where LLMs play a critical role. However, it's not directly involved in web browsers or specific computer automation applications, hence it scores 4 out of 5.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13752" target="_blank">Towards General Conceptual Model Editing via Adversarial Representation Engineering</a></h3>
            <a href="https://arxiv.org/html/2404.13752v1/extracted/5550230/figure/edit.png" target="_blank"><img src="https://arxiv.org/html/2404.13752v1/extracted/5550230/figure/edit.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yihao Zhang, Zeming Wei, Jun Sun, Meng Sun</p>
            <p><strong>Summary:</strong> arXiv:2404.13752v1 Announce Type: new 
Abstract: Recent research has introduced Representation Engineering (RepE) as a promising approach for understanding complex inner workings of large-scale models like Large Language Models (LLMs). However, finding practical and efficient methods to apply these representations for general and flexible model editing remains an open problem. Inspired by the Generative Adversarial Network (GAN) framework, we introduce a novel approach called Adversarial Representation Engineering (ARE). This method leverages RepE by using a representation sensor to guide the editing of LLMs, offering a unified and interpretable framework for conceptual model editing without degrading baseline performance. Our experiments on multiple conceptual editing confirm ARE's effectiveness. Code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13752">https://arxiv.org/abs/2404.13752</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in 'Agents based on large language models'. It discusses the Adversarial Representation Engineering (ARE) method for editing Large Language Models and has potential implications for controlling software or automating systems using these models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.14047" target="_blank">How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study</a></h3>
            <a href="https://arxiv.org/html/2404.14047v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.14047v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Wei Huang, Xudong Ma, Haotong Qin, Xingyu Zheng, Chengtao Lv, Hong Chen, Jie Luo, Xiaojuan Qi, Xianglong Liu, Michele Magno</p>
            <p><strong>Summary:</strong> arXiv:2404.14047v1 Announce Type: new 
Abstract: Meta's LLaMA family has become one of the most powerful open-source Large Language Model (LLM) series. Notably, LLaMA3 models have recently been released and achieve impressive performance across various with super-large scale pre-training on over 15T tokens of data. Given the wide application of low-bit quantization for LLMs in resource-limited scenarios, we explore LLaMA3's capabilities when quantized to low bit-width. This exploration holds the potential to unveil new insights and challenges for low-bit quantization of LLaMA3 and other forthcoming LLMs, especially in addressing performance degradation problems that suffer in LLM compression. Specifically, we evaluate the 10 existing post-training quantization and LoRA-finetuning methods of LLaMA3 on 1-8 bits and diverse datasets to comprehensively reveal LLaMA3's low-bit quantization performance. Our experiment results indicate that LLaMA3 still suffers non-negligent degradation in these scenarios, especially in ultra-low bit-width. This highlights the significant performance gap under low bit-width that needs to be bridged in future developments. We expect that this empirical study will prove valuable in advancing future models, pushing the LLMs to lower bit-width with higher accuracy for being practical. Our project is released on https://github.com/Macaronlin/LLaMA3-Quantization and quantized LLaMA3 models are released in https://huggingface.co/LLMQ.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.14047">https://arxiv.org/abs/2404.14047</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The research paper is relevant as it explores the capabilities of Large Language Models, specifically LLaMA3, when quantized to low-bit width. It aligns with your interest in large language models, especially in terms of understanding their performance and providing insights which could be crucial in controlling software or web browsers. However, it doesn't specifically address employing these models for computer automation or control.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.14367" target="_blank">Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data</a></h3>
            <a href="https://arxiv.org/html/2404.14367v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.14367v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Fahim Tajwar, Anikait Singh, Archit Sharma, Rafael Rafailov, Jeff Schneider, Tengyang Xie, Stefano Ermon, Chelsea Finn, Aviral Kumar</p>
            <p><strong>Summary:</strong> arXiv:2404.14367v1 Announce Type: new 
Abstract: Learning from preference labels plays a crucial role in fine-tuning large language models. There are several distinct approaches for preference fine-tuning, including supervised learning, on-policy reinforcement learning (RL), and contrastive learning. Different methods come with different implementation tradeoffs and performance differences, and existing empirical findings present different conclusions, for instance, some results show that online RL is quite important to attain good fine-tuning results, while others find (offline) contrastive or even purely supervised methods sufficient. This raises a natural question: what kind of approaches are important for fine-tuning with preference data and why? In this paper, we answer this question by performing a rigorous analysis of a number of fine-tuning techniques on didactic and full-scale LLM problems. Our main finding is that, in general, approaches that use on-policy sampling or attempt to push down the likelihood on certain responses (i.e., employ a "negative gradient") outperform offline and maximum likelihood objectives. We conceptualize our insights and unify methods that use on-policy sampling or negative gradient under a notion of mode-seeking objectives for categorical distributions. Mode-seeking objectives are able to alter probability mass on specific bins of a categorical distribution at a fast rate compared to maximum likelihood, allowing them to relocate masses across bins more effectively. Our analysis prescribes actionable insights for preference fine-tuning of LLMs and informs how data should be collected for maximal improvement.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.14367">https://arxiv.org/abs/2404.14367</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in 'Agents based on large-language models' as it discusses preference fine-tuning in large language models. Although it does not directly discuss controlling software or browsers, the insights on fine-tuning techniques could be applicable to your particular subtopics of interest.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13077" target="_blank">Improving the Capabilities of Large Language Model Based Marketing Analytics Copilots With Semantic Search And Fine-Tuning</a></h3>
            
            <p><strong>Authors:</strong> Yilin Gao, Sai Kumar Arava, Yancheng Li, James W. Snyder Jr</p>
            <p><strong>Summary:</strong> arXiv:2404.13077v1 Announce Type: cross 
Abstract: Artificial intelligence (AI) is widely deployed to solve problems related to marketing attribution and budget optimization. However, AI models can be quite complex, and it can be difficult to understand model workings and insights without extensive implementation teams. In principle, recently developed large language models (LLMs), like GPT-4, can be deployed to provide marketing insights, reducing the time and effort required to make critical decisions. In practice, there are substantial challenges that need to be overcome to reliably use such models. We focus on domain-specific question-answering, SQL generation needed for data retrieval, and tabular analysis and show how a combination of semantic search, prompt engineering, and fine-tuning can be applied to dramatically improve the ability of LLMs to execute these tasks accurately. We compare both proprietary models, like GPT-4, and open-source models, like Llama-2-70b, as well as various embedding methods. These models are tested on sample use cases specific to marketing mix modeling and attribution.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13077">https://arxiv.org/abs/2404.13077</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper intersects with your interest in the application of large language models for tasks such as domain-specific question-answering and data retrieval. Although it does not explicitly discuss controlling software or web browsers, its exploration of how large language models can be utilized for complex tasks is relevant to your interest.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13081" target="_blank">SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs</a></h3>
            <a href="https://arxiv.org/html/2404.13081v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13081v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha, Jinwoo Shin</p>
            <p><strong>Summary:</strong> arXiv:2404.13081v1 Announce Type: cross 
Abstract: Large language models (LLMs) have made significant advancements in various natural language processing tasks, including question answering (QA) tasks. While incorporating new information with the retrieval of relevant passages is a promising way to improve QA with LLMs, the existing methods often require additional fine-tuning which becomes infeasible with recent LLMs. Augmenting retrieved passages via prompting has the potential to address this limitation, but this direction has been limitedly explored. To this end, we design a simple yet effective framework to enhance open-domain QA (ODQA) with LLMs, based on the summarized retrieval (SuRe). SuRe helps LLMs predict more accurate answers for a given question, which are well-supported by the summarized retrieval that could be viewed as an explicit rationale extracted from the retrieved passages. Specifically, SuRe first constructs summaries of the retrieved passages for each of the multiple answer candidates. Then, SuRe confirms the most plausible answer from the candidate set by evaluating the validity and ranking of the generated summaries. Experimental results on diverse ODQA benchmarks demonstrate the superiority of SuRe, with improvements of up to 4.6% in exact match (EM) and 4.0% in F1 score over standard prompting approaches. SuRe also can be integrated with a broad range of retrieval methods and LLMs. Finally, the generated summaries from SuRe show additional advantages to measure the importance of retrieved passages and serve as more preferred rationales by models and humans.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13081">https://arxiv.org/abs/2404.13081</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper could be interesting to your research, as it focuses on improving the question answering capabilities of LLMs (Large Language Models). Although it does not directly discuss controlling software or web browsers, improving the QA capability of LLMs could lead to better control automation of software and web browsers when interacting with end-users. However, because it's not directly related to the control aspect, the score is 4 and not 5.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13082" target="_blank">TREACLE: Thrifty Reasoning via Context-Aware LLM and Prompt Selection</a></h3>
            <a href="https://arxiv.org/html/2404.13082v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13082v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xuechen Zhang, Zijian Huang, Ege Onur Taga, Carlee Joe-Wong, Samet Oymak, Jiasi Chen</p>
            <p><strong>Summary:</strong> arXiv:2404.13082v1 Announce Type: cross 
Abstract: Recent successes in natural language processing have led to the proliferation of large language models (LLMs) by multiple providers. Each LLM offering has different inference accuracy, monetary cost, and latency, and their accuracy further depends on the exact wording of the question (i.e., the specific prompt). At the same time, users often have a limit on monetary budget and latency to answer all their questions, and they do not know which LLMs to choose for each question to meet their accuracy and long-term budget requirements. To navigate this rich design space, we propose TREACLE (Thrifty Reasoning via Context-Aware LLM and Prompt Selection), a reinforcement learning policy that jointly selects the model and prompting scheme while respecting the user's monetary cost and latency constraints. TREACLE uses the problem context, including question text embeddings (reflecting the type or difficulty of a query) and the response history (reflecting the consistency of previous responses) to make smart decisions. Our evaluations on standard reasoning datasets (GSM8K, CSQA, and LLC ) with various LLMs and prompts show that TREACLE enables cost savings of up to 85% compared to baselines while maintaining high accuracy. Importantly, it provides the user with the ability to gracefully trade off accuracy for cost.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13082">https://arxiv.org/abs/2404.13082</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in 'agents based on large-language models.' TREACLE, the proposed model in this paper, uses large language models for problem solving and decision making, which aligns with your interest in using large language models for control and automation objectives. Although it does not propose a new method, it offers an innovative perspective on how to navigate and efficiently use existing LLMs, which may provide valuable insights.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13096" target="_blank">Reducing Redundant Computation in Multi-Agent Coordination through Locally Centralized Execution</a></h3>
            <a href="https://arxiv.org/html/2404.13096v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13096v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yidong Bai, Toshiharu Sugawara</p>
            <p><strong>Summary:</strong> arXiv:2404.13096v1 Announce Type: cross 
Abstract: In multi-agent reinforcement learning, decentralized execution is a common approach, yet it suffers from the redundant computation problem. This occurs when multiple agents redundantly perform the same or similar computation due to overlapping observations. To address this issue, this study introduces a novel method referred to as locally centralized team transformer (LCTT). LCTT establishes a locally centralized execution framework where selected agents serve as leaders, issuing instructions, while the rest agents, designated as workers, act as these instructions without activating their policy networks. For LCTT, we proposed the team-transformer (T-Trans) architecture that allows leaders to provide specific instructions to each worker, and the leadership shift mechanism that allows agents autonomously decide their roles as leaders or workers. Our experimental results demonstrate that the proposed method effectively reduces redundant computation, does not decrease reward levels, and leads to faster learning convergence.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13096">https://arxiv.org/abs/2404.13096</a></p>
            <p><strong>Category:</strong> cs.MA</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper is relevant as it has a focus on multi-agent reinforcement learning, which is a type of large-language model-based application according to your interests. It introduces a new method which could potentially be used in computer automation, effectively making it a new method application in controlling software. However, the paper does not seem to specifically focus on controlling web browsers or primarily using large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13161" target="_blank">CyberSecEval 2: A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2404.13161v1/extracted/5547443/figs/overview_v6.png" target="_blank"><img src="https://arxiv.org/html/2404.13161v1/extracted/5547443/figs/overview_v6.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Manish Bhatt, Sahana Chennabasappa, Yue Li, Cyrus Nikolaidis, Daniel Song, Shengye Wan, Faizan Ahmad, Cornelius Aschermann, Yaohui Chen, Dhaval Kapil, David Molnar, Spencer Whitman, Joshua Saxe</p>
            <p><strong>Summary:</strong> arXiv:2404.13161v1 Announce Type: cross 
Abstract: Large language models (LLMs) introduce new security risks, but there are few comprehensive evaluation suites to measure and reduce these risks. We present BenchmarkName, a novel benchmark to quantify LLM security risks and capabilities. We introduce two new areas for testing: prompt injection and code interpreter abuse. We evaluated multiple state-of-the-art (SOTA) LLMs, including GPT-4, Mistral, Meta Llama 3 70B-Instruct, and Code Llama. Our results show that conditioning away risk of attack remains an unsolved problem; for example, all tested models showed between 26% and 41% successful prompt injection tests. We further introduce the safety-utility tradeoff: conditioning an LLM to reject unsafe prompts can cause the LLM to falsely reject answering benign prompts, which lowers utility. We propose quantifying this tradeoff using False Refusal Rate (FRR). As an illustration, we introduce a novel test set to quantify FRR for cyberattack helpfulness risk. We find many LLMs able to successfully comply with "borderline" benign requests while still rejecting most unsafe requests. Finally, we quantify the utility of LLMs for automating a core cybersecurity task, that of exploiting software vulnerabilities. This is important because the offensive capabilities of LLMs are of intense interest; we quantify this by creating novel test sets for four representative problems. We find that models with coding capabilities perform better than those without, but that further work is needed for LLMs to become proficient at exploit generation. Our code is open source and can be used to evaluate other LLMs.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13161">https://arxiv.org/abs/2404.13161</a></p>
            <p><strong>Category:</strong> cs.CR</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in 'Agents based on large-language models'. It deals with large language models and their security risks. It also explores the use of these models for automating tasks, specifically in the field of cybersecurity, which relates to your interest in automation using large language models. However, it does not directly address controlling software or web browsers.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13207" target="_blank">STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases</a></h3>
            <a href="https://arxiv.org/html/2404.13207v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13207v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Shirley Wu, Shiyu Zhao, Michihiro Yasunaga, Kexin Huang, Kaidi Cao, Qian Huang, Vassilis N. Ioannidis, Karthik Subbian, James Zou, Jure Leskovec</p>
            <p><strong>Summary:</strong> arXiv:2404.13207v1 Announce Type: cross 
Abstract: Answering real-world user queries, such as product search, often requires accurate retrieval of information from semi-structured knowledge bases or databases that involve blend of unstructured (e.g., textual descriptions of products) and structured (e.g., entity relations of products) information. However, previous works have mostly studied textual and relational retrieval tasks as separate topics. To address the gap, we develop STARK, a large-scale Semi-structure retrieval benchmark on Textual and Relational Knowledge Bases. We design a novel pipeline to synthesize natural and realistic user queries that integrate diverse relational information and complex textual properties, as well as their ground-truth answers. Moreover, we rigorously conduct human evaluation to validate the quality of our benchmark, which covers a variety of practical applications, including product recommendations, academic paper searches, and precision medicine inquiries. Our benchmark serves as a comprehensive testbed for evaluating the performance of retrieval systems, with an emphasis on retrieval approaches driven by large language models (LLMs). Our experiments suggest that the STARK datasets present significant challenges to the current retrieval and LLM systems, indicating the demand for building more capable retrieval systems that can handle both textual and relational aspects.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13207">https://arxiv.org/abs/2404.13207</a></p>
            <p><strong>Category:</strong> cs.IR</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper discusses the benchmarking of large language models retrieval systems that could be a promising area in your interest of using LLMs to control software and other automation tasks. Although it does not propose a specific method, it could provide useful insights.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13521" target="_blank">Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces</a></h3>
            <a href="https://arxiv.org/html/2404.13521v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13521v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yue Jiang, Changkong Zhou, Vikas Garg, Antti Oulasvirta</p>
            <p><strong>Summary:</strong> arXiv:2404.13521v1 Announce Type: cross 
Abstract: Present-day graphical user interfaces (GUIs) exhibit diverse arrangements of text, graphics, and interactive elements such as buttons and menus, but representations of GUIs have not kept up. They do not encapsulate both semantic and visuo-spatial relationships among elements. To seize machine learning's potential for GUIs more efficiently, Graph4GUI exploits graph neural networks to capture individual elements' properties and their semantic-visuo-spatial constraints in a layout. The learned representation demonstrated its effectiveness in multiple tasks, especially generating designs in a challenging GUI autocompletion task, which involved predicting the positions of remaining unplaced elements in a partially completed GUI. The new model's suggestions showed alignment and visual appeal superior to the baseline method and received higher subjective ratings for preference. Furthermore, we demonstrate the practical benefits and efficiency advantages designers perceive when utilizing our model as an autocompletion plug-in.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13521">https://arxiv.org/abs/2404.13521</a></p>
            <p><strong>Category:</strong> cs.HC</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper could be of interest as it discusses the use of machine learning, specifically graph neural networks, in GUI autocompletion. It pertains to your concern of using large language models for software control and automation. Although not directly addressing large language models, the paper delves into a related field which might prove insightful.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.14408" target="_blank">SpaceByte: Towards Deleting Tokenization from Large Language Modeling</a></h3>
            <a href="https://arxiv.org/html/2404.14408v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.14408v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kevin Slagle</p>
            <p><strong>Summary:</strong> arXiv:2404.14408v1 Announce Type: cross 
Abstract: Tokenization is widely used in large language models because it significantly improves performance. However, tokenization imposes several disadvantages, such as performance biases, increased adversarial vulnerability, decreased character-level modeling performance, and increased modeling complexity. To address these disadvantages without sacrificing performance, we propose SpaceByte, a novel byte-level decoder architecture that closes the performance gap between byte-level and subword autoregressive language modeling. SpaceByte consists of a byte-level Transformer model, but with extra larger transformer blocks inserted in the middle of the layers. We find that performance is significantly improved by applying these larger blocks only after certain bytes, such as space characters, which typically denote word boundaries. Our experiments show that for a fixed training and inference compute budget, SpaceByte outperforms other byte-level architectures and roughly matches the performance of tokenized Transformer architectures.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.14408">https://arxiv.org/abs/2404.14408</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper should be of interest as it focuses on the topic of large language models, specifically tackling the concept of tokenization. While it doesn't directly deal with control of software or web browsers or automation using large language models, the innovation presented could potentially influence these areas.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.10255" target="_blank">FREE: The Foundational Semantic Recognition for Modeling Environmental Ecosystems</a></h3>
            <a href="https://arxiv.org/html/2311.10255v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2311.10255v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Shiyuan Luo, Juntong Ni, Shengyu Chen, Runlong Yu, Yiqun Xie, Licheng Liu, Zhenong Jin, Huaxiu Yao, Xiaowei Jia</p>
            <p><strong>Summary:</strong> arXiv:2311.10255v2 Announce Type: replace 
Abstract: Modeling environmental ecosystems is critical for the sustainability of our planet, but is extremely challenging due to the complex underlying processes driven by interactions amongst a large number of physical variables. As many variables are difficult to measure at large scales, existing works often utilize a combination of observable features and locally available measurements or modeled values as input to build models for a specific study region and time period. This raises a fundamental question in advancing the modeling of environmental ecosystems: how to build a general framework for modeling the complex relationships amongst various environmental data over space and time? In this paper, we introduce a new framework, FREE, which maps available environmental data into a text space and then converts the traditional predictive modeling task in environmental science to the semantic recognition problem. The proposed FREE framework leverages recent advances in Large Language Models (LLMs) to supplement the original input features with natural language descriptions. This facilitates capturing the data semantics and also allows harnessing the irregularities of input features. When used for long-term prediction, FREE has the flexibility to incorporate newly collected observations to enhance future prediction. The efficacy of FREE is evaluated in the context of two societally important real-world applications, predicting stream water temperature in the Delaware River Basin and predicting annual corn yield in Illinois and Iowa. Beyond the superior predictive performance over multiple baseline methods, FREE is shown to be more data- and computation-efficient as it can be pre-trained on simulated data generated by physics-based models.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.10255">https://arxiv.org/abs/2311.10255</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper discovers a framework, FREE, which uses Large Language Models (LLMs) to perform predictive modelling in environmental science, mapping them to semantic recognition problems. It's not a direct match for any subtopic, but it does connect to large language models and their usage in automation tasks, contributing to your interest in agents based on large-language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.02937" target="_blank">Towards Responsible and Reliable Traffic Flow Prediction with Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2404.02937v4/extracted/5550050/imgs/fig0.png" target="_blank"><img src="https://arxiv.org/html/2404.02937v4/extracted/5550050/imgs/fig0.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Xusen Guo (Frank), Qiming Zhang (Frank), Junyue Jiang (Frank), Mingxing Peng (Frank),  Hao (Frank),  Yang, Meixin Zhu</p>
            <p><strong>Summary:</strong> arXiv:2404.02937v4 Announce Type: replace 
Abstract: Traffic forecasting is crucial for intelligent transportation systems. It has experienced significant advancements thanks to the power of deep learning in capturing latent patterns of traffic data. However, recent deep-learning architectures require intricate model designs and lack an intuitive understanding of the mapping from input data to predicted results. Achieving both accuracy and responsibility in traffic prediction models remains a challenge due to the complexity of traffic data and the inherent opacity of deep learning models. To tackle these challenges, we propose a Responsible and Reliable Traffic flow forecasting model with Large Language Models (R2T-LLM), which leverages large language models (LLMs) to generate responsible traffic predictions. By transferring multi-modal traffic data into natural language descriptions, R2T-LLM captures complex spatial-temporal patterns and external factors from comprehensive traffic data. The LLM framework is fine-tuned using language-based instructions to align with spatial-temporal traffic flow data. Empirically, R2T-LLM shows competitive accuracy compared with deep learning baselines, while providing an intuitive and reliable explanation for predictions. We discuss the spatial-temporal and input dependencies for conditional future flow forecasting, showcasing R2T-LLM's potential for diverse city prediction tasks. This paper contributes to advancing accountable traffic prediction models and lays a foundation for future exploration of LLM applications in transportation. To the best of our knowledge, this is the first study to use LLM for accountable and reliable prediction of traffic flows.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.02937">https://arxiv.org/abs/2404.02937</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper is relevant as it documents the use of a large language model (referred as R2T-LLM in the paper) to control and predict traffic flows, an application of using large language models for automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2306.04930" target="_blank">When to Show a Suggestion? Integrating Human Feedback in AI-Assisted Programming</a></h3>
            <a href="https://arxiv.org/html/2306.04930v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2306.04930v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz</p>
            <p><strong>Summary:</strong> arXiv:2306.04930v3 Announce Type: replace-cross 
Abstract: AI powered code-recommendation systems, such as Copilot and CodeWhisperer, provide code suggestions inside a programmer's environment (e.g., an IDE) with the aim of improving productivity. We pursue mechanisms for leveraging signals about programmers' acceptance and rejection of code suggestions to guide recommendations. We harness data drawn from interactions with GitHub Copilot, a system used by millions of programmers, to develop interventions that can save time for programmers. We introduce a utility-theoretic framework to drive decisions about suggestions to display versus withhold. The approach, conditional suggestion display from human feedback (CDHF), relies on a cascade of models that provide the likelihood that recommended code will be accepted. These likelihoods are used to selectively hide suggestions, reducing both latency and programmer verification time. Using data from 535 programmers, we perform a retrospective evaluation of CDHF and show that we can avoid displaying a significant fraction of suggestions that would have been rejected. We further demonstrate the importance of incorporating the programmer's latent unobserved state in decisions about when to display suggestions through an ablation study. Finally, we showcase how using suggestion acceptance as a reward signal for guiding the display of suggestions can lead to suggestions of reduced quality, indicating an unexpected pitfall.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2306.04930">https://arxiv.org/abs/2306.04930</a></p>
            <p><strong>Category:</strong> cs.HC</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> This paper might be of interest as it discusses the use of AI (specifically, in code recommendation) in the context of programming environments. Although it's not directly about controlling software or web browsers with large language models, it is about improving productivity in programming, which aligns with the general idea of computer automation using large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.04870" target="_blank">Lemur: Integrating Large Language Models in Automated Program Verification</a></h3>
            <a href="https://arxiv.org/html/2310.04870v4/extracted/5549170/figs/histogram_esbmc.png" target="_blank"><img src="https://arxiv.org/html/2310.04870v4/extracted/5549170/figs/histogram_esbmc.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Haoze Wu, Clark Barrett, Nina Narodytska</p>
            <p><strong>Summary:</strong> arXiv:2310.04870v4 Announce Type: replace-cross 
Abstract: The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that demands high-level abstract reasoning about program properties that is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of transition rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure and demonstrate practical improvements on a set of synthetic and competition benchmarks.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.04870">https://arxiv.org/abs/2310.04870</a></p>
            <p><strong>Category:</strong> cs.FL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper is relevant to the 'Agents based on large-language models' topic as it explores using Large Language Models for automated program verification, which can be considered a form of software control. However, it doesn't touch upon web browser control or computer automation explicitly.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2310.07712" target="_blank">Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models</a></h3>
            <a href="https://arxiv.org/html/2310.07712v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2310.07712v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Raphael Tang, Xinyu Zhang, Xueguang Ma, Jimmy Lin, Ferhan Ture</p>
            <p><strong>Summary:</strong> arXiv:2310.07712v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking. To address this, we propose permutation self-consistency, a form of self-consistency over ranking list outputs of black-box LLMs. Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias. First, given some input prompt, we repeatedly shuffle the list in the prompt and pass it through the LLM while holding the instructions the same. Next, we aggregate the resulting sample of rankings by computing the central ranking closest in distance to all of them, marginalizing out prompt order biases in the process. Theoretically, we prove the robustness of our method, showing convergence to the true ranking in the presence of random perturbations. Empirically, on five list-ranking datasets in sorting and passage reranking, our approach improves scores from conventional inference by up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous state of the art in passage reranking. Our code is at https://github.com/castorini/perm-sc.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2310.07712">https://arxiv.org/abs/2310.07712</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper focuses on large language models (LLMs) and methods to improve their ranking process, which is a key component for applications in controlling software or performing tasks such as web browsing. However, it does not directly address the concept of using LLMs for control or automation.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2312.13905" target="_blank">Domain-Specific Fine-Tuning of Large Language Models for Interactive Robot Programming</a></h3>
            
            <p><strong>Authors:</strong> Benjamin Alt, Urs Ke{\ss}ner, Aleksandar Taranovic, Darko Katic, Andreas Hermann, Rainer J\"akel, Gerhard Neumann</p>
            <p><strong>Summary:</strong> arXiv:2312.13905v2 Announce Type: replace-cross 
Abstract: Industrial robots are applied in a widening range of industries, but robot programming mostly remains a task limited to programming experts. We propose a natural language-based assistant for programming of advanced, industrial robotic applications and investigate strategies for domain-specific fine-tuning of foundation models with limited data and compute.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2312.13905">https://arxiv.org/abs/2312.13905</a></p>
            <p><strong>Category:</strong> cs.RO</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper discusses using natural language-based assistant for industrial robotic programming which is an application of using large language models to control software, reflecting your interest in computer automation using large language models.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2402.01830" target="_blank">PiCO: Peer Review in LLMs based on the Consistency Optimization</a></h3>
            <a href="https://arxiv.org/html/2402.01830v2/extracted/5548684/fig/cute.png" target="_blank"><img src="https://arxiv.org/html/2402.01830v2/extracted/5548684/fig/cute.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kun-Peng Ning, Shuo Yang, Yu-Yang Liu, Jia-Yu Yao, Zhen-Hui Liu, Yu Wang, Ming Pang, Li Yuan</p>
            <p><strong>Summary:</strong> arXiv:2402.01830v2 Announce Type: replace-cross 
Abstract: Existing large language models (LLMs) evaluation methods typically focus on testing the performance on some closed-environment and domain-specific benchmarks with human annotations. In this paper, we explore a novel unsupervised evaluation direction, utilizing peer-review mechanisms to measure LLMs automatically. In this setting, both open-source and closed-source LLMs lie in the same environment, capable of answering unlabeled questions and evaluating each other, where each LLM's response score is jointly determined by other anonymous ones. To obtain the ability hierarchy among these models, we assign each LLM a learnable capability parameter to adjust the final ranking. We formalize it as a constrained optimization problem, intending to maximize the consistency of each LLM's capabilities and scores. The key assumption behind is that high-level LLM can evaluate others' answers more accurately than low-level ones, while higher-level LLM can also achieve higher response scores. Moreover, we propose three metrics called PEN, CIN, and LIS to evaluate the gap in aligning human rankings. We perform experiments on multiple datasets with these metrics, validating the effectiveness of the proposed approach.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2402.01830">https://arxiv.org/abs/2402.01830</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> The paper shows the application of large language models (LLMs) for peer review, suggesting a step towards using LLMs to control different environments. It does not directly address control of software or browsers but it is a deeply relevant read as it explores unprecedented applications of LLMs.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.00027" target="_blank">LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning</a></h3>
            <a href="https://arxiv.org/html/2404.00027v3/extracted/5551109/fig/9_10.png" target="_blank"><img src="https://arxiv.org/html/2404.00027v3/extracted/5551109/fig/9_10.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Azmine Toushik Wasi, Mst Rafia Islam, Raima Islam</p>
            <p><strong>Summary:</strong> arXiv:2404.00027v3 Announce Type: replace-cross 
Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.00027">https://arxiv.org/abs/2404.00027</a></p>
            <p><strong>Category:</strong> cs.HC</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> While this paper does not directly ensure the use of large language models in software control or automation, it provides essential insights into the psychological interactions and perceptions between humans and large language models, that may be applied to improve such interactions in software control or automation platforms.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.06395" target="_blank">MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</a></h3>
            <a href="https://arxiv.org/html/2404.06395v2/extracted/5551071/Fig/batch_size_1.png" target="_blank"><img src="https://arxiv.org/html/2404.06395v2/extracted/5551071/Fig/batch_size_1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, Xinrong Zhang, Zheng Leng Thai, Kaihuo Zhang, Chongyi Wang, Yuan Yao, Chenyang Zhao, Jie Zhou, Jie Cai, Zhongwu Zhai, Ning Ding, Chao Jia, Guoyang Zeng, Dahai Li, Zhiyuan Liu, Maosong Sun</p>
            <p><strong>Summary:</strong> arXiv:2404.06395v2 Announce Type: replace-cross 
Abstract: The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This scenario underscores the importance of exploring the potential of Small Language Models (SLMs) as a resource-efficient alternative. In this context, we introduce MiniCPM, specifically the 1.2B and 2.4B non-embedding parameter variants, not only excel in their respective categories but also demonstrate capabilities on par with 7B-13B LLMs. While focusing on SLMs, our approach exhibits scalability in both model and data dimensions for future LLM research. Regarding model scaling, we employ extensive model wind tunnel experiments for stable and optimal scaling. For data scaling, we introduce a Warmup-Stable-Decay (WSD) learning rate scheduler (LRS), conducive to continuous training and domain adaptation. We present an in-depth analysis of the intriguing training dynamics that occurred in the WSD LRS. With WSD LRS, we are now able to efficiently study data-model scaling law without extensive retraining experiments on both axes of model and data, from which we derive the much higher compute optimal data-model ratio than Chinchilla Optimal. Additionally, we introduce MiniCPM family, including MiniCPM-DPO, MiniCPM-MoE and MiniCPM-128K, whose excellent performance further cementing MiniCPM's foundation in diverse SLM applications. MiniCPM models are available publicly at https://github.com/OpenBMB/MiniCPM .</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.06395">https://arxiv.org/abs/2404.06395</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> Although this paper does not directly address controlling software or web browsers with large language models, it introduces a MiniCPM model - a type of language model that exhibits scalability for future LLM research, which could be beneficial for developing LLM-based agents.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.08699" target="_blank">Analyzing the Impact of Data Selection and Fine-Tuning on Economic and Political Biases in LLMs</a></h3>
            <a href="https://arxiv.org/html/2404.08699v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.08699v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Ahmed Agiza, Mohamed Mostagir, Sherief Reda</p>
            <p><strong>Summary:</strong> arXiv:2404.08699v2 Announce Type: replace-cross 
Abstract: In an era where language models are increasingly integrated into decision-making and communication, understanding the biases within Large Language Models (LLMs) becomes imperative, especially when these models are applied in the economic and political domains. This work investigates the impact of fine-tuning and data selection on economic and political biases in LLM. We explore the methodological aspects of biasing LLMs towards specific ideologies, mindful of the biases that arise from their extensive training on diverse datasets. Our approach, distinct from earlier efforts that either focus on smaller models or entail resource-intensive pre-training, employs Parameter-Efficient Fine-Tuning (PEFT) techniques. These techniques allow for the alignment of LLMs with targeted ideologies by modifying a small subset of parameters. We introduce a systematic method for dataset selection, annotation, and instruction tuning, and we assess its effectiveness through both quantitative and qualitative evaluations. Our work analyzes the potential of embedding specific biases into LLMs and contributes to the dialogue on the ethical application of AI, highlighting the importance of deploying AI in a manner that aligns with societal values.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.08699">https://arxiv.org/abs/2404.08699</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> llm-agents</p>
            <p><strong>Interest justification:</strong> Although this paper doesn’t explicitly cover controlling software or browsers with large language models, it is highly relevant for understanding the biases in training such models, which is a crucial part of deploying them in practical applications like those you're interested in. It further discusses fine-tuning methodologies that could be valuable in your large language model research.</p>
        </div>
        </div><h2 onclick="toggleSection('section_time-series')">Time-series</h2><div id='section_time-series' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13257" target="_blank">ST-SSMs: Spatial-Temporal Selective State of Space Model for Traffic Forecasting</a></h3>
            <a href="https://arxiv.org/html/2404.13257v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13257v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Zhiqi Shao, Michael G. H. Bell, Ze Wang, D. Glenn Geers, Haoning Xi, Junbin Gao</p>
            <p><strong>Summary:</strong> arXiv:2404.13257v1 Announce Type: new 
Abstract: Accurate and efficient traffic prediction is crucial for planning, management, and control of intelligent transportation systems. Most state-of-the-art methods for traffic prediction effectively predict both long-term and short-term by employing spatio-temporal neural networks as prediction models, together with transformers to learn global information on prediction objects (e.g., traffic states of road segments). However, these methods often have a high computational cost to obtain good performance. This paper introduces an innovative approach to traffic flow prediction, the Spatial-Temporal Selective State Space Model (ST-SSMs), featuring the novel ST-Mamba block, which can achieve good prediction accuracy with less computational cost. A comparative analysis highlights the ST-Mamba layer's efficiency, revealing its equivalence to three attention layers, yet with markedly reduced processing time. Through rigorous testing on diverse real-world datasets, the ST-SSMs model demonstrates exceptional improvements in prediction accuracy and computational simplicity, setting new benchmarks in the domain of traffic flow forecasting</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13257">https://arxiv.org/abs/2404.13257</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in deep learning methods for time series and forecasting. However, it doesn't seem to explore new multimodal or transformer-like models, and neither does it explicitly mention new datasets for training foundation models for time series.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.14197" target="_blank">SOFTS: Efficient Multivariate Time Series Forecasting with Series-Core Fusion</a></h3>
            <a href="https://arxiv.org/html/2404.14197v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.14197v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Lu Han, Xu-Yang Chen, Han-Jia Ye, De-Chuan Zhan</p>
            <p><strong>Summary:</strong> arXiv:2404.14197v1 Announce Type: new 
Abstract: Multivariate time series forecasting plays a crucial role in various fields such as finance, traffic management, energy, and healthcare. Recent studies have highlighted the advantages of channel independence to resist distribution drift but neglect channel correlations, limiting further enhancements. Several methods utilize mechanisms like attention or mixer to address this by capturing channel correlations, but they either introduce excessive complexity or rely too heavily on the correlation to achieve satisfactory results under distribution drifts, particularly with a large number of channels. Addressing this gap, this paper presents an efficient MLP-based model, the Series-cOre Fused Time Series forecaster (SOFTS), which incorporates a novel STar Aggregate-Dispatch (STAD) module. Unlike traditional approaches that manage channel interactions through distributed structures, e.g., attention, STAD employs a centralized strategy. It aggregates all series to form a global core representation, which is then dispatched and fused with individual series representations to facilitate channel interactions effectively. SOFTS achieves superior performance over existing state-of-the-art methods with only linear complexity. The broad applicability of the STAD module across different forecasting models is also demonstrated empirically. For further research and development, we have made our code publicly available at https://github.com/Secilia-Cxy/SOFTS.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.14197">https://arxiv.org/abs/2404.14197</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper proposes a new deep learning method for time series forecasting and it deals with both multivariate time series forecasting and channel correlations, which might be of interest to you.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.14212" target="_blank">Toward Routing River Water in Land Surface Models with Recurrent Neural Networks</a></h3>
            <a href="https://arxiv.org/html/2404.14212v1/extracted/5545771/fig01a.png" target="_blank"><img src="https://arxiv.org/html/2404.14212v1/extracted/5545771/fig01a.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Mauricio Lima, Katherine Deck, Oliver R. A. Dunbar, Tapio Schneider</p>
            <p><strong>Summary:</strong> arXiv:2404.14212v1 Announce Type: cross 
Abstract: Machine learning is playing an increasing role in hydrology, supplementing or replacing physics-based models. One notable example is the use of recurrent neural networks (RNNs) for forecasting streamflow given observed precipitation and geographic characteristics. Training of such a model over the continental United States has demonstrated that a single set of model parameters can be used across independent catchments, and that RNNs can outperform physics-based models. In this work, we take a next step and study the performance of RNNs for river routing in land surface models (LSMs). Instead of observed precipitation, the LSM-RNN uses instantaneous runoff calculated from physics-based models as an input. We train the model with data from river basins spanning the globe and test it in streamflow hindcasts. The model demonstrates skill at generalization across basins (predicting streamflow in unseen catchments) and across time (predicting streamflow during years not used in training). We compare the predictions from the LSM-RNN to an existing physics-based model calibrated with a similar dataset and find that the LSM-RNN outperforms the physics-based model. Our results give further evidence that RNNs are effective for global streamflow prediction from runoff inputs and motivate the development of complete routing models that can capture nested sub-basis connections.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.14212">https://arxiv.org/abs/2404.14212</a></p>
            <p><strong>Category:</strong> physics.comp-ph</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper proposes and tests a new method of using Recurrent Neural Networks (RNNs) in the field of hydrology for forecasting. It demonstrates the application of deep learning for time series forecasting in streamflow prediction, which aligns with your interest.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2305.14244" target="_blank">Federated Prompt Learning for Weather Foundation Models on Devices</a></h3>
            <a href="https://arxiv.org/html/2305.14244v2/x1.png" target="_blank"><img src="https://arxiv.org/html/2305.14244v2/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Shengchao Chen, Guodong Long, Tao Shen, Jing Jiang, Chengqi Zhang</p>
            <p><strong>Summary:</strong> arXiv:2305.14244v2 Announce Type: replace 
Abstract: On-device intelligence for weather forecasting uses local deep learning models to analyze weather patterns without centralized cloud computing, holds significance for supporting human activates. Federated Learning is a promising solution for such forecasting by enabling collaborative model training without sharing raw data. However, it faces three main challenges that hinder its reliability: (1) data heterogeneity among devices due to geographic differences; (2) data homogeneity within individual devices and (3) communication overload from sending large model parameters for collaboration. To address these challenges, this paper propose Federated Prompt Learning for Weather Foundation Models on Devices (FedPoD), which enables devices to obtain highly customized models while maintaining communication efficiency. Concretely, our Adaptive Prompt Tuning leverages lightweight prompts guide frozen foundation model to generate more precise predictions, also conducts prompt-based multi-level communication to encourage multi-source knowledge fusion and regulate optimization. Additionally, Dynamic Graph Modeling constructs graphs from prompts, prioritizing collaborative training among devices with similar data distributions to against heterogeneity. Extensive experiments demonstrates FedPoD leads the performance among state-of-the-art baselines across various setting in real-world on-device weather forecasting datasets.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2305.14244">https://arxiv.org/abs/2305.14244</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> While this paper does not propose a new deep learning method, it does present a novel application of existing methods (Federated Learning) in the context of time-series forecasting (weather forecasting). The new approach it suggests (Federated Prompt Learning) might be of interest to you.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2306.05880" target="_blank">Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations</a></h3>
            <a href="https://arxiv.org/html/2306.05880v5/x1.png" target="_blank"><img src="https://arxiv.org/html/2306.05880v5/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Etienne Le Naour, Louis Serrano, L\'eon Migus, Yuan Yin, Ghislain Agoua, Nicolas Baskiotis, Patrick Gallinari, Vincent Guigue</p>
            <p><strong>Summary:</strong> arXiv:2306.05880v5 Announce Type: replace 
Abstract: We introduce a novel modeling approach for time series imputation and forecasting, tailored to address the challenges often encountered in real-world data, such as irregular samples, missing data, or unaligned measurements from multiple sensors. Our method relies on a continuous-time-dependent model of the series' evolution dynamics. It leverages adaptations of conditional, implicit neural representations for sequential data. A modulation mechanism, driven by a meta-learning algorithm, allows adaptation to unseen samples and extrapolation beyond observed time-windows for long-term predictions. The model provides a highly flexible and unified framework for imputation and forecasting tasks across a wide range of challenging scenarios. It achieves state-of-the-art performance on classical benchmarks and outperforms alternative time-continuous models.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2306.05880">https://arxiv.org/abs/2306.05880</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper presents a new approach to model time series dynamics using a continuous-time-dependent model with conditional, implicit neural representations. It relates to your interest in 'New deep learning methods for time series'. It's worth reading for its novel methodology and reported results.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.07202" target="_blank">Input Convex LSTM: A Convex Approach for Fast Model Predictive Control</a></h3>
            
            <p><strong>Authors:</strong> Zihao Wang, Zhe Wu</p>
            <p><strong>Summary:</strong> arXiv:2311.07202v4 Announce Type: replace 
Abstract: Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive Control (MPC) successfully attains globally optimal solutions by upholding convexity within the MPC framework. However, current ICNN architectures encounter the issue of exploding gradients, which limits their ability to serve as deep neural networks for complex tasks. Additionally, the current neural network-based MPC, including conventional neural network-based MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC based on first-principles models. In this study, we leverage the principles of ICNNs to propose a novel Input Convex LSTM for MPC, with the specific goals of mitigating the exploding gradient problems in current ICNNs and reducing convergence time for NN-based MPC. From a simulation study of a nonlinear chemical reactor, we observed a reduction in convergence time, with a percentage decrease of 46.7%, 31.3%, and 20.2% compared to baseline plain RNN, plain LSTM, and Input Convex RNN, respectively.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.07202">https://arxiv.org/abs/2311.07202</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper fits in the 'time-series' tag. It explores a new deep learning method (Input Convex LSTM) specifically designed for time series forecasting. It does not mention multimodality or transformer-like structures causing the score to be shy of 5.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.16198" target="_blank">Ultra-short-term multi-step wind speed prediction for wind farms based on adaptive noise reduction technology and temporal convolutional network</a></h3>
            
            <p><strong>Authors:</strong> Haojian Huang</p>
            <p><strong>Summary:</strong> arXiv:2311.16198v2 Announce Type: replace 
Abstract: As an important clean and renewable kind of energy, wind power plays an important role in coping with energy crisis and environmental pollution. However, the volatility and intermittency of wind speed restrict the development of wind power. To improve the utilization of wind power, this study proposes a new wind speed prediction model based on data noise reduction technology, temporal convolutional network (TCN), and gated recurrent unit (GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed based on singular spectrum analysis (SSA) and Pearson correlation coefficient. The original wind speed is decomposed into multiple subsequences by SSA and then reconstructed. When the Pearson correlation coefficient between the reconstructed sequence and the original sequence is greater than 0.99, other noise subsequences are deleted to complete the data denoising. Then, the receptive field of the samples is expanded through the causal convolution and dilated convolution of TCN, and the characteristics of wind speed change are extracted. Then, the time feature information of the sequence is extracted by GRU, and then the wind speed is predicted to form the wind speed sequence prediction model of P-SSA-TCN-GRU. The proposed model was validated on three wind farms in Shandong Province. The experimental results show that the prediction performance of the proposed model is better than that of the traditional model and other models based on TCN, and the wind speed prediction of wind farms with high precision and strong stability is realized. The wind speed predictions of this model have the potential to become the data that support the operation and management of wind farms. The code is available at https://github.com/JethroJames/Wind-Speed-Forecast-TCN_GRU</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.16198">https://arxiv.org/abs/2311.16198</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interests in time series and deep learning, as it discusses a new wind speed prediction model based on a temporal convolutional network (TCN). However, it doesn't seem to mention transformer-like models or foundation models, hence the 4 score.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.11422" target="_blank">Short-term wind speed forecasting model based on an attention-gated recurrent neural network and error correction strategy</a></h3>
            
            <p><strong>Authors:</strong> Haojian Huang</p>
            <p><strong>Summary:</strong> arXiv:2404.11422v2 Announce Type: replace 
Abstract: The accurate wind speed series forecast is very pivotal to security of grid dispatching and the application of wind power. Nevertheless, on account of their nonlinear and non-stationary nature, their short-term forecast is extremely challenging. Therefore, this dissertation raises one short-term wind speed forecast pattern on the foundation of attention with an improved gated recurrent neural network (AtGRU) and a tactic of error correction. That model uses the AtGRU model as the preliminary predictor and the GRU model as the error corrector. At the beginning, SSA (singular spectrum analysis) is employed in previous wind speed series for lessening the noise. Subsequently, historical wind speed series is going to be used for the predictor training. During this process, the prediction can have certain errors. The sequence of these errors processed by variational modal decomposition (VMD) is used to train the corrector of error. The eventual forecast consequence is just the sum of predictor forecast and error corrector. The proposed SSA-AtGRU-VMD-GRU model outperforms the compared models in three case studies on Woodburn, St. Thomas, and Santa Cruz. It is indicated that the model evidently enhances the correction of the wind speed forecast.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.11422">https://arxiv.org/abs/2404.11422</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> This paper presents a novel deep learning method for time series forecasting, specifically with wind speed. While it might not cover all your specific interests under the 'time-series' tag, it provides worthy insight into a new error correction strategy based on the AtGRU model.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2309.07136" target="_blank">Masked Transformer for Electrocardiogram Classification</a></h3>
            <a href="https://arxiv.org/html/2309.07136v2/extracted/5551682/pretrain_flow.png" target="_blank"><img src="https://arxiv.org/html/2309.07136v2/extracted/5551682/pretrain_flow.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Ya Zhou, Xiaolin Diao, Yanni Huo, Yang Liu, Xiaohan Fan, Wei Zhao</p>
            <p><strong>Summary:</strong> arXiv:2309.07136v2 Announce Type: replace-cross 
Abstract: Electrocardiogram (ECG) is one of the most important diagnostic tools in clinical applications. With the advent of advanced algorithms, various deep learning models have been adopted for ECG tasks. However, the potential of Transformers for ECG data is not yet realized, despite their widespread success in computer vision and natural language processing. In this work, we present a useful masked Transformer method for ECG classification referred to as MTECG, which expands the application of masked autoencoders to ECG time series. We construct a dataset comprising 220,251 ECG recordings with a broad range of diagnoses annoated by medical experts to explore the properties of MTECG. Under the proposed training strategies, a lightweight model with 5.7M parameters performs stably well on a broad range of masking ratios (5%-75%). The ablation studies highlight the importance of fluctuated reconstruction targets, training schedule length, layer-wise LR decay and DropPath rate. The experiments on both private and public ECG datasets demonstrate that MTECG-T significantly outperforms the recent state-of-the-art algorithms in ECG classification.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2309.07136">https://arxiv.org/abs/2309.07136</a></p>
            <p><strong>Category:</strong> eess.SP</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> time-series</p>
            <p><strong>Interest justification:</strong> The paper presents a new masked Transformer method for time series data related to ECG classification, making it relevant to your interest in new transformer-like models for time series.</p>
        </div>
        </div><h2 onclick="toggleSection('section_causality')">Causality</h2><div id='section_causality' class='papers-container'>
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2311.07454" target="_blank">Discrete Nonparametric Causal Discovery Under Latent Class Confounding</a></h3>
            <a href="https://arxiv.org/html/2311.07454v3/x1.png" target="_blank"><img src="https://arxiv.org/html/2311.07454v3/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Bijan Mazaheri, Spencer Gordon, Yuval Rabani, Leonard Schulman</p>
            <p><strong>Summary:</strong> arXiv:2311.07454v3 Announce Type: replace 
Abstract: An acyclic causal structure can be described using a directed acyclic graph (DAG) with arrows indicating causation. The task of learning these structures from data is known as ``causal discovery''. Diverse populations or changing environments can sometimes give rise to heterogeneous data. This heterogeneity can be thought of as a mixture model with multiple ``sources'', each exerting their own distinct signature on the observed variables. From this perspective, the source is a latent common cause for every observed variable. While some methods for causal discovery are able to work around unobserved confounding in special cases, the only known ways to deal with a global confounder (such as a latent class) involve parametric assumptions. These assumptions are restrictive, especially for discrete variables. By focusing on discrete observables, we demonstrate that globally confounded causal structures can still be identifiable without parametric assumptions, so long as the number of latent classes remains small relative to the size and sparsity of the underlying DAG.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2311.07454">https://arxiv.org/abs/2311.07454</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 5</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper appears to be highly relevant to your interest as it focuses on the topic of causal discovery, specifically addressing problems of latent confounding in a data-driven non-parametric way, which corresponds to your interest in causal discovery under the 'causality' tag.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13476" target="_blank">A Framework for Feasible Counterfactual Exploration incorporating Causality, Sparsity and Density</a></h3>
            <a href="https://arxiv.org/html/2404.13476v1/extracted/5549277/cfexample.png" target="_blank"><img src="https://arxiv.org/html/2404.13476v1/extracted/5549277/cfexample.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kleopatra Markou, Dimitrios Tomaras, Vana Kalogeraki, Dimitrios Gunopulos</p>
            <p><strong>Summary:</strong> arXiv:2404.13476v1 Announce Type: new 
Abstract: The imminent need to interpret the output of a Machine Learning model with counterfactual (CF) explanations - via small perturbations to the input - has been notable in the research community. Although the variety of CF examples is important, the aspect of them being feasible at the same time, does not necessarily apply in their entirety. This work uses different benchmark datasets to examine through the preservation of the logical causal relations of their attributes, whether CF examples can be generated after a small amount of changes to the original input, be feasible and actually useful to the end-user in a real-world case. To achieve this, we used a black box model as a classifier, to distinguish the desired from the input class and a Variational Autoencoder (VAE) to generate feasible CF examples. As an extension, we also extracted two-dimensional manifolds (one for each dataset) that located the majority of the feasible examples, a representation that adequately distinguished them from infeasible ones. For our experimentation we used three commonly used datasets and we managed to generate feasible and at the same time sparse, CF examples that satisfy all possible predefined causal constraints, by confirming their importance with the attributes in a dataset.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13476">https://arxiv.org/abs/2404.13476</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper delves into the aspect of Causal discovery and representation learning. It explores the generation of counterfactual explanations for machine learning models, thus fitting within your interest in investigating new methods incorporating causality in machine learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13853" target="_blank">ICST-DNET: An Interpretable Causal Spatio-Temporal Diffusion Network for Traffic Speed Prediction</a></h3>
            <a href="https://arxiv.org/html/2404.13853v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.13853v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Yi Rong, Yingchi Mao, Yinqiu Liu, Ling Chen, Xiaoming He, Dusit Niyato</p>
            <p><strong>Summary:</strong> arXiv:2404.13853v1 Announce Type: new 
Abstract: Traffic speed prediction is significant for intelligent navigation and congestion alleviation. However, making accurate predictions is challenging due to three factors: 1) traffic diffusion, i.e., the spatial and temporal causality existing between the traffic conditions of multiple neighboring roads, 2) the poor interpretability of traffic data with complicated spatio-temporal correlations, and 3) the latent pattern of traffic speed fluctuations over time, such as morning and evening rush. Jointly considering these factors, in this paper, we present a novel architecture for traffic speed prediction, called Interpretable Causal Spatio-Temporal Diffusion Network (ICST-DNET). Specifically, ICST-DENT consists of three parts, namely the Spatio-Temporal Causality Learning (STCL), Causal Graph Generation (CGG), and Speed Fluctuation Pattern Recognition (SFPR) modules. First, to model the traffic diffusion within road networks, an STCL module is proposed to capture both the temporal causality on each individual road and the spatial causality in each road pair. The CGG module is then developed based on STCL to enhance the interpretability of the traffic diffusion procedure from the temporal and spatial perspectives. Specifically, a time causality matrix is generated to explain the temporal causality between each road's historical and future traffic conditions. For spatial causality, we utilize causal graphs to visualize the diffusion process in road pairs. Finally, to adapt to traffic speed fluctuations in different scenarios, we design a personalized SFPR module to select the historical timesteps with strong influences for learning the pattern of traffic speed fluctuations. Extensive experimental results prove that ICST-DNET can outperform all existing baselines, as evidenced by the higher prediction accuracy, ability to explain causality, and adaptability to different scenarios.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13853">https://arxiv.org/abs/2404.13853</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> This paper is relevant to your interest in causal discovery, as it discusses an interpretable causal spatio-temporal diffusion network for traffic predictions, thus introducing a new method within causality and machine learning.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.14073" target="_blank">Towards Robust Trajectory Representations: Isolating Environmental Confounders with Causal Learning</a></h3>
            <a href="https://arxiv.org/html/2404.14073v1/x1.png" target="_blank"><img src="https://arxiv.org/html/2404.14073v1/x1.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Kang Luo, Yuanshao Zhu, Wei Chen, Kun Wang, Zhengyang Zhou, Sijie Ruan, Yuxuan Liang</p>
            <p><strong>Summary:</strong> arXiv:2404.14073v1 Announce Type: new 
Abstract: Trajectory modeling refers to characterizing human movement behavior, serving as a pivotal step in understanding mobility patterns. Nevertheless, existing studies typically ignore the confounding effects of geospatial context, leading to the acquisition of spurious correlations and limited generalization capabilities. To bridge this gap, we initially formulate a Structural Causal Model (SCM) to decipher the trajectory representation learning process from a causal perspective. Building upon the SCM, we further present a Trajectory modeling framework (TrajCL) based on Causal Learning, which leverages the backdoor adjustment theory as an intervention tool to eliminate the spurious correlations between geospatial context and trajectories. Extensive experiments on two real-world datasets verify that TrajCL markedly enhances performance in trajectory classification tasks while showcasing superior generalization and interpretability.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.14073">https://arxiv.org/abs/2404.14073</a></p>
            <p><strong>Category:</strong> cs.LG</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> The paper introduces a Trajectory modeling framework (TrajCL) based on Causal Learning, which aligns with your interest in Causal discovery and Causal representation learning. However, it may not involve the concept of large language model you stated.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.13240" target="_blank">Learning In Reverse Causal Strategic Environments With Ramifications on Two Sided Markets</a></h3>
            <a href="https://arxiv.org/html/2404.13240v1/extracted/5484059/qual_work_a_c.png" target="_blank"><img src="https://arxiv.org/html/2404.13240v1/extracted/5484059/qual_work_a_c.png" class="paper-figure" alt="Main Figure"></a>
            <p><strong>Authors:</strong> Seamus Somerstep, Yuekai Sun, Ya'acov Ritov</p>
            <p><strong>Summary:</strong> arXiv:2404.13240v1 Announce Type: cross 
Abstract: Motivated by equilibrium models of labor markets, we develop a formulation of causal strategic classification in which strategic agents can directly manipulate their outcomes. As an application, we compare employers that anticipate the strategic response of a labor force with employers that do not. We show through a combination of theory and experiment that employers with performatively optimal hiring policies improve employer reward, labor force skill level, and in some cases labor force equity. On the other hand, we demonstrate that performative employers harm labor force utility and fail to prevent discrimination in other cases.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.13240">https://arxiv.org/abs/2404.13240</a></p>
            <p><strong>Category:</strong> stat.ML</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> The paper relates to causal strategic classification, which is part of causal discovery under your interests. They are discussing causal effects in two-sided markets, which can be seen as a kind of causal representation learning. Although it does not directly seem to use large language models, it touches on performative aspects in labor markets, implying strategic outcomes that might be relevant to your interests.</p>
        </div>
        
        <div class="paper-box">
            <h3><a href="https://arxiv.org/abs/2404.05656" target="_blank">Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework</a></h3>
            
            <p><strong>Authors:</strong> Shahidur Rahoman Sohag, Sai Zhang, Min Xian, Shoukun Sun, Fei Xu, Zhegang Ma</p>
            <p><strong>Summary:</strong> arXiv:2404.05656v2 Announce Type: replace-cross 
Abstract: Industry-wide nuclear power plant operating experience is a critical source of raw data for performing parameter estimations in reliability and risk models. Much operating experience information pertains to failure events and is stored as reports containing unstructured data, such as narratives. Event reports are essential for understanding how failures are initiated and propagated, including the numerous causal relations involved. Causal relation extraction using deep learning represents a significant frontier in the field of natural language processing (NLP), and is crucial since it enables the interpretation of intricate narratives and connections contained within vast amounts of written information. This paper proposed a hybrid framework for causality detection and extraction from nuclear licensee event reports. The main contributions include: (1) we compiled an LER corpus with 20,129 text samples for causality analysis, (2) developed an interactive tool for labeling cause effect pairs, (3) built a deep-learning-based approach for causal relation detection, and (4) developed a knowledge based cause-effect extraction approach.</p>
            <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2404.05656">https://arxiv.org/abs/2404.05656</a></p>
            <p><strong>Category:</strong> cs.CL</p>
            <p><strong>Interest score:</strong> 4</p>
            <p><strong>Interest tag:</strong> causality</p>
            <p><strong>Interest justification:</strong> While the specific context of the paper is nuclear power plant operation, it presents a new approach to causal relation detection using deep learning, which is one of your interests. Also, it describes the creation of an interactive tool for labeling cause-effect pairs and a method for cause-effect extraction, contributing to causal discovery and representation learning.</p>
        </div>
        </div><div class='timestamp'>Report generated on April 23, 2024 at 21:43:47</div></body></html>